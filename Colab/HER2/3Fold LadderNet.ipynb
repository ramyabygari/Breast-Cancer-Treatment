{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3Fold LadderNet.ipynb","provenance":[{"file_id":"16hqggEiNT-NR-gwzWl-JDg6OSUab1SSE","timestamp":1590932441130},{"file_id":"1dLxM_AMOSs32Mxu42FNwumVVm11sLpeG","timestamp":1589304160359},{"file_id":"17lvwlvqQV7B-wqN2ajx7Q2UwCZwCd-WD","timestamp":1586698406636},{"file_id":"1SAeOlks1aRTndKfvFcMtNB7V3Ik6nfN0","timestamp":1586361815646},{"file_id":"1puNfvA8GEtqbsfDMP30_RS6XRrNM8Ky8","timestamp":1586249758540},{"file_id":"1QPxGukBl9nFKfyxsNhM4lUw4rYauJaY1","timestamp":1586242198727},{"file_id":"1txy9g7gYnELmPTY6sT4JtfbhwQthIyoG","timestamp":1583812009231},{"file_id":"1a9BwVwMfQ4iFdte5xgs4kzj58JNqs4Vu","timestamp":1579539718864},{"file_id":"1KyLESiefS0uSAi_kTOAZ9NmNUSYTs9lL","timestamp":1578995412588},{"file_id":"1YDTADQrLw8-aYCSjOEYxDuIB1nuy3Xzm","timestamp":1577686452735},{"file_id":"1DqrMpMvIbzPtWFjsL_eNwrVM-xaFvx6c","timestamp":1571727299009}],"collapsed_sections":["ZwjDP44MUTa6"],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ixvBWa23MB7e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1595562423699,"user_tz":-330,"elapsed":99990,"user":{"displayName":"Bhavishya Viswanath","photoUrl":"","userId":"05271986293024817587"}},"outputId":"75bd7ded-7f72-4c1c-d1c6-ae0d9af7877d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LzNbXYWE4I5E","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Mk6pnB6tFp0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595562737811,"user_tz":-330,"elapsed":3839,"user":{"displayName":"Bhavishya Viswanath","photoUrl":"","userId":"05271986293024817587"}},"outputId":"37206146-240e-4387-8096-38cb8158d56a"},"source":["import math\n","import random\n","import keras\n","from keras.layers import *\n","from keras.models import Sequential\n","from keras import Model\n","from keras import backend as K  \n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","\n","from sklearn import metrics"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U4SPHrcLZH4a","colab":{}},"source":["def get_conv_block(input_layer,nFilters,size):\n","    conv1 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(input_layer)\n","    bn1 = BatchNormalization()(conv1)\n","    conv2 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(bn1)\n","    bn2 = BatchNormalization()(conv2)\n","    return bn2\n","\n","def get_deconv_block(input_layer,nFilters,size):\n","    conv1 = Conv2DTranspose(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(input_layer)\n","    bn1 = BatchNormalization()(conv1)\n","    conv2 = Conv2DTranspose(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(bn1)\n","    bn2 = BatchNormalization()(conv2)\n","    return bn2\n","    \n","def get_UNET(input_layer,nFilters,flag): \n","\n","    block1 = get_conv_block(input_layer[0],nFilters,3)\n","    mp1 = MaxPooling2D(pool_size=(2, 2))(block1)\n","    dr1 = Dropout(0.1)(mp1)\n","   \n","    if(flag==1):\n","      dr1 = concatenate([dr1,input_layer[1]])\n","\n","    block2 = get_conv_block(dr1,nFilters*2,3)\n","    mp2 = MaxPooling2D(pool_size=(2, 2))(block2)\n","    dr2 = Dropout(0.1)(mp2)\n","\n","    if(flag==1):\n","      dr2 = concatenate([dr2,input_layer[2]])\n","   \n","    block3 = get_conv_block(dr2,nFilters*4,3)\n","    mp3 = MaxPooling2D(pool_size=(2, 2))(block3)\n","    dr3 = Dropout(0.1)(mp3)\n","\n","    if(flag==1):\n","      dr3 = concatenate([dr3,input_layer[3]])\n","       \n","    block4 = get_conv_block(dr3,nFilters*8,3)\n","    mp4 = MaxPooling2D(pool_size=(2, 2))(block4)\n","    dr4 = Dropout(0.1)(mp4)\n","\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(dr4)\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(conv5)\n","\n","    up1 = UpSampling2D(size=(2,2))(conv5)\n","    cat1 = concatenate([block4, up1, mp3])\n","    dr1 = Dropout(0.1)(cat1)\n","    block5 = get_deconv_block(dr1,nFilters*8,3)\n","\n","    up2 = UpSampling2D(size=(2,2))(block5)\n","    b4_upsample = UpSampling2D(size=(2,2))(block4)\n","    cat2 = concatenate([block3, up2, b4_upsample, mp2])\n","    dr2 = Dropout(0.1)(cat2)\n","    block6 = get_deconv_block(dr2,nFilters*4,3)\n","    \n","    up3 = UpSampling2D(size=(2,2))(block6)\n","    b3_upsample = UpSampling2D(size=(2,2))(block3)\n","    cat3 = concatenate([block2, up3, mp1, b3_upsample])\n","    dr3 = Dropout(0.1)(cat3)\n","    block7 = get_deconv_block(dr3,nFilters*2,3)\n","    \n","    up4 = UpSampling2D(size=(2,2))(block7)\n","    b2_upsample = UpSampling2D(size=(2,2))(block2)\n","    cat4 = concatenate([block1, up4, b2_upsample])\n","    dr4 = Dropout(0.1)(cat4)\n","    block8 = get_deconv_block(dr4,nFilters,3)\n","\n","    conv10 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(block8)\n","    conv11 = Conv2D(3,(1,1), activation='softmax', padding = 'same',kernel_regularizer=l2(1e-4))(conv10)\n","\n","    return (conv11, block7, block6, block5)\n","\n","def get_model(input_shape,nFilters1,nFilters2):\n","\n","    input_layer = Input(shape=input_shape)\n","    out1,out2,out3,out4 = get_UNET([input_layer],nFilters1,0)\n","\n","    out1,out2,out3,out4 = get_UNET([out1,out2,out3,out4],nFilters2,1)\n","\n","    model = Model(input_layer,out1)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiXrY-SjvEMW","colab_type":"code","colab":{}},"source":["PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/HER2/\"\n","\n","# Loading the data patient wise\n","X1 = np.load(PATH + 'Sliced Images/IHC 221.npy')\n","Y1 = np.load(PATH + 'Sliced Ground Truth/IHC 221.npy')\n","\n","X2 = np.load(PATH + 'Sliced Images/IHC 229.npy')\n","Y2 = np.load(PATH + 'Sliced Ground Truth/IHC 229.npy')\n","\n","X3 = np.load(PATH + 'Sliced Images/IHC 232.npy')\n","Y3 = np.load(PATH + 'Sliced Ground Truth/IHC 232.npy')\n","\n","X4 = np.load(PATH + 'Sliced Images/IHC 239.npy')\n","Y4 = np.load(PATH + 'Sliced Ground Truth/IHC 239.npy')\n","\n","X5 = np.load(PATH + 'Sliced Images/IHC 242.npy')\n","Y5 = np.load(PATH + 'Sliced Ground Truth/IHC 242.npy')\n","\n","X6 = np.load(PATH + 'Sliced Images/IHC 246.npy')\n","Y6 = np.load(PATH + 'Sliced Ground Truth/IHC 246.npy')\n","\n","X7 = np.load(PATH + 'Sliced Images/IHC 252.npy')\n","Y7 = np.load(PATH + 'Sliced Ground Truth/IHC 252.npy')\n","\n","X8 = np.load(PATH + 'Sliced Images/IHC 254.npy')\n","Y8 = np.load(PATH + 'Sliced Ground Truth/IHC 254.npy')\n","\n","X9 = np.load(PATH + 'Sliced Images/IHC 263.npy')\n","Y9 = np.load(PATH + 'Sliced Ground Truth/IHC 263.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgAEBm703KCC","colab_type":"code","colab":{}},"source":["X = [X1, X2, X3, X4, X5, X6, X7, X8, X9]\n","Y = [Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y9]\n","patient_no = ['221','229','232','239','242','246','252','254','263']\n","size = [10,10,10,10,10,10,11,10,10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWE-QvIXeBrW","colab_type":"code","colab":{}},"source":["fold_split = []\n","\n","#test patient = 221, 229\n","fold_split.append(([2,3,4,5,6,7,8],[0,1]))\n","\n","#test_patient = 239, 252\n","fold_split.append(([0,1,2,4,5,7,8],[3,6]))\n","\n","#test_patient = 252,263\n","fold_split.append(([0,1,2,3,4,6,8],[5,7]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MujkbhpsnE9","colab_type":"code","colab":{}},"source":["def convertToLabels(data):\n","  data[data==128]=1\n","  data[data==255]=2\n","\n","def convertFromLabels(data):\n","  data[data==1]=128\n","  data[data==2]=255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDodKs-AMB81","colab_type":"code","colab":{}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TH9yDcoO6Kyg","colab_type":"code","colab":{}},"source":["def tversky_loss_1(y_true, y_pred):\n","    alpha = 0.7\n","    beta  = 0.3\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","  \n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def tversky_loss_2(y_true, y_pred):\n","    alpha = 0.3\n","    beta  = 0.7\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","\n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def focal_tversky_loss_1(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_1(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","  \n","def focal_tversky_loss_2(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_2(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","\n","def combined_loss(y_true, y_pred):\n","  return (0.2*K.categorical_crossentropy(y_true, y_pred))+(0.8*focal_tversky_loss_1(y_true, y_pred)+(0.8*focal_tversky_loss_2(y_true, y_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaGvHbqtarli","colab_type":"code","colab":{}},"source":["batch_size = 8\n","def get_batch(batch_size, X_train, Y_train): \n","    size_batch = batch_size\n","    last_index = len(X_train) - 1\n","    x_train = X_train\n","    y_train = Y_train \n","    while True:\n","        batch_data = [[],[]]\n","        for i in range(0, size_batch):\n","            random_index = random.randint(0, last_index)\n","            batch_data[0].append(x_train[random_index])\n","            batch_data[1].append(y_train[random_index])\n","\n","        yield (np.array(batch_data[0]), np.array(batch_data[1]))     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"59LOrWNyeE9X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"934d9bab-0f59-485f-b7fd-e5db79f288b8"},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/HER2/3Fold LadderNet/\"\n","\n","fold=0\n","\n","for train_index, test_index in fold_split:\n","  print(\"TRAIN:\", train_index, \"TEST:\", test_index, \"FOLD:\", fold)\n","\n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  Train = list(zip(TrainX,TrainY))\n","  random.shuffle(Train)\n","  TrainX,TrainY = zip(*Train)\n","  TrainX = np.asarray(list(TrainX))\n","  TrainY = np.asarray(list(TrainY))\n","\n","  Test = list(zip(TestX,TestY))\n","  random.shuffle(Test)\n","  TestX,TestY = zip(*Test)\n","  TestX = np.asarray(list(TestX))\n","  TestY = np.asarray(list(TestY))\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","  convertToLabels(TrainY)\n","  TrainY = keras.utils.to_categorical(TrainY,num_classes=3,dtype='int16')\n","  convertToLabels(TestY)\n","  TestY = keras.utils.to_categorical(TestY,num_classes=3,dtype='int16')\n","  ValX = TrainX[(int)(0.8*TrainX.shape[0]):]\n","  ValY = TrainY[(int)(0.8*TrainY.shape[0]):]\n","  model = get_model((240,240,3),32,64)\n","\n","  mc = ModelCheckpoint('Checkpoint.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","  optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)\n","\n","  model.compile(loss=combined_loss, optimizer= optimizer , metrics=[dice_coef,'accuracy']) \n","  num_epoch = 100\n","  datagen = get_batch(batch_size, TrainX, TrainY)\n","  n_points = len(TrainX)\n","  print('-----------fold {}--------------'.format(fold))\n","  history = model.fit(datagen, validation_data = [ValX, ValY],\n","                  epochs=num_epoch,steps_per_epoch = math.ceil(n_points / batch_size), callbacks =[mc],  shuffle =True)\n","  model.save(MODELS_PATH + '/LadderNet_HER2_'+ str(fold) +'.h5')\n","  fold = fold + 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN: [2, 3, 4, 5, 6, 7, 8] TEST: [0, 1] FOLD: 0\n","-----------fold 0--------------\n","Epoch 1/100\n","426/426 [==============================] - 345s 811ms/step - loss: 4.3843 - dice_coef: 0.7849 - accuracy: 0.8622 - val_loss: 4.3956 - val_dice_coef: 0.8098 - val_accuracy: 0.8391\n","\n","Epoch 00001: val_loss improved from inf to 4.39564, saving model to Checkpoint.h5\n","Epoch 2/100\n","426/426 [==============================] - 324s 760ms/step - loss: 3.8010 - dice_coef: 0.8455 - accuracy: 0.8961 - val_loss: 3.9686 - val_dice_coef: 0.7377 - val_accuracy: 0.7682\n","\n","Epoch 00002: val_loss improved from 4.39564 to 3.96864, saving model to Checkpoint.h5\n","Epoch 3/100\n","426/426 [==============================] - 324s 760ms/step - loss: 3.3523 - dice_coef: 0.8659 - accuracy: 0.8996 - val_loss: 3.3920 - val_dice_coef: 0.8573 - val_accuracy: 0.8727\n","\n","Epoch 00003: val_loss improved from 3.96864 to 3.39196, saving model to Checkpoint.h5\n","Epoch 4/100\n","426/426 [==============================] - 324s 760ms/step - loss: 2.9612 - dice_coef: 0.8818 - accuracy: 0.9042 - val_loss: 2.7775 - val_dice_coef: 0.8954 - val_accuracy: 0.9135\n","\n","Epoch 00004: val_loss improved from 3.39196 to 2.77750, saving model to Checkpoint.h5\n","Epoch 5/100\n","426/426 [==============================] - 324s 760ms/step - loss: 2.6384 - dice_coef: 0.8916 - accuracy: 0.9073 - val_loss: 2.5854 - val_dice_coef: 0.8810 - val_accuracy: 0.8937\n","\n","Epoch 00005: val_loss improved from 2.77750 to 2.58541, saving model to Checkpoint.h5\n","Epoch 6/100\n","426/426 [==============================] - 324s 760ms/step - loss: 2.3979 - dice_coef: 0.8923 - accuracy: 0.9052 - val_loss: 2.4506 - val_dice_coef: 0.8817 - val_accuracy: 0.8893\n","\n","Epoch 00006: val_loss improved from 2.58541 to 2.45058, saving model to Checkpoint.h5\n","Epoch 7/100\n","426/426 [==============================] - 324s 760ms/step - loss: 2.1557 - dice_coef: 0.8999 - accuracy: 0.9102 - val_loss: 2.4949 - val_dice_coef: 0.8251 - val_accuracy: 0.8322\n","\n","Epoch 00007: val_loss did not improve from 2.45058\n","Epoch 8/100\n","426/426 [==============================] - 323s 759ms/step - loss: 1.9742 - dice_coef: 0.9015 - accuracy: 0.9103 - val_loss: 2.0217 - val_dice_coef: 0.8762 - val_accuracy: 0.8847\n","\n","Epoch 00008: val_loss improved from 2.45058 to 2.02173, saving model to Checkpoint.h5\n","Epoch 9/100\n","426/426 [==============================] - 323s 759ms/step - loss: 1.8165 - dice_coef: 0.9026 - accuracy: 0.9106 - val_loss: 1.9320 - val_dice_coef: 0.8869 - val_accuracy: 0.8922\n","\n","Epoch 00009: val_loss improved from 2.02173 to 1.93196, saving model to Checkpoint.h5\n","Epoch 10/100\n","426/426 [==============================] - 324s 759ms/step - loss: 1.6962 - dice_coef: 0.9037 - accuracy: 0.9109 - val_loss: 2.0101 - val_dice_coef: 0.8698 - val_accuracy: 0.8726\n","\n","Epoch 00010: val_loss did not improve from 1.93196\n","Epoch 11/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.5735 - dice_coef: 0.9074 - accuracy: 0.9138 - val_loss: 1.6898 - val_dice_coef: 0.8959 - val_accuracy: 0.8993\n","\n","Epoch 00011: val_loss improved from 1.93196 to 1.68984, saving model to Checkpoint.h5\n","Epoch 12/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.4853 - dice_coef: 0.9053 - accuracy: 0.9116 - val_loss: 1.5232 - val_dice_coef: 0.9013 - val_accuracy: 0.9051\n","\n","Epoch 00012: val_loss improved from 1.68984 to 1.52320, saving model to Checkpoint.h5\n","Epoch 13/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.3870 - dice_coef: 0.9091 - accuracy: 0.9148 - val_loss: 1.5646 - val_dice_coef: 0.8868 - val_accuracy: 0.8925\n","\n","Epoch 00013: val_loss did not improve from 1.52320\n","Epoch 14/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.2972 - dice_coef: 0.9111 - accuracy: 0.9165 - val_loss: 1.4130 - val_dice_coef: 0.8973 - val_accuracy: 0.9019\n","\n","Epoch 00014: val_loss improved from 1.52320 to 1.41299, saving model to Checkpoint.h5\n","Epoch 15/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.2434 - dice_coef: 0.9128 - accuracy: 0.9180 - val_loss: 1.4387 - val_dice_coef: 0.8892 - val_accuracy: 0.8913\n","\n","Epoch 00015: val_loss did not improve from 1.41299\n","Epoch 16/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.1734 - dice_coef: 0.9141 - accuracy: 0.9192 - val_loss: 1.4393 - val_dice_coef: 0.8855 - val_accuracy: 0.8888\n","\n","Epoch 00016: val_loss did not improve from 1.41299\n","Epoch 17/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.1244 - dice_coef: 0.9142 - accuracy: 0.9189 - val_loss: 1.2237 - val_dice_coef: 0.8981 - val_accuracy: 0.9083\n","\n","Epoch 00017: val_loss improved from 1.41299 to 1.22373, saving model to Checkpoint.h5\n","Epoch 18/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.0963 - dice_coef: 0.9145 - accuracy: 0.9190 - val_loss: 1.4302 - val_dice_coef: 0.8663 - val_accuracy: 0.8687\n","\n","Epoch 00018: val_loss did not improve from 1.22373\n","Epoch 19/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.0645 - dice_coef: 0.9134 - accuracy: 0.9179 - val_loss: 1.1377 - val_dice_coef: 0.8957 - val_accuracy: 0.8998\n","\n","Epoch 00019: val_loss improved from 1.22373 to 1.13767, saving model to Checkpoint.h5\n","Epoch 20/100\n","426/426 [==============================] - 324s 760ms/step - loss: 1.0203 - dice_coef: 0.9169 - accuracy: 0.9211 - val_loss: 1.1380 - val_dice_coef: 0.9050 - val_accuracy: 0.9076\n","\n","Epoch 00020: val_loss did not improve from 1.13767\n","Epoch 21/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.9749 - dice_coef: 0.9181 - accuracy: 0.9224 - val_loss: 1.0198 - val_dice_coef: 0.9170 - val_accuracy: 0.9193\n","\n","Epoch 00021: val_loss improved from 1.13767 to 1.01981, saving model to Checkpoint.h5\n","Epoch 22/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.9897 - dice_coef: 0.9155 - accuracy: 0.9196 - val_loss: 1.8789 - val_dice_coef: 0.6937 - val_accuracy: 0.6967\n","\n","Epoch 00022: val_loss did not improve from 1.01981\n","Epoch 23/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.9492 - dice_coef: 0.9170 - accuracy: 0.9211 - val_loss: 1.0070 - val_dice_coef: 0.9059 - val_accuracy: 0.9108\n","\n","Epoch 00023: val_loss improved from 1.01981 to 1.00704, saving model to Checkpoint.h5\n","Epoch 24/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.9662 - dice_coef: 0.9136 - accuracy: 0.9176 - val_loss: 1.1185 - val_dice_coef: 0.9015 - val_accuracy: 0.9039\n","\n","Epoch 00024: val_loss did not improve from 1.00704\n","Epoch 25/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.9521 - dice_coef: 0.9149 - accuracy: 0.9189 - val_loss: 1.1011 - val_dice_coef: 0.8927 - val_accuracy: 0.8949\n","\n","Epoch 00025: val_loss did not improve from 1.00704\n","Epoch 26/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.9101 - dice_coef: 0.9187 - accuracy: 0.9226 - val_loss: 0.9396 - val_dice_coef: 0.9193 - val_accuracy: 0.9214\n","\n","Epoch 00026: val_loss improved from 1.00704 to 0.93962, saving model to Checkpoint.h5\n","Epoch 27/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.9131 - dice_coef: 0.9165 - accuracy: 0.9203 - val_loss: 0.9514 - val_dice_coef: 0.9158 - val_accuracy: 0.9181\n","\n","Epoch 00027: val_loss did not improve from 0.93962\n","Epoch 28/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8627 - dice_coef: 0.9218 - accuracy: 0.9255 - val_loss: 0.9336 - val_dice_coef: 0.9152 - val_accuracy: 0.9181\n","\n","Epoch 00028: val_loss improved from 0.93962 to 0.93355, saving model to Checkpoint.h5\n","Epoch 29/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8745 - dice_coef: 0.9206 - accuracy: 0.9243 - val_loss: 1.2116 - val_dice_coef: 0.8570 - val_accuracy: 0.8592\n","\n","Epoch 00029: val_loss did not improve from 0.93355\n","Epoch 30/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8660 - dice_coef: 0.9200 - accuracy: 0.9236 - val_loss: 0.9577 - val_dice_coef: 0.9099 - val_accuracy: 0.9120\n","\n","Epoch 00030: val_loss did not improve from 0.93355\n","Epoch 31/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.8551 - dice_coef: 0.9208 - accuracy: 0.9243 - val_loss: 1.0074 - val_dice_coef: 0.8980 - val_accuracy: 0.9027\n","\n","Epoch 00031: val_loss did not improve from 0.93355\n","Epoch 32/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8530 - dice_coef: 0.9209 - accuracy: 0.9244 - val_loss: 0.9937 - val_dice_coef: 0.9062 - val_accuracy: 0.9088\n","\n","Epoch 00032: val_loss did not improve from 0.93355\n","Epoch 33/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8716 - dice_coef: 0.9192 - accuracy: 0.9226 - val_loss: 0.8535 - val_dice_coef: 0.9219 - val_accuracy: 0.9243\n","\n","Epoch 00033: val_loss improved from 0.93355 to 0.85347, saving model to Checkpoint.h5\n","Epoch 34/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8416 - dice_coef: 0.9219 - accuracy: 0.9253 - val_loss: 1.4489 - val_dice_coef: 0.8102 - val_accuracy: 0.8118\n","\n","Epoch 00034: val_loss did not improve from 0.85347\n","Epoch 35/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8525 - dice_coef: 0.9209 - accuracy: 0.9242 - val_loss: 0.9759 - val_dice_coef: 0.9078 - val_accuracy: 0.9098\n","\n","Epoch 00035: val_loss did not improve from 0.85347\n","Epoch 36/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8281 - dice_coef: 0.9218 - accuracy: 0.9251 - val_loss: 0.8676 - val_dice_coef: 0.9179 - val_accuracy: 0.9208\n","\n","Epoch 00036: val_loss did not improve from 0.85347\n","Epoch 37/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8135 - dice_coef: 0.9237 - accuracy: 0.9270 - val_loss: 1.2266 - val_dice_coef: 0.8761 - val_accuracy: 0.8781\n","\n","Epoch 00037: val_loss did not improve from 0.85347\n","Epoch 38/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8015 - dice_coef: 0.9253 - accuracy: 0.9285 - val_loss: 0.9883 - val_dice_coef: 0.9039 - val_accuracy: 0.9065\n","\n","Epoch 00038: val_loss did not improve from 0.85347\n","Epoch 39/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8369 - dice_coef: 0.9218 - accuracy: 0.9251 - val_loss: 1.0513 - val_dice_coef: 0.8960 - val_accuracy: 0.8974\n","\n","Epoch 00039: val_loss did not improve from 0.85347\n","Epoch 40/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8188 - dice_coef: 0.9226 - accuracy: 0.9259 - val_loss: 1.0706 - val_dice_coef: 0.8969 - val_accuracy: 0.8980\n","\n","Epoch 00040: val_loss did not improve from 0.85347\n","Epoch 41/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.8018 - dice_coef: 0.9243 - accuracy: 0.9274 - val_loss: 1.1638 - val_dice_coef: 0.8880 - val_accuracy: 0.8884\n","\n","Epoch 00041: val_loss did not improve from 0.85347\n","Epoch 42/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8216 - dice_coef: 0.9226 - accuracy: 0.9258 - val_loss: 1.0332 - val_dice_coef: 0.8909 - val_accuracy: 0.8919\n","\n","Epoch 00042: val_loss did not improve from 0.85347\n","Epoch 43/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8051 - dice_coef: 0.9230 - accuracy: 0.9262 - val_loss: 0.9781 - val_dice_coef: 0.8976 - val_accuracy: 0.9000\n","\n","Epoch 00043: val_loss did not improve from 0.85347\n","Epoch 44/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7972 - dice_coef: 0.9249 - accuracy: 0.9281 - val_loss: 0.8991 - val_dice_coef: 0.9117 - val_accuracy: 0.9143\n","\n","Epoch 00044: val_loss did not improve from 0.85347\n","Epoch 45/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7965 - dice_coef: 0.9239 - accuracy: 0.9271 - val_loss: 1.0184 - val_dice_coef: 0.9002 - val_accuracy: 0.9025\n","\n","Epoch 00045: val_loss did not improve from 0.85347\n","Epoch 46/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7844 - dice_coef: 0.9254 - accuracy: 0.9285 - val_loss: 0.9112 - val_dice_coef: 0.9068 - val_accuracy: 0.9094\n","\n","Epoch 00046: val_loss did not improve from 0.85347\n","Epoch 47/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7979 - dice_coef: 0.9240 - accuracy: 0.9271 - val_loss: 1.2237 - val_dice_coef: 0.8713 - val_accuracy: 0.8726\n","\n","Epoch 00047: val_loss did not improve from 0.85347\n","Epoch 48/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8040 - dice_coef: 0.9235 - accuracy: 0.9266 - val_loss: 1.0271 - val_dice_coef: 0.9042 - val_accuracy: 0.9048\n","\n","Epoch 00048: val_loss did not improve from 0.85347\n","Epoch 49/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7821 - dice_coef: 0.9248 - accuracy: 0.9278 - val_loss: 1.3898 - val_dice_coef: 0.7955 - val_accuracy: 0.7985\n","\n","Epoch 00049: val_loss did not improve from 0.85347\n","Epoch 50/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8088 - dice_coef: 0.9224 - accuracy: 0.9255 - val_loss: 0.9086 - val_dice_coef: 0.9124 - val_accuracy: 0.9147\n","\n","Epoch 00050: val_loss did not improve from 0.85347\n","Epoch 51/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8068 - dice_coef: 0.9235 - accuracy: 0.9265 - val_loss: 1.8449 - val_dice_coef: 0.6973 - val_accuracy: 0.6970\n","\n","Epoch 00051: val_loss did not improve from 0.85347\n","Epoch 52/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8050 - dice_coef: 0.9226 - accuracy: 0.9257 - val_loss: 0.8899 - val_dice_coef: 0.9157 - val_accuracy: 0.9186\n","\n","Epoch 00052: val_loss did not improve from 0.85347\n","Epoch 53/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8021 - dice_coef: 0.9228 - accuracy: 0.9259 - val_loss: 1.0545 - val_dice_coef: 0.9007 - val_accuracy: 0.9016\n","\n","Epoch 00053: val_loss did not improve from 0.85347\n","Epoch 54/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7688 - dice_coef: 0.9277 - accuracy: 0.9305 - val_loss: 0.9209 - val_dice_coef: 0.9132 - val_accuracy: 0.9145\n","\n","Epoch 00054: val_loss did not improve from 0.85347\n","Epoch 55/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7738 - dice_coef: 0.9275 - accuracy: 0.9303 - val_loss: 0.9303 - val_dice_coef: 0.8983 - val_accuracy: 0.9021\n","\n","Epoch 00055: val_loss did not improve from 0.85347\n","Epoch 56/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7816 - dice_coef: 0.9264 - accuracy: 0.9293 - val_loss: 1.0411 - val_dice_coef: 0.9004 - val_accuracy: 0.9014\n","\n","Epoch 00056: val_loss did not improve from 0.85347\n","Epoch 57/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7975 - dice_coef: 0.9237 - accuracy: 0.9266 - val_loss: 1.0322 - val_dice_coef: 0.8976 - val_accuracy: 0.9009\n","\n","Epoch 00057: val_loss did not improve from 0.85347\n","Epoch 58/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8056 - dice_coef: 0.9249 - accuracy: 0.9278 - val_loss: 1.0100 - val_dice_coef: 0.8993 - val_accuracy: 0.9003\n","\n","Epoch 00058: val_loss did not improve from 0.85347\n","Epoch 59/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7781 - dice_coef: 0.9278 - accuracy: 0.9306 - val_loss: 0.9285 - val_dice_coef: 0.9142 - val_accuracy: 0.9155\n","\n","Epoch 00059: val_loss did not improve from 0.85347\n","Epoch 60/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7997 - dice_coef: 0.9238 - accuracy: 0.9267 - val_loss: 0.8153 - val_dice_coef: 0.9254 - val_accuracy: 0.9269\n","\n","Epoch 00060: val_loss improved from 0.85347 to 0.81535, saving model to Checkpoint.h5\n","Epoch 61/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7875 - dice_coef: 0.9261 - accuracy: 0.9289 - val_loss: 0.8013 - val_dice_coef: 0.9256 - val_accuracy: 0.9278\n","\n","Epoch 00061: val_loss improved from 0.81535 to 0.80130, saving model to Checkpoint.h5\n","Epoch 62/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7648 - dice_coef: 0.9288 - accuracy: 0.9315 - val_loss: 0.9778 - val_dice_coef: 0.8931 - val_accuracy: 0.8954\n","\n","Epoch 00062: val_loss did not improve from 0.80130\n","Epoch 63/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7589 - dice_coef: 0.9284 - accuracy: 0.9312 - val_loss: 0.9291 - val_dice_coef: 0.9120 - val_accuracy: 0.9140\n","\n","Epoch 00063: val_loss did not improve from 0.80130\n","Epoch 64/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7804 - dice_coef: 0.9269 - accuracy: 0.9297 - val_loss: 0.9397 - val_dice_coef: 0.9103 - val_accuracy: 0.9117\n","\n","Epoch 00064: val_loss did not improve from 0.80130\n","Epoch 65/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7639 - dice_coef: 0.9285 - accuracy: 0.9312 - val_loss: 0.8883 - val_dice_coef: 0.9153 - val_accuracy: 0.9182\n","\n","Epoch 00065: val_loss did not improve from 0.80130\n","Epoch 66/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7691 - dice_coef: 0.9287 - accuracy: 0.9314 - val_loss: 0.9027 - val_dice_coef: 0.9139 - val_accuracy: 0.9159\n","\n","Epoch 00066: val_loss did not improve from 0.80130\n","Epoch 67/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7734 - dice_coef: 0.9292 - accuracy: 0.9319 - val_loss: 1.0157 - val_dice_coef: 0.8894 - val_accuracy: 0.8909\n","\n","Epoch 00067: val_loss did not improve from 0.80130\n","Epoch 68/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7751 - dice_coef: 0.9283 - accuracy: 0.9310 - val_loss: 0.9526 - val_dice_coef: 0.9092 - val_accuracy: 0.9103\n","\n","Epoch 00068: val_loss did not improve from 0.80130\n","Epoch 69/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7814 - dice_coef: 0.9272 - accuracy: 0.9299 - val_loss: 0.8556 - val_dice_coef: 0.9191 - val_accuracy: 0.9208\n","\n","Epoch 00069: val_loss did not improve from 0.80130\n","Epoch 70/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7938 - dice_coef: 0.9253 - accuracy: 0.9281 - val_loss: 0.8492 - val_dice_coef: 0.9205 - val_accuracy: 0.9227\n","\n","Epoch 00070: val_loss did not improve from 0.80130\n","Epoch 71/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7851 - dice_coef: 0.9264 - accuracy: 0.9292 - val_loss: 0.8608 - val_dice_coef: 0.9199 - val_accuracy: 0.9211\n","\n","Epoch 00071: val_loss did not improve from 0.80130\n","Epoch 72/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7811 - dice_coef: 0.9270 - accuracy: 0.9299 - val_loss: 0.7985 - val_dice_coef: 0.9259 - val_accuracy: 0.9276\n","\n","Epoch 00072: val_loss improved from 0.80130 to 0.79851, saving model to Checkpoint.h5\n","Epoch 73/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7838 - dice_coef: 0.9267 - accuracy: 0.9295 - val_loss: 0.9848 - val_dice_coef: 0.9103 - val_accuracy: 0.9111\n","\n","Epoch 00073: val_loss did not improve from 0.79851\n","Epoch 74/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7664 - dice_coef: 0.9290 - accuracy: 0.9316 - val_loss: 1.2734 - val_dice_coef: 0.8799 - val_accuracy: 0.8801\n","\n","Epoch 00074: val_loss did not improve from 0.79851\n","Epoch 75/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7710 - dice_coef: 0.9271 - accuracy: 0.9299 - val_loss: 0.9639 - val_dice_coef: 0.9110 - val_accuracy: 0.9120\n","\n","Epoch 00075: val_loss did not improve from 0.79851\n","Epoch 76/100\n","426/426 [==============================] - 323s 759ms/step - loss: 0.8168 - dice_coef: 0.9221 - accuracy: 0.9250 - val_loss: 1.0396 - val_dice_coef: 0.9025 - val_accuracy: 0.9036\n","\n","Epoch 00076: val_loss did not improve from 0.79851\n","Epoch 77/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.8069 - dice_coef: 0.9245 - accuracy: 0.9273 - val_loss: 0.8623 - val_dice_coef: 0.9195 - val_accuracy: 0.9213\n","\n","Epoch 00077: val_loss did not improve from 0.79851\n","Epoch 78/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7573 - dice_coef: 0.9296 - accuracy: 0.9322 - val_loss: 1.0202 - val_dice_coef: 0.8980 - val_accuracy: 0.8999\n","\n","Epoch 00078: val_loss did not improve from 0.79851\n","Epoch 79/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7887 - dice_coef: 0.9255 - accuracy: 0.9283 - val_loss: 1.2109 - val_dice_coef: 0.8604 - val_accuracy: 0.8614\n","\n","Epoch 00079: val_loss did not improve from 0.79851\n","Epoch 80/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7390 - dice_coef: 0.9325 - accuracy: 0.9350 - val_loss: 0.9154 - val_dice_coef: 0.9093 - val_accuracy: 0.9119\n","\n","Epoch 00080: val_loss did not improve from 0.79851\n","Epoch 81/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7772 - dice_coef: 0.9293 - accuracy: 0.9318 - val_loss: 0.9578 - val_dice_coef: 0.9094 - val_accuracy: 0.9117\n","\n","Epoch 00081: val_loss did not improve from 0.79851\n","Epoch 82/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7713 - dice_coef: 0.9280 - accuracy: 0.9307 - val_loss: 0.8407 - val_dice_coef: 0.9201 - val_accuracy: 0.9220\n","\n","Epoch 00082: val_loss did not improve from 0.79851\n","Epoch 83/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7469 - dice_coef: 0.9308 - accuracy: 0.9333 - val_loss: 1.0956 - val_dice_coef: 0.8975 - val_accuracy: 0.8978\n","\n","Epoch 00083: val_loss did not improve from 0.79851\n","Epoch 84/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7749 - dice_coef: 0.9283 - accuracy: 0.9310 - val_loss: 0.8612 - val_dice_coef: 0.9186 - val_accuracy: 0.9208\n","\n","Epoch 00084: val_loss did not improve from 0.79851\n","Epoch 85/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7570 - dice_coef: 0.9309 - accuracy: 0.9334 - val_loss: 1.6785 - val_dice_coef: 0.7283 - val_accuracy: 0.7297\n","\n","Epoch 00085: val_loss did not improve from 0.79851\n","Epoch 86/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7715 - dice_coef: 0.9288 - accuracy: 0.9314 - val_loss: 0.8545 - val_dice_coef: 0.9183 - val_accuracy: 0.9217\n","\n","Epoch 00086: val_loss did not improve from 0.79851\n","Epoch 87/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7644 - dice_coef: 0.9296 - accuracy: 0.9322 - val_loss: 0.8860 - val_dice_coef: 0.9170 - val_accuracy: 0.9192\n","\n","Epoch 00087: val_loss did not improve from 0.79851\n","Epoch 88/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7621 - dice_coef: 0.9304 - accuracy: 0.9329 - val_loss: 1.5057 - val_dice_coef: 0.7676 - val_accuracy: 0.7694\n","\n","Epoch 00088: val_loss did not improve from 0.79851\n","Epoch 89/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7963 - dice_coef: 0.9247 - accuracy: 0.9274 - val_loss: 1.0189 - val_dice_coef: 0.9023 - val_accuracy: 0.9040\n","\n","Epoch 00089: val_loss did not improve from 0.79851\n","Epoch 90/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7741 - dice_coef: 0.9289 - accuracy: 0.9315 - val_loss: 0.8821 - val_dice_coef: 0.9157 - val_accuracy: 0.9175\n","\n","Epoch 00090: val_loss did not improve from 0.79851\n","Epoch 91/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7811 - dice_coef: 0.9281 - accuracy: 0.9307 - val_loss: 0.8512 - val_dice_coef: 0.9223 - val_accuracy: 0.9238\n","\n","Epoch 00091: val_loss did not improve from 0.79851\n","Epoch 92/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7512 - dice_coef: 0.9316 - accuracy: 0.9340 - val_loss: 1.0276 - val_dice_coef: 0.8958 - val_accuracy: 0.8997\n","\n","Epoch 00092: val_loss did not improve from 0.79851\n","Epoch 93/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7586 - dice_coef: 0.9313 - accuracy: 0.9338 - val_loss: 0.8578 - val_dice_coef: 0.9156 - val_accuracy: 0.9179\n","\n","Epoch 00093: val_loss did not improve from 0.79851\n","Epoch 94/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7567 - dice_coef: 0.9307 - accuracy: 0.9332 - val_loss: 0.9604 - val_dice_coef: 0.9066 - val_accuracy: 0.9089\n","\n","Epoch 00094: val_loss did not improve from 0.79851\n","Epoch 95/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7391 - dice_coef: 0.9325 - accuracy: 0.9349 - val_loss: 0.8892 - val_dice_coef: 0.9174 - val_accuracy: 0.9185\n","\n","Epoch 00095: val_loss did not improve from 0.79851\n","Epoch 96/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7833 - dice_coef: 0.9274 - accuracy: 0.9300 - val_loss: 1.1850 - val_dice_coef: 0.8736 - val_accuracy: 0.8741\n","\n","Epoch 00096: val_loss did not improve from 0.79851\n","Epoch 97/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7742 - dice_coef: 0.9284 - accuracy: 0.9311 - val_loss: 0.8364 - val_dice_coef: 0.9239 - val_accuracy: 0.9252\n","\n","Epoch 00097: val_loss did not improve from 0.79851\n","Epoch 98/100\n","426/426 [==============================] - 324s 760ms/step - loss: 0.7702 - dice_coef: 0.9289 - accuracy: 0.9315 - val_loss: 1.0209 - val_dice_coef: 0.8984 - val_accuracy: 0.8994\n","\n","Epoch 00098: val_loss did not improve from 0.79851\n","Epoch 99/100\n","426/426 [==============================] - 324s 759ms/step - loss: 0.7482 - dice_coef: 0.9326 - accuracy: 0.9350 - val_loss: 0.9104 - val_dice_coef: 0.9145 - val_accuracy: 0.9164\n","\n","Epoch 00099: val_loss did not improve from 0.79851\n","Epoch 100/100\n","426/426 [==============================] - 323s 759ms/step - loss: 0.7793 - dice_coef: 0.9282 - accuracy: 0.9309 - val_loss: 0.9615 - val_dice_coef: 0.9079 - val_accuracy: 0.9107\n","\n","Epoch 00100: val_loss did not improve from 0.79851\n","TRAIN: [0, 1, 2, 4, 5, 7, 8] TEST: [3, 6] FOLD: 1\n","-----------fold 1--------------\n","Epoch 1/100\n","420/420 [==============================] - 333s 792ms/step - loss: 4.1227 - dice_coef: 0.8077 - accuracy: 0.8461 - val_loss: 3.8013 - val_dice_coef: 0.8790 - val_accuracy: 0.8846\n","\n","Epoch 00001: val_loss improved from inf to 3.80128, saving model to Checkpoint.h5\n","Epoch 2/100\n","420/420 [==============================] - 320s 761ms/step - loss: 3.6070 - dice_coef: 0.8746 - accuracy: 0.8782 - val_loss: 3.3034 - val_dice_coef: 0.8901 - val_accuracy: 0.8918\n","\n","Epoch 00002: val_loss improved from 3.80128 to 3.30343, saving model to Checkpoint.h5\n","Epoch 3/100\n","420/420 [==============================] - 320s 761ms/step - loss: 3.2984 - dice_coef: 0.8802 - accuracy: 0.8833 - val_loss: 3.0922 - val_dice_coef: 0.8954 - val_accuracy: 0.8983\n","\n","Epoch 00003: val_loss improved from 3.30343 to 3.09219, saving model to Checkpoint.h5\n","Epoch 4/100\n","420/420 [==============================] - 320s 761ms/step - loss: 3.0236 - dice_coef: 0.8813 - accuracy: 0.8838 - val_loss: 2.8652 - val_dice_coef: 0.8936 - val_accuracy: 0.8963\n","\n","Epoch 00004: val_loss improved from 3.09219 to 2.86517, saving model to Checkpoint.h5\n","Epoch 5/100\n","420/420 [==============================] - 319s 761ms/step - loss: 2.7734 - dice_coef: 0.8831 - accuracy: 0.8852 - val_loss: 2.6649 - val_dice_coef: 0.8695 - val_accuracy: 0.8703\n","\n","Epoch 00005: val_loss improved from 2.86517 to 2.66494, saving model to Checkpoint.h5\n","Epoch 6/100\n","420/420 [==============================] - 319s 761ms/step - loss: 2.5207 - dice_coef: 0.8888 - accuracy: 0.8908 - val_loss: 2.5233 - val_dice_coef: 0.8866 - val_accuracy: 0.8883\n","\n","Epoch 00006: val_loss improved from 2.66494 to 2.52334, saving model to Checkpoint.h5\n","Epoch 7/100\n","420/420 [==============================] - 319s 760ms/step - loss: 2.3130 - dice_coef: 0.8894 - accuracy: 0.8910 - val_loss: 2.2689 - val_dice_coef: 0.8716 - val_accuracy: 0.8718\n","\n","Epoch 00007: val_loss improved from 2.52334 to 2.26894, saving model to Checkpoint.h5\n","Epoch 8/100\n","420/420 [==============================] - 319s 760ms/step - loss: 2.1403 - dice_coef: 0.8897 - accuracy: 0.8913 - val_loss: 1.9487 - val_dice_coef: 0.9090 - val_accuracy: 0.9116\n","\n","Epoch 00008: val_loss improved from 2.26894 to 1.94872, saving model to Checkpoint.h5\n","Epoch 9/100\n","420/420 [==============================] - 319s 760ms/step - loss: 1.9510 - dice_coef: 0.8963 - accuracy: 0.8976 - val_loss: 1.9081 - val_dice_coef: 0.8993 - val_accuracy: 0.9015\n","\n","Epoch 00009: val_loss improved from 1.94872 to 1.90807, saving model to Checkpoint.h5\n","Epoch 10/100\n","420/420 [==============================] - 319s 760ms/step - loss: 1.8393 - dice_coef: 0.8946 - accuracy: 0.8956 - val_loss: 1.7658 - val_dice_coef: 0.8949 - val_accuracy: 0.8952\n","\n","Epoch 00010: val_loss improved from 1.90807 to 1.76577, saving model to Checkpoint.h5\n","Epoch 11/100\n","236/420 [===============>..............] - ETA: 2:12 - loss: 1.7348 - dice_coef: 0.8961 - accuracy: 0.8971"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XzwipgD8UuIy","colab_type":"code","colab":{}},"source":["def stitchMaskPatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img\n","\n","\n","def stitchImagePatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920,3])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240,:] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KNI0eyqvGcy","colab_type":"code","colab":{}},"source":["def saveNumpyOutput(mask, Patient_array,Patient_length,title,folder):\n","  idx = 0\n","  for i in range(len(Patient_length)):\n","    temp = []\n","    for j in range(Patient_length[i]):\n","      final_output = mask[idx:idx+48]\n","      idx = idx + 48\n","      final_output = stitchMaskPatches(final_output)\n","      temp.append(final_output)\n","    final_output = np.asarray(temp)\n","    np.save(folder + title + Patient_array[i], final_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NErfv7ZJ7Bxr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595563192942,"user_tz":-330,"elapsed":1094,"user":{"displayName":"Bhavishya Viswanath","photoUrl":"","userId":"05271986293024817587"}},"outputId":"d56fc693-5b9f-4982-bee2-46718d3aac23"},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/HER2/3Fold LadderNet/\"\n","model_names = os.listdir(MODELS_PATH)\n","model_names.sort()\n","model_names.pop(0)\n","print(model_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['LadderNet_HER2_0.h5', 'LadderNet_HER2_1.h5']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2bo0X0lXSwE6","colab_type":"code","colab":{}},"source":["SAVE_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/HER2/3Fold LadderNet/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-zmdlCcbBGn","colab_type":"code","colab":{}},"source":["# Axis 0 = Folds\n","# Axis 1 = Class (Membrane Nuclei Background)\n","# Axis 2 = Evaluation Technique (Precision, Recall, Dice coefficient)\n","pixEvaluationTrain = np.empty((0,3,3))\n","pixEvaluationTest = np.empty((0,3,3))\n","score = np.zeros((1,3,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wl31sylb0qvs","colab_type":"code","colab":{}},"source":["fold = 0\n","\n","for train_index, test_index in fold_split:\n","  print(\"FOLD:\",fold,\"\\tTRAIN:\", train_index, \"TEST:\", test_index)\n","  # Splitting Train and Test data\n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  train_no = [patient_no[i] for i in train_index]\n","  train_size = [size[i] for i in train_index]\n","\n","  test_no = [patient_no[i] for i in test_index]\n","  test_size = [size[i] for i in test_index]\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","\n","  convertToLabels(TrainY)\n","  convertToLabels(TestY)\n","\n","  # Loading corrosponding fold of model\n","  model = keras.models.load_model(MODELS_PATH + model_names[fold],custom_objects={ 'combined_loss': combined_loss, 'dice_coef': dice_coef })\n","\n","  # Predicting results using model\n","  trainResult = model.predict(TrainX, batch_size=8)\n","  testResult = model.predict(TestX,batch_size=8)\n","\n","  trainResult = np.argmax(trainResult,axis=-1)\n","  testResult = np.argmax(testResult,axis=-1)\n","\n","  # Obtaining pixel-wise results: Precision recall and dice coefficient\n","  # For TRAIN\n","  y_true = np.reshape(TrainY,(-1))\n","  y_pred = np.reshape(trainResult,(-1))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(3):\n","    score[0][i][0] = prec[2-i]\n","    score[0][i][1] = recall[2-i]\n","    score[0][i][2] = dice[2-i]\n","\n","  pixEvaluationTrain = np.append(pixEvaluationTrain,score,axis=0)\n"," \n","  # For TEST\n","  y_true = np.reshape(TestY,(-1))\n","  y_pred = np.reshape(testResult,(-1))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(3):\n","    score[0][i][0] = prec[2-i]\n","    score[0][i][1] = recall[2-i]\n","    score[0][i][2] = dice[2-i]\n","\n","  pixEvaluationTest = np.append(pixEvaluationTest,score,axis=0)\n","\n","  # Converting predicted labels to required output format\n","  convertFromLabels(trainResult)\n","  convertFromLabels(testResult)\n","\n","  # Saving numpy arrays\n","  path = os.path.join(SAVE_PATH,\"Fold \" + str(fold))\n","  os.mkdir(path)\n","  os.mkdir(path + '/Train')\n","  os.mkdir(path + '/Test')\n","\n","  saveNumpyOutput(trainResult, train_no, train_size,\"/Train/\",path)\n","  saveNumpyOutput(testResult, test_no, test_size,\"/Test/\",path)\n","\n","  fold +=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeQAQsZexovM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595564372756,"user_tz":-330,"elapsed":1107,"user":{"displayName":"Bhavishya Viswanath","photoUrl":"","userId":"05271986293024817587"}},"outputId":"99969621-1e5c-4ba8-bcaf-78d7cad8e967"},"source":["print(pixEvaluationTrain.shape)\n","print(pixEvaluationTest.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2, 3, 3)\n","(2, 3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q9Z7ZVvgpEYc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1595564376917,"user_tz":-330,"elapsed":1091,"user":{"displayName":"Bhavishya Viswanath","photoUrl":"","userId":"05271986293024817587"}},"outputId":"7b937e86-2227-4877-c385-c94368e85d00"},"source":["print(pixEvaluationTest)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[[0.97970822 0.86456187 0.91854048]\n","  [0.74876641 0.54365218 0.62993289]\n","  [0.86160267 0.94738236 0.90245874]]\n","\n"," [[0.96148832 0.99157845 0.97630159]\n","  [0.78987302 0.70201292 0.74335584]\n","  [0.93285643 0.94732193 0.94003353]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBNZbrAiyEhO","colab_type":"code","colab":{}},"source":["np.save(SAVE_PATH + \"Pixel-wise Metrics Train.npy\", pixEvaluationTrain)\n","np.save(SAVE_PATH + \"Pixel-wise Metrics Test.npy\", pixEvaluationTest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZwjDP44MUTa6","colab_type":"text"},"source":["# **DISPLAY**"]},{"cell_type":"code","metadata":{"id":"DzUOdXOKU2nb","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","\n","plt.figure(figsize=(20,20))\n","id = 48   # enter between 0- 50 since there are 5 patients with 10 images each\n","\n","id = id * 48\n","final_input = TestX[id:id+48]\n","Mask_input = TestGT[id:id+48]\n","final_output = testResult[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","final_output = stitchMaskPatches(final_output)\n","\n","print(final_input.shape)\n","print(final_output.shape)\n","print(Mask_input.shape)\n","\n","print(np.unique(final_output))\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","plt.subplot(132).imshow(Mask_input,'gray')\n","plt.subplot(133).imshow(final_output,'gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5IqVx01JeWn","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","\n","plt.figure(figsize=(20,20))\n","id = 25  # enter between 0- 40 since there are 4 patients with 10 images each\n","\n","id = id * 48\n","final_input = TrainX[id:id+48]\n","Mask_input = TrainGT[id:id+48]\n","final_output = trainResult[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","final_output = stitchMaskPatches(final_output)\n","\n","print(final_input.shape)\n","print(final_output.shape)\n","print(Mask_input.shape)\n","\n","print(np.unique(final_output))\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","plt.subplot(132).imshow(Mask_input,'gray')\n","plt.subplot(133).imshow(final_output,'gray')"],"execution_count":null,"outputs":[]}]}