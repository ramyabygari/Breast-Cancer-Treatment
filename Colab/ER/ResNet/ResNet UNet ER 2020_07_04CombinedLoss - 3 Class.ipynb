{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet UNet ER 2020_07_04CombinedLoss - 3 Class.ipynb","provenance":[{"file_id":"1G6TGq3e2l8kzc-PH5w6M67cFZBGmr3tl","timestamp":1584527523476},{"file_id":"1upJavTPxjBOHZ7_OSFcmAHC_TkFWyKni","timestamp":1584169574863},{"file_id":"1txy9g7gYnELmPTY6sT4JtfbhwQthIyoG","timestamp":1583898230224},{"file_id":"1a9BwVwMfQ4iFdte5xgs4kzj58JNqs4Vu","timestamp":1579539718864},{"file_id":"1KyLESiefS0uSAi_kTOAZ9NmNUSYTs9lL","timestamp":1578995412588},{"file_id":"1YDTADQrLw8-aYCSjOEYxDuIB1nuy3Xzm","timestamp":1577686452735},{"file_id":"1DqrMpMvIbzPtWFjsL_eNwrVM-xaFvx6c","timestamp":1571727299009}],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ixvBWa23MB7e","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pZLOIrcO8eM","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import numpy as np\n","!pip install -U keras\n","!pip install tensorflow-gpu==2.1.0rc0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lqf9hr1JcaqT","colab_type":"code","colab":{}},"source":["from keras.layers import Activation,Conv2D,MaxPooling2D,UpSampling2D,Dense,BatchNormalization,Input,Reshape,multiply,add,Dropout,AveragePooling2D,GlobalAveragePooling2D,concatenate\n","from keras.layers.convolutional import Conv2DTranspose\n","from keras.models import Model\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n","import keras.backend as K\n","from keras.regularizers import l2\n","from keras.engine import Layer,InputSpec\n","from keras.utils import conv_utils\n","from keras.layers import Activation,Conv2D,MaxPooling2D,UpSampling2D,Dense,BatchNormalization,Input,Reshape,multiply,add,Dropout,AveragePooling2D,GlobalAveragePooling2D,concatenate, Add\n","from keras.layers.convolutional import Conv2DTranspose\n","from keras.models import Model\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n","import keras.backend as K\n","from keras.regularizers import l2\n","from keras.engine import Layer,InputSpec\n","from keras.utils import conv_utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HeDNRPFoc2Gl","colab_type":"code","colab":{}},"source":["def BatchActivate(x):\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    return x\n","\n","def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    if activation == True:\n","        x = BatchActivate(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16, batch_activate = False):\n","    x = BatchActivate(blockInput)\n","    x = convolution_block(x, num_filters, (3,3) )\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    if batch_activate:\n","        x = BatchActivate(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1mVVOTKgfe0","colab_type":"code","colab":{}},"source":["# Build model\n","def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n","    # 240 -> 120\n","    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n","    conv1 = residual_block(conv1,start_neurons * 1)\n","    conv1 = residual_block(conv1,start_neurons * 1, True)\n","    pool1 = MaxPooling2D((2, 2))(conv1)\n","    pool1 = Dropout(DropoutRatio/2)(pool1)\n","\n","    # 120 -> 60\n","    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n","    conv2 = residual_block(conv2,start_neurons * 2)\n","    conv2 = residual_block(conv2,start_neurons * 2, True)\n","    pool2 = MaxPooling2D((2, 2))(conv2)\n","    pool2 = Dropout(DropoutRatio)(pool2)\n","\n","    # 60 -> 30\n","    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n","    conv3 = residual_block(conv3,start_neurons * 4)\n","    conv3 = residual_block(conv3,start_neurons * 4, True)\n","    pool3 = MaxPooling2D((2, 2))(conv3)\n","    pool3 = Dropout(DropoutRatio)(pool3)\n","\n","    # 30 -> 15\n","    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n","    conv4 = residual_block(conv4,start_neurons * 8)\n","    conv4 = residual_block(conv4,start_neurons * 8, True)\n","    pool4 = MaxPooling2D((2, 2))(conv4)\n","    pool4 = Dropout(DropoutRatio)(pool4)\n","\n","    # Middle\n","    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n","    convm = residual_block(convm,start_neurons * 16)\n","    convm = residual_block(convm,start_neurons * 16, True)\n","    \n","    # 15 -> 30\n","    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","    uconv4 = concatenate([deconv4, conv4])\n","    uconv4 = Dropout(DropoutRatio)(uconv4)\n","    \n","    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n","    uconv4 = residual_block(uconv4,start_neurons * 8)\n","    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n","    \n","    # 30 -> 60\n","    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    uconv3 = concatenate([deconv3, conv3])    \n","    uconv3 = Dropout(DropoutRatio)(uconv3)\n","    \n","    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n","    uconv3 = residual_block(uconv3,start_neurons * 4)\n","    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n","\n","    # 60 -> 120\n","    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","    uconv2 = concatenate([deconv2, conv2])\n","        \n","    uconv2 = Dropout(DropoutRatio)(uconv2)\n","    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n","    \n","    # 120 -> 240\n","    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    uconv1 = concatenate([deconv1, conv1])\n","    \n","    uconv1 = Dropout(DropoutRatio)(uconv1)\n","    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n","    \n","    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n","    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n","    output_layer_noActi = Conv2D(3, (1,1), padding=\"same\", activation=None)(uconv1)\n","    output_layer =  Activation('sigmoid')(output_layer_noActi)\n","    \n","    return output_layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wsz32rVueBed","colab_type":"code","outputId":"b8a5e69a-e524-484c-c529-8be36bdb8bd2","executionInfo":{"status":"ok","timestamp":1586268576501,"user_tz":-330,"elapsed":11658,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["input_layer = Input(shape=(240,240,3))\n","output_layer = build_model(input_layer, 16,0.5)\n","model = Model(input_layer, output_layer)\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 240, 240, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 240, 240, 16) 448         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 240, 240, 16) 64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 240, 240, 16) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 240, 240, 16) 2320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 240, 240, 16) 64          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 240, 240, 16) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 240, 240, 16) 2320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 240, 240, 16) 0           conv2d_3[0][0]                   \n","                                                                 conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 240, 240, 16) 64          add_1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 240, 240, 16) 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 240, 240, 16) 2320        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 240, 240, 16) 64          conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 240, 240, 16) 0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 240, 240, 16) 2320        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 240, 240, 16) 0           conv2d_5[0][0]                   \n","                                                                 add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 240, 240, 16) 64          add_2[0][0]                      \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 240, 240, 16) 0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 120, 120, 16) 0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 120, 120, 16) 0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 120, 120, 32) 4640        dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 120, 120, 32) 128         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 120, 120, 32) 0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 120, 120, 32) 9248        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 120, 120, 32) 128         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 120, 120, 32) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 120, 120, 32) 9248        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 120, 120, 32) 0           conv2d_8[0][0]                   \n","                                                                 conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 120, 120, 32) 128         add_3[0][0]                      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 120, 120, 32) 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 120, 120, 32) 9248        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 120, 120, 32) 128         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 120, 120, 32) 0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 120, 120, 32) 9248        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 120, 120, 32) 0           conv2d_10[0][0]                  \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 120, 120, 32) 128         add_4[0][0]                      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 120, 120, 32) 0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 60, 60, 32)   0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 60, 60, 32)   0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 60, 60, 64)   18496       dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 60, 60, 64)   256         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 60, 60, 64)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 60, 60, 64)   36928       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 60, 60, 64)   256         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 60, 60, 64)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 60, 60, 64)   36928       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 60, 60, 64)   0           conv2d_13[0][0]                  \n","                                                                 conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 60, 60, 64)   256         add_5[0][0]                      \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 60, 60, 64)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 60, 60, 64)   36928       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 60, 60, 64)   256         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 60, 60, 64)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 60, 60, 64)   36928       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 60, 60, 64)   0           conv2d_15[0][0]                  \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 60, 60, 64)   256         add_6[0][0]                      \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 60, 60, 64)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 30, 30, 64)   0           activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 30, 30, 64)   0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 30, 30, 128)  73856       dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 30, 30, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 30, 30, 128)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 30, 30, 128)  147584      activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 30, 30, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 30, 30, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 30, 30, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 30, 30, 128)  0           conv2d_18[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 30, 30, 128)  512         add_7[0][0]                      \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 30, 30, 128)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 30, 30, 128)  147584      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 30, 30, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 30, 30, 128)  0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 30, 30, 128)  147584      activation_19[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 30, 30, 128)  0           conv2d_20[0][0]                  \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 30, 30, 128)  512         add_8[0][0]                      \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 30, 30, 128)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 128)  0           activation_20[0][0]              \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 15, 15, 128)  0           max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 15, 15, 256)  295168      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 15, 15, 256)  1024        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 15, 15, 256)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 15, 15, 256)  590080      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 15, 15, 256)  1024        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 15, 15, 256)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 15, 15, 256)  590080      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 15, 15, 256)  0           conv2d_23[0][0]                  \n","                                                                 conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 15, 15, 256)  1024        add_9[0][0]                      \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 15, 15, 256)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 15, 15, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 15, 15, 256)  1024        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 15, 15, 256)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 15, 15, 256)  590080      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 15, 15, 256)  0           conv2d_25[0][0]                  \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 15, 15, 256)  1024        add_10[0][0]                     \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 15, 15, 256)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 30, 30, 128)  295040      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 30, 30, 256)  0           conv2d_transpose_1[0][0]         \n","                                                                 activation_20[0][0]              \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 30, 30, 256)  0           concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 30, 30, 128)  295040      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 30, 30, 128)  512         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 30, 30, 128)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 30, 30, 128)  147584      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 30, 30, 128)  512         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 30, 30, 128)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 30, 30, 128)  147584      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 30, 30, 128)  0           conv2d_28[0][0]                  \n","                                                                 conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 30, 30, 128)  512         add_11[0][0]                     \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 30, 30, 128)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 30, 30, 128)  147584      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 30, 30, 128)  512         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 30, 30, 128)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 30, 30, 128)  147584      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 30, 30, 128)  0           conv2d_30[0][0]                  \n","                                                                 add_11[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 30, 30, 128)  512         add_12[0][0]                     \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 30, 30, 128)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 60, 60, 64)   73792       activation_30[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 60, 60, 128)  0           conv2d_transpose_2[0][0]         \n","                                                                 activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 60, 60, 128)  0           concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 60, 60, 64)   73792       dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 60, 60, 64)   256         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 60, 60, 64)   0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 60, 60, 64)   36928       activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 60, 60, 64)   256         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 60, 60, 64)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 60, 60, 64)   36928       activation_32[0][0]              \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 60, 60, 64)   0           conv2d_33[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 60, 60, 64)   256         add_13[0][0]                     \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 60, 60, 64)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 60, 60, 64)   36928       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 60, 60, 64)   256         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 60, 60, 64)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 60, 60, 64)   36928       activation_34[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 60, 60, 64)   0           conv2d_35[0][0]                  \n","                                                                 add_13[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 60, 60, 64)   256         add_14[0][0]                     \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 60, 60, 64)   0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 120, 120, 32) 18464       activation_35[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 120, 120, 64) 0           conv2d_transpose_3[0][0]         \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 120, 120, 64) 0           concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 120, 120, 32) 18464       dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 120, 120, 32) 128         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 120, 120, 32) 0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 120, 120, 32) 9248        activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 120, 120, 32) 128         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 120, 120, 32) 0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 120, 120, 32) 9248        activation_37[0][0]              \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 120, 120, 32) 0           conv2d_38[0][0]                  \n","                                                                 conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 120, 120, 32) 128         add_15[0][0]                     \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 120, 120, 32) 0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 120, 120, 32) 9248        activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 120, 120, 32) 128         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 120, 120, 32) 0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 120, 120, 32) 9248        activation_39[0][0]              \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 120, 120, 32) 0           conv2d_40[0][0]                  \n","                                                                 add_15[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 120, 120, 32) 128         add_16[0][0]                     \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 120, 120, 32) 0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_4 (Conv2DTrans (None, 240, 240, 16) 4624        activation_40[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 240, 240, 32) 0           conv2d_transpose_4[0][0]         \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 240, 240, 32) 0           concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 240, 240, 16) 4624        dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 240, 240, 16) 64          conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 240, 240, 16) 0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 240, 240, 16) 2320        activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 240, 240, 16) 64          conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 240, 240, 16) 0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 240, 240, 16) 2320        activation_42[0][0]              \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 240, 240, 16) 0           conv2d_43[0][0]                  \n","                                                                 conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 240, 240, 16) 64          add_17[0][0]                     \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 240, 240, 16) 0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 240, 240, 16) 2320        activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 240, 240, 16) 64          conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 240, 240, 16) 0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 240, 240, 16) 2320        activation_44[0][0]              \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 240, 240, 16) 0           conv2d_45[0][0]                  \n","                                                                 add_17[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 240, 240, 16) 64          add_18[0][0]                     \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 240, 240, 16) 0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 240, 240, 3)  51          activation_45[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 240, 240, 3)  0           conv2d_46[0][0]                  \n","==================================================================================================\n","Total params: 5,120,179\n","Trainable params: 5,112,819\n","Non-trainable params: 7,360\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LzNbXYWE4I5E","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdhsO-GqAzfp","colab_type":"code","colab":{}},"source":["# Function to convert image from greyscale to one hot (i.e. 3 channels)\n","def convertToOneHot(image):\n","    num_classes = 3\n","    shape = image.shape[:2]+(num_classes,)\n","    encoded_image = np.zeros(shape, dtype=np.uint8)\n","    for r in range(len(image)):\n","      for c in range(len(image[0])):\n","        if image[r][c]==0:\n","          encoded_image[r][c][0] = 1\n","        elif image[r][c]==128:\n","          encoded_image[r][c][1] = 1\n","        else:\n","          encoded_image[r][c][2] = 1\n","    return encoded_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iWVfAlaM-95","colab_type":"code","colab":{}},"source":["# Function to convert back from one hot image to greyscale\n","def convertFromOneHot(image):\n","    shape = image.shape[:2]\n","    encoded_image = np.zeros(shape, dtype=np.uint8)\n","    for r in range(len(image)):\n","      for c in range(len(image[0])):\n","        if image[r][c][0] == 1:\n","          encoded_image[r][c] = 0\n","        elif image[r][c][1] == 1:\n","          encoded_image[r][c] = 128\n","        else:\n","          encoded_image[r][c] = 255\n","    return encoded_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiXrY-SjvEMW","colab_type":"code","colab":{}},"source":["PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/3 Class ER\"\n","\n","# Train set patients: 230 232 239 242 \n","TrainX_1 = np.load(PATH + '/ER IHC 239 Images.npy')\n","TrainY_1 = np.load(PATH + '/ER IHC 239 Masks.npy')\n","TrainX_2 = np.load(PATH + '/ER IHC 232 Images.npy')\n","TrainY_2 = np.load(PATH + '/ER IHC 232 Masks.npy')\n","TrainX_3 = np.load(PATH + '/ER IHC 242 Images.npy')\n","TrainY_3 = np.load(PATH + '/ER IHC 242 Masks.npy')\n","TrainX_4 = np.load(PATH + '/ER IHC 230 Images.npy')\n","TrainY_4 = np.load(PATH + '/ER IHC 230 Masks.npy')\n","\n","# Test set patients: 221 246 263\n","TestX_1 = np.load(PATH + '/ER IHC 221 Images.npy')\n","TestY_1 = np.load(PATH + '/ER IHC 221 Masks.npy')\n","TestX_2 = np.load(PATH + '/ER IHC 246 Images.npy')\n","TestY_2 = np.load(PATH + '/ER IHC 246 Masks.npy')\n","TestX_3 = np.load(PATH + '/ER IHC 252 Images.npy')\n","TestY_3 = np.load(PATH + '/ER IHC 252 Masks.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugUJ-qzr6L-d","colab_type":"code","outputId":"450ee647-bc25-47b0-e914-d2b29ce09d8d","executionInfo":{"status":"ok","timestamp":1586284342127,"user_tz":-330,"elapsed":1253,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":257}},"source":["cv2_imshow(TrainY_1[2])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAADrklEQVR4nO2c25KrIBBFG+v8/y97\nHmKUUZDG0Nhs9nqYmprKGJa7uRlNEBGRVaoJ9f/yJrtheOB6xbt9JLm0PqBH4ua1EfZuHNFIeBwo\n/JBharpZwqMY/2t2pMPY9SQ1RR+OE5hCODaeQzhiEuEj4kmED2YR3iOeRXg3nkb4a5xbeASRcVZP\nOj5b/yW9LArRTxiCSK6kwUxjQqpwd99fatrhSVslmXA4mvpLox0OAEFSg9NJ8rQJqtDwGXHYf9so\nNLMmN5fGW0mbtM1hUR99+NtxS+YOU6shRIOWgcrqL+MQrbQGD0/JPGvpDQqjQ+G2+BumrRN2Z8yS\nbo23iO0TdmbcoaR9GS++mmPP4iwAc2pLevjTs9Q5DO9bmfD4vjW3PADYCldaN2AErBcG8VULo/iy\nD8OjFIapaCacBidgWQRKp8ycJT1TxJ+EJzLeSnq1/GTT1ek8tod3N3oA0WXQ8hSxThgo8MyzhylD\njLvUKi7xYNxv2mnh4ec8zbnSuuCnyzUnJRwsbtlqf8hnpO6m7d+KjlyFjXy9RHyZlszyXbtXTnKx\n3HGU7pxxZjsEOy2ddb/+PYV7Rpx4r8+fYBNO8Hlu6e1W2JAupsxTLQDkOs/a8jsAHJEfLFbQhG8A\nTPh+MjgJA6yjC5Pfn5JWbJPcn5HSZB8Lq2TcGxeIhJUqvo2Lq7kHo7Rv4xJPpqWhjaebh8GEyxuy\nSNjLRRhb4oQdPgzanszXWuCy/BlzbSO2P7eK9ofTy1SNenhebIWVjXo0Su8tt/iM4iHaEJ5tD/14\nbuhrbhGj5oee6Vf0MauFh7sa+LKIWLSur2/NIHpKuFFDk4ex+9Sq5sWfQcttAban3+bBR8CmVy2T\n39X1NsaXaf31FZOS9qd5AHYBoAyF0flV2MF+qa4FvyfsQLmGFiV9Nu59Bqrer1XjohXGC4m/sD18\nt64rulXDhq6tD/jo/UuMNeLcohMGmod12QEJ64yRhFVQGB0Ko0NhdCg8MpqVB5SwxhhLWAGYcDli\nMOGyMdB++Mv9vhgtYSllCCh8b4wofGsMKXxnjCl8A6hwPmJQ4TwURofCGOSXl6DCeSiMDoXRoTA6\nFEaHwuhQGANe8dhBFc5GjCqcBVY4FzGscA5c4UzEuMIZY2Dhzg/1OuFy+RI5YZFEoOjCF2N44bMx\nvvDJGH3Q2jjGrkmEZXeeR1g8fiOBPTM6E0IIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEII\nIYQQQgghhLzAf7qybWngaivpAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=L size=240x240 at 0x7F77142E1080>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"rez3-E-Wg3tV","colab_type":"code","outputId":"957fdd3c-eba4-4f6d-f80e-6b77dc577a0f","executionInfo":{"status":"ok","timestamp":1586180092989,"user_tz":-330,"elapsed":30273,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["TrainX_3.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(480, 240, 240, 3)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"FAF_4OPawvpc","colab_type":"code","outputId":"43cfe06f-a86c-43be-ebea-964f85828881","executionInfo":{"status":"ok","timestamp":1586283487495,"user_tz":-330,"elapsed":238934,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["TrainX = np.concatenate((TrainX_1, TrainX_2, TrainX_3, TrainX_4), axis=0)\n","TrainGroundTruth = np.concatenate((TrainY_1, TrainY_2, TrainY_3, TrainY_4), axis=0)\n","TrainY = []\n","\n","for img in TrainGroundTruth:\n","  encoded_img = convertToOneHot(img)\n","  TrainY.append(encoded_img)\n","\n","TrainY = np.asarray(TrainY)\n","\n","TestX = np.concatenate((TestX_1, TestX_2, TestX_3), axis=0)\n","TestGroundTruth = np.concatenate((TestY_1, TestY_2, TestY_3), axis=0)\n","TestY = []\n","\n","for img in TestGroundTruth:\n","  encoded_img = convertToOneHot(img)\n","  TestY.append(encoded_img)\n","\n","TestY = np.asarray(TestY)\n","\n","ValidX = TrainX[1800:, : ]\n","ValidY = TrainY[1800:, : ]\n","\n","TrainX = TrainX[0:1800, : ]\n","TrainY = TrainY[0:1800, : ]\n","\n","print(TrainX.shape)\n","print(TrainY.shape)\n","print(TestX.shape)\n","print(TestY.shape)\n","print(ValidX.shape)\n","print(ValidY.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1800, 240, 240, 3)\n","(1800, 240, 240, 3)\n","(1440, 240, 240, 3)\n","(1440, 240, 240, 3)\n","(120, 240, 240, 3)\n","(120, 240, 240, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HjHNZ_ZfMB8K","colab_type":"code","colab":{}},"source":["TrainX = np.reshape(TrainX,(-1,240, 240,3))\n","TrainY = np.reshape(TrainY,(-1,240, 240,3))\n","\n","TrainX = TrainX.astype('float32')/255\n","\n","TestX = np.reshape(TestX,(-1,240, 240,3))\n","TestY = np.reshape(TestY,(-1,240, 240,3))\n","\n","TestX = TestX.astype('float32')/255\n","\n","ValidX = np.reshape(ValidX,(-1,240, 240,3))\n","ValidY = np.reshape(ValidY,(-1,240, 240,3))\n","\n","ValidX = ValidX.astype('float32')/255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FG7FXY3fMB8P","colab_type":"code","outputId":"38db0236-bb67-45f5-b667-9d556aaa538b","executionInfo":{"status":"ok","timestamp":1586283488270,"user_tz":-330,"elapsed":235820,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["print(TrainX.shape)\n","print(TrainY.shape)\n","\n","print(TestX.shape)\n","print(TestY.shape)\n","\n","print(ValidX.shape)\n","print(ValidY.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1800, 240, 240, 3)\n","(1800, 240, 240, 3)\n","(1440, 240, 240, 3)\n","(1440, 240, 240, 3)\n","(120, 240, 240, 3)\n","(120, 240, 240, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JPrbHkJDMB8e","colab_type":"code","outputId":"46d0449b-c57a-482a-e03d-1ba85e25712d","executionInfo":{"status":"ok","timestamp":1586283507925,"user_tz":-330,"elapsed":254593,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["!pip install medpy\n","from keras.layers import *\n","import keras\n","from keras.models import Sequential\n","import cv2\n","import os\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from medpy.metric import dc, precision, recall\n","from keras import Model\n","from keras.layers import (Input, Convolution2D, Activation, BatchNormalization,\n","                          merge, AveragePooling2D, GlobalAveragePooling2D,\n","                          Dense, Dropout)\n","from keras.regularizers import l2\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting medpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n","\r\u001b[K     |██▏                             | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 6.4MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.18.2)\n","Collecting SimpleITK>=1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n","\u001b[K     |████████████████████████████████| 42.5MB 72kB/s \n","\u001b[?25hBuilding wheels for collected packages: medpy\n","  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for medpy: filename=MedPy-0.4.0-cp36-cp36m-linux_x86_64.whl size=753436 sha256=0c1dafb8889414cad8805c171dfb8bc573e42acbedeb0cdccf4a5579e9adc9bf\n","  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n","Successfully built medpy\n","Installing collected packages: SimpleITK, medpy\n","Successfully installed SimpleITK-1.2.4 medpy-0.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YDodKs-AMB81","colab_type":"code","colab":{}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TH9yDcoO6Kyg","colab_type":"code","colab":{}},"source":["def tversky_loss(y_true, y_pred):\n","    alpha = 0.5\n","    beta  = 0.5\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def combined_loss(y_true, y_pred):\n","  return (1*K.categorical_crossentropy(y_true, y_pred))+(0.5*tversky_loss(y_true, y_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMnXb4wMMB88","colab_type":"code","colab":{}},"source":["import math\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n","mc = ModelCheckpoint('Checkpoint.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyEYstIcMB9B","colab_type":"code","colab":{}},"source":["optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIzmCHVMMB9I","colab_type":"code","outputId":"697d602b-d2c3-45c0-97f4-b0301c624fd0","executionInfo":{"status":"ok","timestamp":1586269128547,"user_tz":-330,"elapsed":2002,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["from keras import backend as K      \n","model.compile(loss=combined_loss, optimizer=optimizer, metrics=[dice_coef,'accuracy',tversky_loss])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cW1V8Wi0ZErc","colab_type":"code","outputId":"c9ac8d62-ced5-43fc-da5a-0e6423b00b91","executionInfo":{"status":"ok","timestamp":1586272006286,"user_tz":-330,"elapsed":1047360,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["num_epoch = 100;\n","MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/3 Class/ER\"\n","history = model.fit(TrainX, TrainY, epochs=num_epoch, validation_data=(ValidX, ValidY), shuffle=True,batch_size=4,callbacks=[es,mc])\n","model.save(MODELS_PATH + '/20_04_05_ResNet.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 1800 samples, validate on 120 samples\n","Epoch 1/100\n","1800/1800 [==============================] - 62s 35ms/step - loss: 1.2044 - dice_coef: 0.7283 - acc: 0.8981 - tversky_loss: 1.4600 - val_loss: 1.0056 - val_dice_coef: 0.9357 - val_acc: 0.9900 - val_tversky_loss: 1.8532\n","\n","Epoch 00001: val_loss improved from inf to 1.00564, saving model to Checkpoint.h5\n","Epoch 2/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.6970 - dice_coef: 0.8946 - acc: 0.9291 - tversky_loss: 0.9885 - val_loss: 1.0544 - val_dice_coef: 0.9870 - val_acc: 0.9885 - val_tversky_loss: 1.9792\n","\n","Epoch 00002: val_loss did not improve from 1.00564\n","Epoch 3/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.6303 - dice_coef: 0.9136 - acc: 0.9329 - tversky_loss: 0.8871 - val_loss: 0.9860 - val_dice_coef: 0.9841 - val_acc: 0.9896 - val_tversky_loss: 1.8803\n","\n","Epoch 00003: val_loss improved from 1.00564 to 0.98596, saving model to Checkpoint.h5\n","Epoch 4/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.6118 - dice_coef: 0.9196 - acc: 0.9358 - tversky_loss: 0.8702 - val_loss: 0.9060 - val_dice_coef: 0.9714 - val_acc: 0.9826 - val_tversky_loss: 1.7262\n","\n","Epoch 00004: val_loss improved from 0.98596 to 0.90598, saving model to Checkpoint.h5\n","Epoch 5/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5998 - dice_coef: 0.9232 - acc: 0.9378 - tversky_loss: 0.8558 - val_loss: 0.9658 - val_dice_coef: 0.9880 - val_acc: 0.9901 - val_tversky_loss: 1.8397\n","\n","Epoch 00005: val_loss did not improve from 0.90598\n","Epoch 6/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5820 - dice_coef: 0.9248 - acc: 0.9384 - tversky_loss: 0.8224 - val_loss: 0.9061 - val_dice_coef: 0.9744 - val_acc: 0.9842 - val_tversky_loss: 1.7205\n","\n","Epoch 00006: val_loss did not improve from 0.90598\n","Epoch 7/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5925 - dice_coef: 0.9264 - acc: 0.9397 - tversky_loss: 0.8473 - val_loss: 0.8856 - val_dice_coef: 0.9845 - val_acc: 0.9901 - val_tversky_loss: 1.7112\n","\n","Epoch 00007: val_loss improved from 0.90598 to 0.88559, saving model to Checkpoint.h5\n","Epoch 8/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5770 - dice_coef: 0.9275 - acc: 0.9405 - tversky_loss: 0.8237 - val_loss: 0.8957 - val_dice_coef: 0.9887 - val_acc: 0.9908 - val_tversky_loss: 1.7261\n","\n","Epoch 00008: val_loss did not improve from 0.88559\n","Epoch 9/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5696 - dice_coef: 0.9277 - acc: 0.9403 - tversky_loss: 0.8089 - val_loss: 0.8707 - val_dice_coef: 0.9855 - val_acc: 0.9901 - val_tversky_loss: 1.6811\n","\n","Epoch 00009: val_loss improved from 0.88559 to 0.87068, saving model to Checkpoint.h5\n","Epoch 10/100\n","1800/1800 [==============================] - 45s 25ms/step - loss: 0.5632 - dice_coef: 0.9294 - acc: 0.9411 - tversky_loss: 0.8025 - val_loss: 0.8593 - val_dice_coef: 0.9869 - val_acc: 0.9902 - val_tversky_loss: 1.6656\n","\n","Epoch 00010: val_loss improved from 0.87068 to 0.85934, saving model to Checkpoint.h5\n","Epoch 11/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5615 - dice_coef: 0.9300 - acc: 0.9418 - tversky_loss: 0.8035 - val_loss: 0.8805 - val_dice_coef: 0.9805 - val_acc: 0.9871 - val_tversky_loss: 1.6951\n","\n","Epoch 00011: val_loss did not improve from 0.85934\n","Epoch 12/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5505 - dice_coef: 0.9309 - acc: 0.9425 - tversky_loss: 0.7836 - val_loss: 0.8647 - val_dice_coef: 0.9844 - val_acc: 0.9874 - val_tversky_loss: 1.6679\n","\n","Epoch 00012: val_loss did not improve from 0.85934\n","Epoch 13/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5593 - dice_coef: 0.9314 - acc: 0.9427 - tversky_loss: 0.8050 - val_loss: 0.8655 - val_dice_coef: 0.9883 - val_acc: 0.9903 - val_tversky_loss: 1.6744\n","\n","Epoch 00013: val_loss did not improve from 0.85934\n","Epoch 14/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5681 - dice_coef: 0.9309 - acc: 0.9423 - tversky_loss: 0.8193 - val_loss: 0.8591 - val_dice_coef: 0.9889 - val_acc: 0.9903 - val_tversky_loss: 1.6583\n","\n","Epoch 00014: val_loss improved from 0.85934 to 0.85915, saving model to Checkpoint.h5\n","Epoch 15/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5605 - dice_coef: 0.9313 - acc: 0.9425 - tversky_loss: 0.8071 - val_loss: 0.9121 - val_dice_coef: 0.9897 - val_acc: 0.9905 - val_tversky_loss: 1.7402\n","\n","Epoch 00015: val_loss did not improve from 0.85915\n","Epoch 16/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5621 - dice_coef: 0.9315 - acc: 0.9422 - tversky_loss: 0.8070 - val_loss: 0.8547 - val_dice_coef: 0.9878 - val_acc: 0.9898 - val_tversky_loss: 1.6567\n","\n","Epoch 00016: val_loss improved from 0.85915 to 0.85468, saving model to Checkpoint.h5\n","Epoch 17/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5339 - dice_coef: 0.9336 - acc: 0.9442 - tversky_loss: 0.7604 - val_loss: 0.9214 - val_dice_coef: 0.9896 - val_acc: 0.9905 - val_tversky_loss: 1.7595\n","\n","Epoch 00017: val_loss did not improve from 0.85468\n","Epoch 18/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5434 - dice_coef: 0.9333 - acc: 0.9437 - tversky_loss: 0.7772 - val_loss: 1.0138 - val_dice_coef: 0.9894 - val_acc: 0.9898 - val_tversky_loss: 1.8952\n","\n","Epoch 00018: val_loss did not improve from 0.85468\n","Epoch 19/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5417 - dice_coef: 0.9339 - acc: 0.9445 - tversky_loss: 0.7791 - val_loss: 0.8778 - val_dice_coef: 0.9876 - val_acc: 0.9911 - val_tversky_loss: 1.6991\n","\n","Epoch 00019: val_loss did not improve from 0.85468\n","Epoch 20/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5455 - dice_coef: 0.9332 - acc: 0.9434 - tversky_loss: 0.7811 - val_loss: 0.8779 - val_dice_coef: 0.9891 - val_acc: 0.9906 - val_tversky_loss: 1.6948\n","\n","Epoch 00020: val_loss did not improve from 0.85468\n","Epoch 21/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5392 - dice_coef: 0.9346 - acc: 0.9448 - tversky_loss: 0.7763 - val_loss: 0.9086 - val_dice_coef: 0.9897 - val_acc: 0.9907 - val_tversky_loss: 1.7416\n","\n","Epoch 00021: val_loss did not improve from 0.85468\n","Epoch 22/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5268 - dice_coef: 0.9356 - acc: 0.9454 - tversky_loss: 0.7527 - val_loss: 0.8647 - val_dice_coef: 0.9890 - val_acc: 0.9912 - val_tversky_loss: 1.6742\n","\n","Epoch 00022: val_loss did not improve from 0.85468\n","Epoch 23/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5286 - dice_coef: 0.9346 - acc: 0.9448 - tversky_loss: 0.7566 - val_loss: 0.8847 - val_dice_coef: 0.9839 - val_acc: 0.9895 - val_tversky_loss: 1.7086\n","\n","Epoch 00023: val_loss did not improve from 0.85468\n","Epoch 24/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5251 - dice_coef: 0.9366 - acc: 0.9462 - tversky_loss: 0.7495 - val_loss: 0.9943 - val_dice_coef: 0.9895 - val_acc: 0.9899 - val_tversky_loss: 1.8776\n","\n","Epoch 00024: val_loss did not improve from 0.85468\n","Epoch 25/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5359 - dice_coef: 0.9354 - acc: 0.9455 - tversky_loss: 0.7735 - val_loss: 0.8648 - val_dice_coef: 0.9852 - val_acc: 0.9881 - val_tversky_loss: 1.6729\n","\n","Epoch 00025: val_loss did not improve from 0.85468\n","Epoch 26/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5231 - dice_coef: 0.9361 - acc: 0.9459 - tversky_loss: 0.7507 - val_loss: 0.8584 - val_dice_coef: 0.9891 - val_acc: 0.9906 - val_tversky_loss: 1.6629\n","\n","Epoch 00026: val_loss did not improve from 0.85468\n","Epoch 27/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5221 - dice_coef: 0.9363 - acc: 0.9459 - tversky_loss: 0.7469 - val_loss: 0.8588 - val_dice_coef: 0.9886 - val_acc: 0.9909 - val_tversky_loss: 1.6639\n","\n","Epoch 00027: val_loss did not improve from 0.85468\n","Epoch 28/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5259 - dice_coef: 0.9354 - acc: 0.9452 - tversky_loss: 0.7538 - val_loss: 0.8803 - val_dice_coef: 0.9883 - val_acc: 0.9904 - val_tversky_loss: 1.7035\n","\n","Epoch 00028: val_loss did not improve from 0.85468\n","Epoch 29/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5171 - dice_coef: 0.9370 - acc: 0.9465 - tversky_loss: 0.7416 - val_loss: 0.9076 - val_dice_coef: 0.9902 - val_acc: 0.9909 - val_tversky_loss: 1.7335\n","\n","Epoch 00029: val_loss did not improve from 0.85468\n","Epoch 30/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5202 - dice_coef: 0.9366 - acc: 0.9461 - tversky_loss: 0.7448 - val_loss: 0.9169 - val_dice_coef: 0.9895 - val_acc: 0.9906 - val_tversky_loss: 1.7503\n","\n","Epoch 00030: val_loss did not improve from 0.85468\n","Epoch 31/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5204 - dice_coef: 0.9368 - acc: 0.9464 - tversky_loss: 0.7469 - val_loss: 0.9931 - val_dice_coef: 0.9895 - val_acc: 0.9899 - val_tversky_loss: 1.8652\n","\n","Epoch 00031: val_loss did not improve from 0.85468\n","Epoch 32/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5138 - dice_coef: 0.9367 - acc: 0.9466 - tversky_loss: 0.7389 - val_loss: 0.8772 - val_dice_coef: 0.9900 - val_acc: 0.9910 - val_tversky_loss: 1.6929\n","\n","Epoch 00032: val_loss did not improve from 0.85468\n","Epoch 33/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5165 - dice_coef: 0.9380 - acc: 0.9474 - tversky_loss: 0.7433 - val_loss: 0.8631 - val_dice_coef: 0.9902 - val_acc: 0.9913 - val_tversky_loss: 1.6680\n","\n","Epoch 00033: val_loss did not improve from 0.85468\n","Epoch 34/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5196 - dice_coef: 0.9383 - acc: 0.9476 - tversky_loss: 0.7499 - val_loss: 0.8405 - val_dice_coef: 0.9891 - val_acc: 0.9907 - val_tversky_loss: 1.6319\n","\n","Epoch 00034: val_loss improved from 0.85468 to 0.84053, saving model to Checkpoint.h5\n","Epoch 35/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4960 - dice_coef: 0.9389 - acc: 0.9482 - tversky_loss: 0.7077 - val_loss: 0.8730 - val_dice_coef: 0.9895 - val_acc: 0.9912 - val_tversky_loss: 1.6898\n","\n","Epoch 00035: val_loss did not improve from 0.84053\n","Epoch 36/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5138 - dice_coef: 0.9383 - acc: 0.9477 - tversky_loss: 0.7411 - val_loss: 0.8652 - val_dice_coef: 0.9895 - val_acc: 0.9914 - val_tversky_loss: 1.6791\n","\n","Epoch 00036: val_loss did not improve from 0.84053\n","Epoch 37/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5044 - dice_coef: 0.9383 - acc: 0.9473 - tversky_loss: 0.7179 - val_loss: 0.8967 - val_dice_coef: 0.9895 - val_acc: 0.9909 - val_tversky_loss: 1.7276\n","\n","Epoch 00037: val_loss did not improve from 0.84053\n","Epoch 38/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5017 - dice_coef: 0.9385 - acc: 0.9478 - tversky_loss: 0.7176 - val_loss: 0.8907 - val_dice_coef: 0.9904 - val_acc: 0.9911 - val_tversky_loss: 1.7090\n","\n","Epoch 00038: val_loss did not improve from 0.84053\n","Epoch 39/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5251 - dice_coef: 0.9384 - acc: 0.9477 - tversky_loss: 0.7656 - val_loss: 0.8531 - val_dice_coef: 0.9899 - val_acc: 0.9911 - val_tversky_loss: 1.6543\n","\n","Epoch 00039: val_loss did not improve from 0.84053\n","Epoch 40/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5048 - dice_coef: 0.9399 - acc: 0.9488 - tversky_loss: 0.7267 - val_loss: 0.8649 - val_dice_coef: 0.9895 - val_acc: 0.9910 - val_tversky_loss: 1.6778\n","\n","Epoch 00040: val_loss did not improve from 0.84053\n","Epoch 41/100\n","1800/1800 [==============================] - 44s 25ms/step - loss: 0.5163 - dice_coef: 0.9382 - acc: 0.9474 - tversky_loss: 0.7508 - val_loss: 0.8754 - val_dice_coef: 0.9894 - val_acc: 0.9909 - val_tversky_loss: 1.6915\n","\n","Epoch 00041: val_loss did not improve from 0.84053\n","Epoch 42/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5091 - dice_coef: 0.9396 - acc: 0.9485 - tversky_loss: 0.7393 - val_loss: 0.8892 - val_dice_coef: 0.9900 - val_acc: 0.9911 - val_tversky_loss: 1.7104\n","\n","Epoch 00042: val_loss did not improve from 0.84053\n","Epoch 43/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4929 - dice_coef: 0.9390 - acc: 0.9484 - tversky_loss: 0.7046 - val_loss: 0.8859 - val_dice_coef: 0.9898 - val_acc: 0.9910 - val_tversky_loss: 1.7030\n","\n","Epoch 00043: val_loss did not improve from 0.84053\n","Epoch 44/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5094 - dice_coef: 0.9395 - acc: 0.9485 - tversky_loss: 0.7351 - val_loss: 0.8840 - val_dice_coef: 0.9850 - val_acc: 0.9879 - val_tversky_loss: 1.7033\n","\n","Epoch 00044: val_loss did not improve from 0.84053\n","Epoch 45/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5098 - dice_coef: 0.9391 - acc: 0.9480 - tversky_loss: 0.7383 - val_loss: 0.8676 - val_dice_coef: 0.9890 - val_acc: 0.9910 - val_tversky_loss: 1.6821\n","\n","Epoch 00045: val_loss did not improve from 0.84053\n","Epoch 46/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5025 - dice_coef: 0.9395 - acc: 0.9484 - tversky_loss: 0.7241 - val_loss: 0.8612 - val_dice_coef: 0.9892 - val_acc: 0.9909 - val_tversky_loss: 1.6704\n","\n","Epoch 00046: val_loss did not improve from 0.84053\n","Epoch 47/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5199 - dice_coef: 0.9388 - acc: 0.9479 - tversky_loss: 0.7571 - val_loss: 0.8535 - val_dice_coef: 0.9880 - val_acc: 0.9904 - val_tversky_loss: 1.6571\n","\n","Epoch 00047: val_loss did not improve from 0.84053\n","Epoch 48/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5032 - dice_coef: 0.9398 - acc: 0.9488 - tversky_loss: 0.7243 - val_loss: 0.8822 - val_dice_coef: 0.9898 - val_acc: 0.9910 - val_tversky_loss: 1.7076\n","\n","Epoch 00048: val_loss did not improve from 0.84053\n","Epoch 49/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4947 - dice_coef: 0.9405 - acc: 0.9492 - tversky_loss: 0.7143 - val_loss: 0.8522 - val_dice_coef: 0.9888 - val_acc: 0.9910 - val_tversky_loss: 1.6561\n","\n","Epoch 00049: val_loss did not improve from 0.84053\n","Epoch 50/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4955 - dice_coef: 0.9380 - acc: 0.9474 - tversky_loss: 0.7039 - val_loss: 0.9266 - val_dice_coef: 0.9900 - val_acc: 0.9906 - val_tversky_loss: 1.7709\n","\n","Epoch 00050: val_loss did not improve from 0.84053\n","Epoch 51/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.5040 - dice_coef: 0.9406 - acc: 0.9493 - tversky_loss: 0.7315 - val_loss: 0.8808 - val_dice_coef: 0.9901 - val_acc: 0.9910 - val_tversky_loss: 1.6965\n","\n","Epoch 00051: val_loss did not improve from 0.84053\n","Epoch 52/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4889 - dice_coef: 0.9409 - acc: 0.9496 - tversky_loss: 0.7005 - val_loss: 0.8871 - val_dice_coef: 0.9810 - val_acc: 0.9880 - val_tversky_loss: 1.7078\n","\n","Epoch 00052: val_loss did not improve from 0.84053\n","Epoch 53/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4902 - dice_coef: 0.9411 - acc: 0.9496 - tversky_loss: 0.7025 - val_loss: 0.8654 - val_dice_coef: 0.9898 - val_acc: 0.9910 - val_tversky_loss: 1.6754\n","\n","Epoch 00053: val_loss did not improve from 0.84053\n","Epoch 54/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4969 - dice_coef: 0.9406 - acc: 0.9492 - tversky_loss: 0.7181 - val_loss: 0.9305 - val_dice_coef: 0.9892 - val_acc: 0.9904 - val_tversky_loss: 1.7800\n","\n","Epoch 00054: val_loss did not improve from 0.84053\n","Epoch 55/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4853 - dice_coef: 0.9415 - acc: 0.9502 - tversky_loss: 0.6929 - val_loss: 0.8787 - val_dice_coef: 0.9902 - val_acc: 0.9913 - val_tversky_loss: 1.6943\n","\n","Epoch 00055: val_loss did not improve from 0.84053\n","Epoch 56/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4980 - dice_coef: 0.9408 - acc: 0.9499 - tversky_loss: 0.7224 - val_loss: 0.9436 - val_dice_coef: 0.9901 - val_acc: 0.9905 - val_tversky_loss: 1.7852\n","\n","Epoch 00056: val_loss did not improve from 0.84053\n","Epoch 57/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4926 - dice_coef: 0.9410 - acc: 0.9498 - tversky_loss: 0.7106 - val_loss: 0.8636 - val_dice_coef: 0.9887 - val_acc: 0.9911 - val_tversky_loss: 1.6757\n","\n","Epoch 00057: val_loss did not improve from 0.84053\n","Epoch 58/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4729 - dice_coef: 0.9420 - acc: 0.9502 - tversky_loss: 0.6762 - val_loss: 0.8511 - val_dice_coef: 0.9893 - val_acc: 0.9910 - val_tversky_loss: 1.6520\n","\n","Epoch 00058: val_loss did not improve from 0.84053\n","Epoch 59/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4789 - dice_coef: 0.9420 - acc: 0.9504 - tversky_loss: 0.6879 - val_loss: 1.0480 - val_dice_coef: 0.9413 - val_acc: 0.9884 - val_tversky_loss: 1.8867\n","\n","Epoch 00059: val_loss did not improve from 0.84053\n","Epoch 60/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4796 - dice_coef: 0.9413 - acc: 0.9499 - tversky_loss: 0.6859 - val_loss: 0.8803 - val_dice_coef: 0.9898 - val_acc: 0.9912 - val_tversky_loss: 1.7063\n","\n","Epoch 00060: val_loss did not improve from 0.84053\n","Epoch 61/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4816 - dice_coef: 0.9421 - acc: 0.9508 - tversky_loss: 0.6935 - val_loss: 0.8922 - val_dice_coef: 0.9886 - val_acc: 0.9901 - val_tversky_loss: 1.7184\n","\n","Epoch 00061: val_loss did not improve from 0.84053\n","Epoch 62/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4803 - dice_coef: 0.9417 - acc: 0.9502 - tversky_loss: 0.6903 - val_loss: 0.9432 - val_dice_coef: 0.9901 - val_acc: 0.9905 - val_tversky_loss: 1.7950\n","\n","Epoch 00062: val_loss did not improve from 0.84053\n","Epoch 63/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4702 - dice_coef: 0.9428 - acc: 0.9513 - tversky_loss: 0.6712 - val_loss: 0.9093 - val_dice_coef: 0.9889 - val_acc: 0.9907 - val_tversky_loss: 1.7528\n","\n","Epoch 00063: val_loss did not improve from 0.84053\n","Epoch 64/100\n","1800/1800 [==============================] - 44s 24ms/step - loss: 0.4676 - dice_coef: 0.9430 - acc: 0.9511 - tversky_loss: 0.6684 - val_loss: 0.9229 - val_dice_coef: 0.9900 - val_acc: 0.9907 - val_tversky_loss: 1.7629\n","\n","Epoch 00064: val_loss did not improve from 0.84053\n","Epoch 00064: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ueu1X5gBMB9e","colab_type":"code","cellView":"both","outputId":"af639e49-0acc-4f75-f7b5-074eab5f1ad3","executionInfo":{"status":"ok","timestamp":1586272023337,"user_tz":-330,"elapsed":1756,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":296}},"source":["train_loss = history.history['loss']\n","train_acc = history.history['acc']\n","val_loss = history.history['val_loss']\n","val_acc = history.history['val_acc']\n","xc=range(len(train_loss))\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.plot(xc, train_loss)\n","plt.plot(xc, val_loss)\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend(['train','val'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f8815ad2128>"]},"metadata":{"tags":[]},"execution_count":57},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X8ZLWHNVnfRkQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"1DvY6AotMB-T","colab_type":"code","outputId":"13824fde-e272-4832-887c-b817eaec7cf1","executionInfo":{"status":"ok","timestamp":1586272027593,"user_tz":-330,"elapsed":1853,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":296}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.plot(xc, train_acc)\n","plt.plot(xc, val_acc)\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Acc\")\n","plt.legend(['train','val'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f8815b27358>"]},"metadata":{"tags":[]},"execution_count":58},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"hr402gEaf6Ix","colab_type":"code","colab":{}},"source":["# MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models\"\n","# model = keras.models.load_model(MODELS_PATH+'/UNET_ER_20_03_03_v5.h5',custom_objects={ 'combined_loss': combined_loss, 'dice_coef': dice_coef })"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAKqsYxXMB-0","colab_type":"code","colab":{}},"source":["# Function to find the most probable class of an image pixel by pixel\n","def ClassFinder(img):\n","  result = np.zeros(img.shape, dtype=np.uint8)\n","  for r in range(len(img)):\n","    for c in range(len(img[0])):\n","      idx = np.argmax(img[r][c])\n","      result[r][c][idx]=1    \n","  return result    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7ud1f_mMB_C","colab_type":"code","outputId":"b490dbe9-b6b3-4177-ee5e-6d4950167b8c","executionInfo":{"status":"ok","timestamp":1586272528134,"user_tz":-330,"elapsed":490400,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["train_result = model.predict(TrainX, batch_size=4)\n","print(np.shape(train_result))\n","trainPredict = [ ]\n","for img in train_result:\n","  img = ClassFinder(img)\n","  encoded_img = convertFromOneHot(img)\n","  trainPredict.append(encoded_img)\n","\n","predictedImages = np.asarray(trainPredict)\n","print(predictedImages.shape)\n","np.unique(predictedImages)\n","# dice = dc(train_result, TrainY)\n","# pre  = precision(train_result,TrainY)\n","# re   = recall(train_result,TrainY)\n","# print('Train dc: '  + str(dice))\n","# print('Train pre: ' + str(pre))\n","# print('Train re: '  + str(re))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1800, 240, 240, 3)\n","(1800, 240, 240)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([  0, 128, 255], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"40g1oWTtQElx","colab_type":"code","outputId":"50eea721-9487-4878-dac2-340d1d4596d1","executionInfo":{"status":"ok","timestamp":1586273176395,"user_tz":-330,"elapsed":378032,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["test_result = model.predict(TestX, batch_size=4)\n","print(np.shape(test_result))\n","\n","testPredict = [ ]\n","for img in test_result:\n","  img = ClassFinder(img)\n","  encoded_img = convertFromOneHot(img)\n","  testPredict.append(encoded_img)\n","\n","predictedImagesTest = np.asarray(testPredict)\n","print(predictedImagesTest.shape)\n","np.unique(predictedImagesTest)\n","# dice = dc(test_result, TestY)\n","# pre  = precision(test_result,TestY)\n","# re   = recall(test_result,TestY)\n","# print('Test dc: '  + str(dice))\n","# print('Test pre: ' + str(pre))\n","# print('Test re: '  + str(re))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1440, 240, 240, 3)\n","(1440, 240, 240)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([  0, 128, 255], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"cS7lN30b9oAX","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix\n","def get_confusion_matrix(Actual, Predicted):\n","  ActualY = np.reshape(Actual,(-1, Actual.shape[3]))\n","  PredY = np.reshape(Predicted,(-1, Predicted.shape[3]))\n","  matrix = confusion_matrix(ActualY.argmax(axis = 1), PredY.argmax(axis = 1))\n","  return matrix\n","\n","def get_precision(confusion_matrix):\n","  precision = np.diag(confusion_matrix) / np.sum(confusion_matrix, axis = 0)\n","  nan_indices = np.isnan(precision)\n","  precision[nan_indices] = 0\n","  return precision\n","\n","def get_recall(confusion_matrix):\n","  recall = np.diag(confusion_matrix) / np.sum(confusion_matrix, axis = 1)\n","  nan_indices = np.isnan(recall)\n","  recall[nan_indices] = 0\n","  return recall"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZF2dV0k5-JME","colab_type":"code","colab":{}},"source":["test_matrix = get_confusion_matrix(TestY, test_result)\n","train_matrix = get_confusion_matrix(TrainY, train_result)\n","print(test_matrix)\n","print(train_matrix)\n","# TestY.shape[3]\n","# test_result.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwmK9wnRueRb","colab_type":"code","colab":{}},"source":["np.unique(predictedImagesTest)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYeWreCuAD4Y","colab_type":"code","colab":{}},"source":["test_precision = get_precision(test_matrix)\n","print('Test Precision')\n","print(test_precision)\n","test_recall = get_recall(test_matrix)\n","print('Test Recall')\n","print(test_recall)\n","train_precision = get_precision(train_matrix)\n","print('Train Precision')\n","print(train_precision)\n","train_recall = get_recall(train_matrix)\n","print('Train Recall')\n","print(train_recall)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bOKLli0hBcGm","colab_type":"code","colab":{}},"source":["# weight_matrix = np.zeros((3,1))\n","# weight_matrix[0] = 0.6\n","# weight_matrix[1] = 0.2\n","# weight_matrix[2] = 0.2\n","# print(weight_matrix.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jC2VHapw-bMW","colab_type":"code","colab":{}},"source":["weight_matrix = np.zeros((3,1))\n","weight_matrix[0] = 1/3\n","weight_matrix[1] = 1/3\n","weight_matrix[2] = 1/3\n","print(weight_matrix.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PO1RA0vCHBR","colab_type":"code","colab":{}},"source":["def get_overall_precision(precision, weights):\n","  final_precision = np.dot(precision,weights)\n","  return final_precision\n","\n","def get_overall_recall(recall, weights):\n","  final_recall = np.dot(recall ,weights)\n","  return final_recall"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjZqxOX8EzbP","colab_type":"code","colab":{}},"source":["final_test_precision  = get_overall_precision(test_precision, weight_matrix)\n","final_test_recall     = get_overall_recall(test_recall, weight_matrix)\n","final_train_precision = get_overall_precision(train_precision, weight_matrix)\n","final_train_recall    = get_overall_recall(train_recall, weight_matrix)\n","print('Final Test Precision')\n","print(final_test_precision)\n","print('Final Test Recall')\n","print(final_test_recall)\n","print('Final Train Precision')\n","print(final_train_precision)\n","print('Final Train Recall')\n","print(final_train_recall)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JiGEcKllGbC6","colab_type":"code","colab":{}},"source":["from scipy.stats import hmean\n","\n","def dice_coefficient(precision, recall):\n","  return hmean(np.asarray([precision , recall]))\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGWVEIDgHD4I","colab_type":"code","colab":{}},"source":["test_dice_coeff = dice_coefficient(final_test_precision, final_test_recall)\n","print('Test Dice coeff')\n","print(test_dice_coeff)\n","\n","train_dice_coeff = dice_coefficient(final_train_precision, final_train_recall)\n","print('Train Dice coeff')\n","print(train_dice_coeff)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4ZaoO0mMoX6","colab_type":"code","colab":{}},"source":["copy1  = np.copy(TestX [250])\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","copy3 = np.reshape(copy2,(240, 240,3))\n","Img = cv2.cvtColor(copy3,cv2.COLOR_BGR2RGB)\n","\n","Mask = TestGroundTruth[250]\n","\n","Predicted_Mask = predictedImagesTest[250] \n","\n","plt.subplot(131).imshow(Img)\n","plt.subplot(132).imshow(Mask,'gray')\n","plt.subplot(133).imshow(Predicted_Mask,'gray')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XzwipgD8UuIy","colab_type":"code","colab":{}},"source":["def stitchMaskPatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img\n","\n","\n","def stitchImagePatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920,3])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240,:] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7rOZOq1M7lm","colab_type":"code","colab":{}},"source":["def saveNumpyOutput(mask):\n","  num = mask.shape[0]/480\n","  for id in range(int(num)):\n","    temp = []\n","    for i in range(id, id+10):\n","      idx = i * 48\n","      final_output = mask[idx:idx+48]\n","      final_output = stitchMaskPatches(final_output)\n","      temp.append(final_output)\n","    final_output = np.asarray(temp)\n","    np.save(\"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/ER/ResNet_3Class/Patient \" + str(id), final_output)\n","\n","NP_PATH = '/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/ER/ResNet_3Class/'\n","\n","def saveImages:\n","  files = os.listdir(NP_PATH)\n","  for i in range(len(files)):\n","    patient = np.load(files[i]) \n","    for j in range(len(patient)):\n","      cv2.imwrite('/content/drive/My Drive/Breast Cancer Treatment/Predicted Images/ER/ResNet_3Class/Patient'+i+' Img'+j.png', patient[j])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_B0gb-OQS53","colab_type":"code","colab":{}},"source":["# saving predicted outputs as numpy arrays for test images\n","saveNumpyOutput(predictedImages)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzUOdXOKU2nb","colab_type":"code","outputId":"6b66987a-45c6-40c1-e8dd-dde388c6c991","executionInfo":{"status":"error","timestamp":1586282986973,"user_tz":-330,"elapsed":3793,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"colab":{"base_uri":"https://localhost:8080/","height":303}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","plt.figure(figsize=(20,20))\n","id = 25   # enter between 0- 40 since there are 4 patients with 10 images each\n","\n","id = id * 48\n","final_input = TestX[id:id+48]\n","\n","Mask_input = TestY[id:id+48]\n","Test_Actual = [ ]\n","for img in Mask_input:\n","  img = ClassFinder(img)\n","  encoded_img = convertFromOneHot(img)\n","  Test_Actual.append(encoded_img)\n","  \n","print(Mask_input.shape)\n","Mask_input = np.asarray(Test_Actual)\n","print(Mask_input.shape)\n","\n","final_output = predictedImagesTest[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","final_output = stitchMaskPatches(final_output)\n","\n","print(final_input.shape)\n","print(final_output.shape)\n","print(Mask_input.shape)\n","\n","print(np.unique(final_output))\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","plt.subplot(132).imshow(Mask_input,'gray')\n","plt.subplot(133).imshow(final_output,'gray')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-824803c6768a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfinal_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mMask_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'TestX' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"t5IqVx01JeWn","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","\n","plt.figure(figsize=(20,20))\n","id = 2  # enter between 0- 40 since there are 4 patients with 10 images each\n","\n","id = id * 48\n","final_input = TrainX[id:id+48]\n","\n","Mask_input = TrainY[id:id+48]\n","Train_Actual = [ ]\n","for img in Mask_input:\n","#   img = ClassFinder(img)\n","  encoded_img = convertFromOneHot(img)\n","  Train_Actual.append(encoded_img)\n","  \n","print(Mask_input.shape)\n","Mask_input = np.asarray(Train_Actual)\n","print(Mask_input.shape)\n","\n","# final_output = predictedImages[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","# final_output = stitchMaskPatches(final_output)\n","\n","# print(final_input.shape)\n","# print(final_output.shape)\n","# print(Mask_input.shape)\n","\n","print(np.unique(Mask_input))\n","plt.subplot(132).imshow(Mask_input, cmap ='gray')\n","# cv2_imshow(Mask_input)\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","# plt.subplot(132).imshow(Mask_input, cmap ='gray')\n","# plt.subplot(133).imshow(final_output,'gray')\n"],"execution_count":0,"outputs":[]}]}