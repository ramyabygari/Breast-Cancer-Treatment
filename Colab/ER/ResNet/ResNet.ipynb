{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet.ipynb","provenance":[{"file_id":"1O-NVo1IydtLI_d3zSOrqO5O28xZuExcF","timestamp":1594209161448},{"file_id":"1yrzaA6g0-hX5EbB9EVCwufTXAfk2Z_M6","timestamp":1592073984971},{"file_id":"1abkYuSvojPmWb7wyA7FWLvFC15PhBNmh","timestamp":1592062059570},{"file_id":"16hqggEiNT-NR-gwzWl-JDg6OSUab1SSE","timestamp":1590932441130},{"file_id":"1dLxM_AMOSs32Mxu42FNwumVVm11sLpeG","timestamp":1589304160359},{"file_id":"17lvwlvqQV7B-wqN2ajx7Q2UwCZwCd-WD","timestamp":1586698406636},{"file_id":"1SAeOlks1aRTndKfvFcMtNB7V3Ik6nfN0","timestamp":1586361815646},{"file_id":"1puNfvA8GEtqbsfDMP30_RS6XRrNM8Ky8","timestamp":1586249758540},{"file_id":"1QPxGukBl9nFKfyxsNhM4lUw4rYauJaY1","timestamp":1586242198727},{"file_id":"1txy9g7gYnELmPTY6sT4JtfbhwQthIyoG","timestamp":1583812009231},{"file_id":"1a9BwVwMfQ4iFdte5xgs4kzj58JNqs4Vu","timestamp":1579539718864},{"file_id":"1KyLESiefS0uSAi_kTOAZ9NmNUSYTs9lL","timestamp":1578995412588},{"file_id":"1YDTADQrLw8-aYCSjOEYxDuIB1nuy3Xzm","timestamp":1577686452735},{"file_id":"1DqrMpMvIbzPtWFjsL_eNwrVM-xaFvx6c","timestamp":1571727299009}],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ixvBWa23MB7e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1594282164942,"user_tz":-330,"elapsed":19008,"user":{"displayName":"Ramya B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GieTE9FAgUSC7kmQGLqSOw7FsRQJ3KKuc3OyVfEyQ=s64","userId":"15349008009844832706"}},"outputId":"9032f352-e5c4-40dc-b090-4310ec34935a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oIbx8AsgvMB7","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzNbXYWE4I5E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594282243359,"user_tz":-330,"elapsed":2038,"user":{"displayName":"Ramya B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GieTE9FAgUSC7kmQGLqSOw7FsRQJ3KKuc3OyVfEyQ=s64","userId":"15349008009844832706"}},"outputId":"72a6a442-5759-4191-9a30-3a40e17ace0e"},"source":["import os\n","import cv2\n","import numpy as np\n","import math\n","import random\n","import keras\n","from keras.layers import *\n","from keras.models import Sequential\n","from keras import Model\n","from keras import backend as K  \n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","from sklearn import metrics"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mQ-s7ae7RPDZ","colab_type":"code","colab":{}},"source":["def BatchActivate(x):\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    return x\n","\n","def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    if activation == True:\n","        x = BatchActivate(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16, batch_activate = False):\n","    x = BatchActivate(blockInput)\n","    x = convolution_block(x, num_filters, (3,3) )\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    if batch_activate:\n","        x = BatchActivate(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1mVVOTKgfe0","colab_type":"code","colab":{}},"source":["# Build model\n","def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n","    # 240 -> 120\n","    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n","    conv1 = residual_block(conv1,start_neurons * 1)\n","    conv1 = residual_block(conv1,start_neurons * 1, True)\n","    pool1 = MaxPooling2D((2, 2))(conv1)\n","    pool1 = Dropout(DropoutRatio/2)(pool1)\n","\n","    # 120 -> 60\n","    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n","    conv2 = residual_block(conv2,start_neurons * 2)\n","    conv2 = residual_block(conv2,start_neurons * 2, True)\n","    pool2 = MaxPooling2D((2, 2))(conv2)\n","    pool2 = Dropout(DropoutRatio)(pool2)\n","\n","    # 60 -> 30\n","    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n","    conv3 = residual_block(conv3,start_neurons * 4)\n","    conv3 = residual_block(conv3,start_neurons * 4, True)\n","    pool3 = MaxPooling2D((2, 2))(conv3)\n","    pool3 = Dropout(DropoutRatio)(pool3)\n","\n","    # 30 -> 15\n","    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n","    conv4 = residual_block(conv4,start_neurons * 8)\n","    conv4 = residual_block(conv4,start_neurons * 8, True)\n","    pool4 = MaxPooling2D((2, 2))(conv4)\n","    pool4 = Dropout(DropoutRatio)(pool4)\n","\n","    # Middle\n","    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n","    convm = residual_block(convm,start_neurons * 16)\n","    convm = residual_block(convm,start_neurons * 16, True)\n","    \n","    # 15 -> 30\n","    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","    uconv4 = concatenate([deconv4, conv4])\n","    uconv4 = Dropout(DropoutRatio)(uconv4)\n","    \n","    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n","    uconv4 = residual_block(uconv4,start_neurons * 8)\n","    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n","    \n","    # 30 -> 60\n","    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    uconv3 = concatenate([deconv3, conv3])    \n","    uconv3 = Dropout(DropoutRatio)(uconv3)\n","    \n","    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n","    uconv3 = residual_block(uconv3,start_neurons * 4)\n","    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n","\n","    # 60 -> 120\n","    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","    uconv2 = concatenate([deconv2, conv2])\n","        \n","    uconv2 = Dropout(DropoutRatio)(uconv2)\n","    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n","    \n","    # 120 -> 240\n","    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    uconv1 = concatenate([deconv1, conv1])\n","    \n","    uconv1 = Dropout(DropoutRatio)(uconv1)\n","    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n","    \n","    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n","    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n","    output_layer_noActi = Conv2D(4, (1,1), padding=\"same\", activation=None)(uconv1)\n","    output_layer =  Activation('sigmoid')(output_layer_noActi)\n","    \n","    return output_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiXrY-SjvEMW","colab_type":"code","colab":{}},"source":["PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/4 Class ER\"\n","\n","# Loading the data patient wise\n","X1 = np.load(PATH + '/ER IHC 230 Images.npy')\n","Y1 = np.load(PATH + '/ER IHC 230 Masks.npy')\n","\n","X2 = np.load(PATH + '/ER IHC 232 Images.npy')\n","Y2 = np.load(PATH + '/ER IHC 232 Masks.npy')\n","\n","X3 = np.load(PATH + '/ER IHC 242 Images.npy')\n","Y3 = np.load(PATH + '/ER IHC 242 Masks.npy')\n","\n","X4 = np.load(PATH + '/ER IHC 263 Images.npy')\n","Y4 = np.load(PATH + '/ER IHC 263 Masks.npy')\n","\n","X5 = np.load(PATH + '/ER IHC 221 Images.npy')\n","Y5 = np.load(PATH + '/ER IHC 221 Masks.npy')\n","\n","X6 = np.load(PATH + '/ER IHC 229 Images.npy')\n","Y6 = np.load(PATH + '/ER IHC 229 Masks.npy')\n","\n","X7 = np.load(PATH + '/ER IHC 239 Images.npy')\n","Y7 = np.load(PATH + '/ER IHC 239 Masks.npy')\n","\n","X8 = np.load(PATH + '/ER IHC 246 Images.npy')\n","Y8 = np.load(PATH + '/ER IHC 246 Masks.npy')\n","\n","X9 = np.load(PATH + '/ER IHC 252 Images.npy')\n","Y9 = np.load(PATH + '/ER IHC 252 Masks.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgAEBm703KCC","colab_type":"code","colab":{}},"source":["X = [X1, X2, X3, X4, X5, X6, X7, X8, X9]\n","Y = [Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y9]\n","patient_no = ['230','232','242','263','221','229','239','246','252']\n","size = [10,10,10,10,10,10,10,10,10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWA9VymZTZzS","colab_type":"code","colab":{}},"source":["fold_split = []\n","\n","#test patient = 230, 232 \n","fold_split.append(([2,3,4,5,6,7,8],[0,1]))\n","\n","#test_patient = 239, 242\n","# fold_split.append(([0,1,3,4,5,7,8],[2,6]))\n","\n","# #test_patient = 252,263\n","# fold_split.append(([0,1,2,4,5,6,7],[3,8]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MujkbhpsnE9","colab_type":"code","colab":{}},"source":["def convertToLabels(data):\n","  data[data==85]=1\n","  data[data==170]=2\n","  data[data==255]=3\n","\n","def convertFromLabels(data):\n","  data[data==1]=85\n","  data[data==2]=170\n","  data[data==3]=255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDodKs-AMB81","colab_type":"code","colab":{}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3giXDJkT7GtK","colab_type":"code","colab":{}},"source":["def tversky_loss_1(y_true, y_pred):\n","    alpha = 0.7\n","    beta  = 0.3\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","  \n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    # \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def tversky_loss_2(y_true, y_pred):\n","    alpha = 0.3\n","    beta  = 0.7\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    # \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def focal_tversky_loss_1(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_1(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","  \n","def focal_tversky_loss_2(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_2(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","\n","def combined_loss(y_true, y_pred):\n","  return (0.2*K.categorical_crossentropy(y_true, y_pred))+(0.8*focal_tversky_loss_1(y_true, y_pred)+(0.8*focal_tversky_loss_2(y_true, y_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaGvHbqtarli","colab_type":"code","colab":{}},"source":["batch_size = 8\n","def get_batch(batch_size, X_train, Y_train): \n","    size_batch = batch_size\n","    last_index = len(X_train) - 1\n","    x_train = X_train\n","    y_train = Y_train \n","    while True:\n","        batch_data = [[],[]]\n","        for i in range(0, size_batch):\n","            random_index = random.randint(0, last_index)\n","            batch_data[0].append(x_train[random_index])\n","            batch_data[1].append(y_train[random_index])\n","\n","        yield (np.array(batch_data[0]), np.array(batch_data[1]))     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"59LOrWNyeE9X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594215646060,"user_tz":-330,"elapsed":5857974,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"b601b796-bf1a-4eeb-e6d4-6a247dc9250f"},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/4 Class/ER/ResNet\"\n","\n","fold=0\n","\n","for train_index, test_index in fold_split:\n","  print(\"TRAIN:\", train_index, \"TEST:\", test_index, \"FOLD:\", fold)\n","\n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  Train = list(zip(TrainX,TrainY))\n","  random.shuffle(Train)\n","  TrainX,TrainY = zip(*Train)\n","  TrainX = np.asarray(list(TrainX))\n","  TrainY = np.asarray(list(TrainY))\n","\n","  Test = list(zip(TestX,TestY))\n","  random.shuffle(Test)\n","  TestX,TestY = zip(*Test)\n","  TestX = np.asarray(list(TestX))\n","  TestY = np.asarray(list(TestY))\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","  convertToLabels(TrainY)\n","  TrainY = keras.utils.to_categorical(TrainY,num_classes=4,dtype='int16')\n","  convertToLabels(TestY)\n","  TestY = keras.utils.to_categorical(TestY,num_classes=4,dtype='int16')\n","  ValX = TrainX[(int)(0.8*TrainX.shape[0]):]\n","  ValY = TrainY[(int)(0.8*TrainY.shape[0]):]\n","  model = get_model((240,240,3),16)\n","\n","  #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","  mc = ModelCheckpoint('Checkpoint.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","  optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)\n","\n","  model.compile(loss=combined_loss, optimizer= optimizer , metrics=[dice_coef,'accuracy']) \n","  num_epoch = 100\n","  datagen = get_batch(batch_size, TrainX, TrainY)\n","  n_points = len(TrainX)\n","  print('-----------fold {}--------------'.format(fold))\n","  history = model.fit(datagen, validation_data = [ValX, ValY],\n","                  epochs=num_epoch,steps_per_epoch = math.ceil(n_points / batch_size), callbacks =[mc],  shuffle =True)\n","  model.save(MODELS_PATH + '/ResNet_ER_'+ str(fold) +'.h5')\n","  fold = fold + 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN: [2, 3, 4, 5, 6, 7, 8] TEST: [0, 1] FOLD: 0\n","-----------fold 0--------------\n","Epoch 1/100\n","420/420 [==============================] - 65s 154ms/step - loss: 3.7441 - dice_coef: 0.8094 - accuracy: 0.9254 - val_loss: 3.4740 - val_dice_coef: 0.9180 - val_accuracy: 0.9424\n","\n","Epoch 00001: val_loss improved from inf to 3.47404, saving model to Checkpoint.h5\n","Epoch 2/100\n","420/420 [==============================] - 59s 140ms/step - loss: 3.4530 - dice_coef: 0.9311 - accuracy: 0.9511 - val_loss: 3.4259 - val_dice_coef: 0.9164 - val_accuracy: 0.9365\n","\n","Epoch 00002: val_loss improved from 3.47404 to 3.42592, saving model to Checkpoint.h5\n","Epoch 3/100\n","420/420 [==============================] - 58s 139ms/step - loss: 3.3607 - dice_coef: 0.9325 - accuracy: 0.9520 - val_loss: 3.3195 - val_dice_coef: 0.9377 - val_accuracy: 0.9540\n","\n","Epoch 00003: val_loss improved from 3.42592 to 3.31952, saving model to Checkpoint.h5\n","Epoch 4/100\n","420/420 [==============================] - 59s 139ms/step - loss: 3.2647 - dice_coef: 0.9374 - accuracy: 0.9562 - val_loss: 3.1971 - val_dice_coef: 0.9217 - val_accuracy: 0.9473\n","\n","Epoch 00004: val_loss improved from 3.31952 to 3.19709, saving model to Checkpoint.h5\n","Epoch 5/100\n","420/420 [==============================] - 58s 139ms/step - loss: 3.0867 - dice_coef: 0.9367 - accuracy: 0.9509 - val_loss: 2.9253 - val_dice_coef: 0.9478 - val_accuracy: 0.9600\n","\n","Epoch 00005: val_loss improved from 3.19709 to 2.92526, saving model to Checkpoint.h5\n","Epoch 6/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.9263 - dice_coef: 0.9486 - accuracy: 0.9583 - val_loss: 2.9048 - val_dice_coef: 0.9427 - val_accuracy: 0.9495\n","\n","Epoch 00006: val_loss improved from 2.92526 to 2.90480, saving model to Checkpoint.h5\n","Epoch 7/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.8371 - dice_coef: 0.9468 - accuracy: 0.9532 - val_loss: 2.9900 - val_dice_coef: 0.9108 - val_accuracy: 0.9186\n","\n","Epoch 00007: val_loss did not improve from 2.90480\n","Epoch 8/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.7786 - dice_coef: 0.9503 - accuracy: 0.9553 - val_loss: 2.9702 - val_dice_coef: 0.8105 - val_accuracy: 0.8276\n","\n","Epoch 00008: val_loss did not improve from 2.90480\n","Epoch 9/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.7472 - dice_coef: 0.9517 - accuracy: 0.9557 - val_loss: 2.6931 - val_dice_coef: 0.9525 - val_accuracy: 0.9563\n","\n","Epoch 00009: val_loss improved from 2.90480 to 2.69306, saving model to Checkpoint.h5\n","Epoch 10/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.6993 - dice_coef: 0.9529 - accuracy: 0.9562 - val_loss: 3.2141 - val_dice_coef: 0.8456 - val_accuracy: 0.8616\n","\n","Epoch 00010: val_loss did not improve from 2.69306\n","Epoch 11/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.7187 - dice_coef: 0.9531 - accuracy: 0.9561 - val_loss: 2.6286 - val_dice_coef: 0.9480 - val_accuracy: 0.9508\n","\n","Epoch 00011: val_loss improved from 2.69306 to 2.62865, saving model to Checkpoint.h5\n","Epoch 12/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.6400 - dice_coef: 0.9552 - accuracy: 0.9576 - val_loss: 2.6086 - val_dice_coef: 0.9536 - val_accuracy: 0.9559\n","\n","Epoch 00012: val_loss improved from 2.62865 to 2.60855, saving model to Checkpoint.h5\n","Epoch 13/100\n","420/420 [==============================] - 59s 139ms/step - loss: 2.6621 - dice_coef: 0.9557 - accuracy: 0.9579 - val_loss: 2.6529 - val_dice_coef: 0.9399 - val_accuracy: 0.9435\n","\n","Epoch 00013: val_loss did not improve from 2.60855\n","Epoch 14/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5765 - dice_coef: 0.9512 - accuracy: 0.9536 - val_loss: 2.6503 - val_dice_coef: 0.9464 - val_accuracy: 0.9479\n","\n","Epoch 00014: val_loss did not improve from 2.60855\n","Epoch 15/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.6265 - dice_coef: 0.9574 - accuracy: 0.9593 - val_loss: 2.6564 - val_dice_coef: 0.9478 - val_accuracy: 0.9499\n","\n","Epoch 00015: val_loss did not improve from 2.60855\n","Epoch 16/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.6277 - dice_coef: 0.9558 - accuracy: 0.9575 - val_loss: 2.7697 - val_dice_coef: 0.9380 - val_accuracy: 0.9422\n","\n","Epoch 00016: val_loss did not improve from 2.60855\n","Epoch 17/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.6101 - dice_coef: 0.9587 - accuracy: 0.9605 - val_loss: 2.5123 - val_dice_coef: 0.9530 - val_accuracy: 0.9551\n","\n","Epoch 00017: val_loss improved from 2.60855 to 2.51228, saving model to Checkpoint.h5\n","Epoch 18/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5573 - dice_coef: 0.9543 - accuracy: 0.9559 - val_loss: 2.6489 - val_dice_coef: 0.9435 - val_accuracy: 0.9460\n","\n","Epoch 00018: val_loss did not improve from 2.51228\n","Epoch 19/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5674 - dice_coef: 0.9598 - accuracy: 0.9612 - val_loss: 2.5807 - val_dice_coef: 0.9587 - val_accuracy: 0.9600\n","\n","Epoch 00019: val_loss did not improve from 2.51228\n","Epoch 20/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5290 - dice_coef: 0.9558 - accuracy: 0.9574 - val_loss: 2.6470 - val_dice_coef: 0.9578 - val_accuracy: 0.9592\n","\n","Epoch 00020: val_loss did not improve from 2.51228\n","Epoch 21/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5232 - dice_coef: 0.9603 - accuracy: 0.9617 - val_loss: 2.5234 - val_dice_coef: 0.9505 - val_accuracy: 0.9525\n","\n","Epoch 00021: val_loss did not improve from 2.51228\n","Epoch 22/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5134 - dice_coef: 0.9566 - accuracy: 0.9581 - val_loss: 2.5757 - val_dice_coef: 0.9589 - val_accuracy: 0.9599\n","\n","Epoch 00022: val_loss did not improve from 2.51228\n","Epoch 23/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5022 - dice_coef: 0.9577 - accuracy: 0.9591 - val_loss: 2.6290 - val_dice_coef: 0.9591 - val_accuracy: 0.9601\n","\n","Epoch 00023: val_loss did not improve from 2.51228\n","Epoch 24/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5785 - dice_coef: 0.9597 - accuracy: 0.9610 - val_loss: 2.6662 - val_dice_coef: 0.9445 - val_accuracy: 0.9456\n","\n","Epoch 00024: val_loss did not improve from 2.51228\n","Epoch 25/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5889 - dice_coef: 0.9579 - accuracy: 0.9592 - val_loss: 2.5390 - val_dice_coef: 0.9522 - val_accuracy: 0.9533\n","\n","Epoch 00025: val_loss did not improve from 2.51228\n","Epoch 26/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5710 - dice_coef: 0.9564 - accuracy: 0.9577 - val_loss: 2.7591 - val_dice_coef: 0.9213 - val_accuracy: 0.9271\n","\n","Epoch 00026: val_loss did not improve from 2.51228\n","Epoch 27/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5497 - dice_coef: 0.9602 - accuracy: 0.9613 - val_loss: 2.7864 - val_dice_coef: 0.9453 - val_accuracy: 0.9459\n","\n","Epoch 00027: val_loss did not improve from 2.51228\n","Epoch 28/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5277 - dice_coef: 0.9572 - accuracy: 0.9584 - val_loss: 2.3889 - val_dice_coef: 0.9588 - val_accuracy: 0.9599\n","\n","Epoch 00028: val_loss improved from 2.51228 to 2.38892, saving model to Checkpoint.h5\n","Epoch 29/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5378 - dice_coef: 0.9610 - accuracy: 0.9621 - val_loss: 2.5230 - val_dice_coef: 0.9543 - val_accuracy: 0.9551\n","\n","Epoch 00029: val_loss did not improve from 2.38892\n","Epoch 30/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5607 - dice_coef: 0.9595 - accuracy: 0.9607 - val_loss: 2.4979 - val_dice_coef: 0.9544 - val_accuracy: 0.9553\n","\n","Epoch 00030: val_loss did not improve from 2.38892\n","Epoch 31/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4882 - dice_coef: 0.9587 - accuracy: 0.9598 - val_loss: 2.4817 - val_dice_coef: 0.9568 - val_accuracy: 0.9579\n","\n","Epoch 00031: val_loss did not improve from 2.38892\n","Epoch 32/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4998 - dice_coef: 0.9595 - accuracy: 0.9605 - val_loss: 2.5281 - val_dice_coef: 0.9609 - val_accuracy: 0.9616\n","\n","Epoch 00032: val_loss did not improve from 2.38892\n","Epoch 33/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5405 - dice_coef: 0.9605 - accuracy: 0.9615 - val_loss: 2.5977 - val_dice_coef: 0.9369 - val_accuracy: 0.9384\n","\n","Epoch 00033: val_loss did not improve from 2.38892\n","Epoch 34/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5206 - dice_coef: 0.9613 - accuracy: 0.9623 - val_loss: 2.7518 - val_dice_coef: 0.9580 - val_accuracy: 0.9587\n","\n","Epoch 00034: val_loss did not improve from 2.38892\n","Epoch 35/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5010 - dice_coef: 0.9578 - accuracy: 0.9590 - val_loss: 2.4852 - val_dice_coef: 0.9576 - val_accuracy: 0.9585\n","\n","Epoch 00035: val_loss did not improve from 2.38892\n","Epoch 36/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5619 - dice_coef: 0.9594 - accuracy: 0.9604 - val_loss: 2.5216 - val_dice_coef: 0.9504 - val_accuracy: 0.9514\n","\n","Epoch 00036: val_loss did not improve from 2.38892\n","Epoch 37/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5207 - dice_coef: 0.9597 - accuracy: 0.9607 - val_loss: 2.5582 - val_dice_coef: 0.9463 - val_accuracy: 0.9475\n","\n","Epoch 00037: val_loss did not improve from 2.38892\n","Epoch 38/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4759 - dice_coef: 0.9562 - accuracy: 0.9572 - val_loss: 2.5583 - val_dice_coef: 0.9576 - val_accuracy: 0.9585\n","\n","Epoch 00038: val_loss did not improve from 2.38892\n","Epoch 39/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4742 - dice_coef: 0.9595 - accuracy: 0.9605 - val_loss: 2.4032 - val_dice_coef: 0.9612 - val_accuracy: 0.9619\n","\n","Epoch 00039: val_loss did not improve from 2.38892\n","Epoch 40/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5680 - dice_coef: 0.9633 - accuracy: 0.9641 - val_loss: 2.4630 - val_dice_coef: 0.9606 - val_accuracy: 0.9614\n","\n","Epoch 00040: val_loss did not improve from 2.38892\n","Epoch 41/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5194 - dice_coef: 0.9625 - accuracy: 0.9634 - val_loss: 2.8823 - val_dice_coef: 0.9396 - val_accuracy: 0.9400\n","\n","Epoch 00041: val_loss did not improve from 2.38892\n","Epoch 42/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5649 - dice_coef: 0.9591 - accuracy: 0.9600 - val_loss: 2.4970 - val_dice_coef: 0.9545 - val_accuracy: 0.9557\n","\n","Epoch 00042: val_loss did not improve from 2.38892\n","Epoch 43/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4672 - dice_coef: 0.9578 - accuracy: 0.9587 - val_loss: 2.4084 - val_dice_coef: 0.9619 - val_accuracy: 0.9625\n","\n","Epoch 00043: val_loss did not improve from 2.38892\n","Epoch 44/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5101 - dice_coef: 0.9594 - accuracy: 0.9603 - val_loss: 2.4521 - val_dice_coef: 0.9617 - val_accuracy: 0.9624\n","\n","Epoch 00044: val_loss did not improve from 2.38892\n","Epoch 45/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4648 - dice_coef: 0.9596 - accuracy: 0.9605 - val_loss: 2.4235 - val_dice_coef: 0.9571 - val_accuracy: 0.9580\n","\n","Epoch 00045: val_loss did not improve from 2.38892\n","Epoch 46/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5058 - dice_coef: 0.9615 - accuracy: 0.9624 - val_loss: 2.5619 - val_dice_coef: 0.9608 - val_accuracy: 0.9615\n","\n","Epoch 00046: val_loss did not improve from 2.38892\n","Epoch 47/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4752 - dice_coef: 0.9609 - accuracy: 0.9618 - val_loss: 2.3786 - val_dice_coef: 0.9628 - val_accuracy: 0.9634\n","\n","Epoch 00047: val_loss improved from 2.38892 to 2.37860, saving model to Checkpoint.h5\n","Epoch 48/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4883 - dice_coef: 0.9588 - accuracy: 0.9596 - val_loss: 2.5095 - val_dice_coef: 0.9467 - val_accuracy: 0.9481\n","\n","Epoch 00048: val_loss did not improve from 2.37860\n","Epoch 49/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5160 - dice_coef: 0.9605 - accuracy: 0.9613 - val_loss: 2.4995 - val_dice_coef: 0.9551 - val_accuracy: 0.9560\n","\n","Epoch 00049: val_loss did not improve from 2.37860\n","Epoch 50/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4893 - dice_coef: 0.9633 - accuracy: 0.9641 - val_loss: 2.4771 - val_dice_coef: 0.9578 - val_accuracy: 0.9583\n","\n","Epoch 00050: val_loss did not improve from 2.37860\n","Epoch 51/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4854 - dice_coef: 0.9628 - accuracy: 0.9636 - val_loss: 2.3862 - val_dice_coef: 0.9598 - val_accuracy: 0.9609\n","\n","Epoch 00051: val_loss did not improve from 2.37860\n","Epoch 52/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4418 - dice_coef: 0.9606 - accuracy: 0.9614 - val_loss: 2.4346 - val_dice_coef: 0.9631 - val_accuracy: 0.9637\n","\n","Epoch 00052: val_loss did not improve from 2.37860\n","Epoch 53/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5172 - dice_coef: 0.9615 - accuracy: 0.9623 - val_loss: 2.4118 - val_dice_coef: 0.9576 - val_accuracy: 0.9584\n","\n","Epoch 00053: val_loss did not improve from 2.37860\n","Epoch 54/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4335 - dice_coef: 0.9579 - accuracy: 0.9587 - val_loss: 2.4093 - val_dice_coef: 0.9611 - val_accuracy: 0.9618\n","\n","Epoch 00054: val_loss did not improve from 2.37860\n","Epoch 55/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4625 - dice_coef: 0.9586 - accuracy: 0.9594 - val_loss: 2.4236 - val_dice_coef: 0.9605 - val_accuracy: 0.9613\n","\n","Epoch 00055: val_loss did not improve from 2.37860\n","Epoch 56/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4717 - dice_coef: 0.9616 - accuracy: 0.9623 - val_loss: 2.4192 - val_dice_coef: 0.9593 - val_accuracy: 0.9600\n","\n","Epoch 00056: val_loss did not improve from 2.37860\n","Epoch 57/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4832 - dice_coef: 0.9593 - accuracy: 0.9600 - val_loss: 2.4915 - val_dice_coef: 0.9626 - val_accuracy: 0.9632\n","\n","Epoch 00057: val_loss did not improve from 2.37860\n","Epoch 58/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4788 - dice_coef: 0.9608 - accuracy: 0.9616 - val_loss: 2.4380 - val_dice_coef: 0.9621 - val_accuracy: 0.9628\n","\n","Epoch 00058: val_loss did not improve from 2.37860\n","Epoch 59/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4919 - dice_coef: 0.9607 - accuracy: 0.9614 - val_loss: 2.4127 - val_dice_coef: 0.9608 - val_accuracy: 0.9613\n","\n","Epoch 00059: val_loss did not improve from 2.37860\n","Epoch 60/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.5025 - dice_coef: 0.9624 - accuracy: 0.9632 - val_loss: 2.4652 - val_dice_coef: 0.9584 - val_accuracy: 0.9589\n","\n","Epoch 00060: val_loss did not improve from 2.37860\n","Epoch 61/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5282 - dice_coef: 0.9601 - accuracy: 0.9609 - val_loss: 2.4931 - val_dice_coef: 0.9576 - val_accuracy: 0.9582\n","\n","Epoch 00061: val_loss did not improve from 2.37860\n","Epoch 62/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4963 - dice_coef: 0.9612 - accuracy: 0.9620 - val_loss: 2.3584 - val_dice_coef: 0.9604 - val_accuracy: 0.9610\n","\n","Epoch 00062: val_loss improved from 2.37860 to 2.35835, saving model to Checkpoint.h5\n","Epoch 63/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4332 - dice_coef: 0.9612 - accuracy: 0.9619 - val_loss: 2.3859 - val_dice_coef: 0.9613 - val_accuracy: 0.9621\n","\n","Epoch 00063: val_loss did not improve from 2.35835\n","Epoch 64/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4907 - dice_coef: 0.9630 - accuracy: 0.9638 - val_loss: 2.4408 - val_dice_coef: 0.9616 - val_accuracy: 0.9622\n","\n","Epoch 00064: val_loss did not improve from 2.35835\n","Epoch 65/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4608 - dice_coef: 0.9615 - accuracy: 0.9622 - val_loss: 2.4585 - val_dice_coef: 0.9590 - val_accuracy: 0.9594\n","\n","Epoch 00065: val_loss did not improve from 2.35835\n","Epoch 66/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4250 - dice_coef: 0.9623 - accuracy: 0.9631 - val_loss: 2.4862 - val_dice_coef: 0.9628 - val_accuracy: 0.9633\n","\n","Epoch 00066: val_loss did not improve from 2.35835\n","Epoch 67/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.3531 - dice_coef: 0.9611 - accuracy: 0.9619 - val_loss: 2.4293 - val_dice_coef: 0.9569 - val_accuracy: 0.9575\n","\n","Epoch 00067: val_loss did not improve from 2.35835\n","Epoch 68/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4286 - dice_coef: 0.9604 - accuracy: 0.9611 - val_loss: 2.4511 - val_dice_coef: 0.9564 - val_accuracy: 0.9571\n","\n","Epoch 00068: val_loss did not improve from 2.35835\n","Epoch 69/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4497 - dice_coef: 0.9581 - accuracy: 0.9589 - val_loss: 2.4048 - val_dice_coef: 0.9625 - val_accuracy: 0.9633\n","\n","Epoch 00069: val_loss did not improve from 2.35835\n","Epoch 70/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4902 - dice_coef: 0.9617 - accuracy: 0.9624 - val_loss: 2.4620 - val_dice_coef: 0.9621 - val_accuracy: 0.9626\n","\n","Epoch 00070: val_loss did not improve from 2.35835\n","Epoch 71/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4307 - dice_coef: 0.9583 - accuracy: 0.9591 - val_loss: 2.4028 - val_dice_coef: 0.9568 - val_accuracy: 0.9575\n","\n","Epoch 00071: val_loss did not improve from 2.35835\n","Epoch 72/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4052 - dice_coef: 0.9626 - accuracy: 0.9633 - val_loss: 2.5876 - val_dice_coef: 0.9541 - val_accuracy: 0.9544\n","\n","Epoch 00072: val_loss did not improve from 2.35835\n","Epoch 73/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4173 - dice_coef: 0.9611 - accuracy: 0.9618 - val_loss: 2.3938 - val_dice_coef: 0.9632 - val_accuracy: 0.9638\n","\n","Epoch 00073: val_loss did not improve from 2.35835\n","Epoch 74/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.3878 - dice_coef: 0.9607 - accuracy: 0.9615 - val_loss: 2.3539 - val_dice_coef: 0.9609 - val_accuracy: 0.9614\n","\n","Epoch 00074: val_loss improved from 2.35835 to 2.35394, saving model to Checkpoint.h5\n","Epoch 75/100\n","420/420 [==============================] - 59s 139ms/step - loss: 2.4807 - dice_coef: 0.9614 - accuracy: 0.9620 - val_loss: 2.3320 - val_dice_coef: 0.9622 - val_accuracy: 0.9626\n","\n","Epoch 00075: val_loss improved from 2.35394 to 2.33201, saving model to Checkpoint.h5\n","Epoch 76/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4771 - dice_coef: 0.9637 - accuracy: 0.9643 - val_loss: 2.6424 - val_dice_coef: 0.9608 - val_accuracy: 0.9613\n","\n","Epoch 00076: val_loss did not improve from 2.33201\n","Epoch 77/100\n","420/420 [==============================] - 59s 140ms/step - loss: 2.4056 - dice_coef: 0.9607 - accuracy: 0.9615 - val_loss: 2.3438 - val_dice_coef: 0.9645 - val_accuracy: 0.9651\n","\n","Epoch 00077: val_loss did not improve from 2.33201\n","Epoch 78/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4430 - dice_coef: 0.9614 - accuracy: 0.9621 - val_loss: 2.4209 - val_dice_coef: 0.9609 - val_accuracy: 0.9615\n","\n","Epoch 00078: val_loss did not improve from 2.33201\n","Epoch 79/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4492 - dice_coef: 0.9611 - accuracy: 0.9617 - val_loss: 2.3919 - val_dice_coef: 0.9575 - val_accuracy: 0.9584\n","\n","Epoch 00079: val_loss did not improve from 2.33201\n","Epoch 80/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.3676 - dice_coef: 0.9615 - accuracy: 0.9623 - val_loss: 2.3456 - val_dice_coef: 0.9621 - val_accuracy: 0.9626\n","\n","Epoch 00080: val_loss did not improve from 2.33201\n","Epoch 81/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4058 - dice_coef: 0.9625 - accuracy: 0.9631 - val_loss: 2.3527 - val_dice_coef: 0.9620 - val_accuracy: 0.9627\n","\n","Epoch 00081: val_loss did not improve from 2.33201\n","Epoch 82/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4060 - dice_coef: 0.9625 - accuracy: 0.9631 - val_loss: 2.3900 - val_dice_coef: 0.9629 - val_accuracy: 0.9635\n","\n","Epoch 00082: val_loss did not improve from 2.33201\n","Epoch 83/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4282 - dice_coef: 0.9626 - accuracy: 0.9632 - val_loss: 2.4479 - val_dice_coef: 0.9628 - val_accuracy: 0.9632\n","\n","Epoch 00083: val_loss did not improve from 2.33201\n","Epoch 84/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4478 - dice_coef: 0.9603 - accuracy: 0.9610 - val_loss: 2.3338 - val_dice_coef: 0.9588 - val_accuracy: 0.9595\n","\n","Epoch 00084: val_loss did not improve from 2.33201\n","Epoch 85/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4172 - dice_coef: 0.9596 - accuracy: 0.9604 - val_loss: 2.5918 - val_dice_coef: 0.9613 - val_accuracy: 0.9618\n","\n","Epoch 00085: val_loss did not improve from 2.33201\n","Epoch 86/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4030 - dice_coef: 0.9604 - accuracy: 0.9612 - val_loss: 2.3509 - val_dice_coef: 0.9581 - val_accuracy: 0.9588\n","\n","Epoch 00086: val_loss did not improve from 2.33201\n","Epoch 87/100\n","420/420 [==============================] - 59s 139ms/step - loss: 2.4625 - dice_coef: 0.9641 - accuracy: 0.9647 - val_loss: 2.4122 - val_dice_coef: 0.9552 - val_accuracy: 0.9565\n","\n","Epoch 00087: val_loss did not improve from 2.33201\n","Epoch 88/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.5008 - dice_coef: 0.9619 - accuracy: 0.9627 - val_loss: 2.3469 - val_dice_coef: 0.9589 - val_accuracy: 0.9594\n","\n","Epoch 00088: val_loss did not improve from 2.33201\n","Epoch 89/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4371 - dice_coef: 0.9599 - accuracy: 0.9606 - val_loss: 2.4116 - val_dice_coef: 0.9596 - val_accuracy: 0.9602\n","\n","Epoch 00089: val_loss did not improve from 2.33201\n","Epoch 90/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4369 - dice_coef: 0.9631 - accuracy: 0.9637 - val_loss: 2.3370 - val_dice_coef: 0.9616 - val_accuracy: 0.9622\n","\n","Epoch 00090: val_loss did not improve from 2.33201\n","Epoch 91/100\n","420/420 [==============================] - 58s 139ms/step - loss: 2.4287 - dice_coef: 0.9614 - accuracy: 0.9621 - val_loss: 2.4502 - val_dice_coef: 0.9623 - val_accuracy: 0.9629\n","\n","Epoch 00091: val_loss did not improve from 2.33201\n","Epoch 92/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4612 - dice_coef: 0.9619 - accuracy: 0.9626 - val_loss: 2.3359 - val_dice_coef: 0.9626 - val_accuracy: 0.9632\n","\n","Epoch 00092: val_loss did not improve from 2.33201\n","Epoch 93/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4509 - dice_coef: 0.9633 - accuracy: 0.9640 - val_loss: 2.3396 - val_dice_coef: 0.9635 - val_accuracy: 0.9641\n","\n","Epoch 00093: val_loss did not improve from 2.33201\n","Epoch 94/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4290 - dice_coef: 0.9608 - accuracy: 0.9615 - val_loss: 2.3003 - val_dice_coef: 0.9616 - val_accuracy: 0.9621\n","\n","Epoch 00094: val_loss improved from 2.33201 to 2.30034, saving model to Checkpoint.h5\n","Epoch 95/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4130 - dice_coef: 0.9620 - accuracy: 0.9627 - val_loss: 2.6335 - val_dice_coef: 0.9591 - val_accuracy: 0.9595\n","\n","Epoch 00095: val_loss did not improve from 2.30034\n","Epoch 96/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4243 - dice_coef: 0.9620 - accuracy: 0.9626 - val_loss: 2.4715 - val_dice_coef: 0.9475 - val_accuracy: 0.9480\n","\n","Epoch 00096: val_loss did not improve from 2.30034\n","Epoch 97/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4550 - dice_coef: 0.9606 - accuracy: 0.9613 - val_loss: 2.4874 - val_dice_coef: 0.9527 - val_accuracy: 0.9537\n","\n","Epoch 00097: val_loss did not improve from 2.30034\n","Epoch 98/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.4109 - dice_coef: 0.9585 - accuracy: 0.9592 - val_loss: 2.3849 - val_dice_coef: 0.9595 - val_accuracy: 0.9600\n","\n","Epoch 00098: val_loss did not improve from 2.30034\n","Epoch 99/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.3772 - dice_coef: 0.9616 - accuracy: 0.9623 - val_loss: 2.3437 - val_dice_coef: 0.9630 - val_accuracy: 0.9635\n","\n","Epoch 00099: val_loss did not improve from 2.30034\n","Epoch 100/100\n","420/420 [==============================] - 58s 138ms/step - loss: 2.3591 - dice_coef: 0.9629 - accuracy: 0.9635 - val_loss: 2.3772 - val_dice_coef: 0.9637 - val_accuracy: 0.9642\n","\n","Epoch 00100: val_loss did not improve from 2.30034\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XzwipgD8UuIy","colab_type":"code","colab":{}},"source":["def stitchMaskPatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img\n","\n","\n","def stitchImagePatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920,3])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240,:] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KNI0eyqvGcy","colab_type":"code","colab":{}},"source":["def saveNumpyOutput(mask, Patient_array,Patient_length,title,folder):\n","  idx = 0\n","  for i in range(len(Patient_length)):\n","    temp = []\n","    for j in range(Patient_length[i]):\n","      final_output = mask[idx:idx+48]\n","      idx = idx + 48\n","      final_output = stitchMaskPatches(final_output)\n","      temp.append(final_output)\n","    final_output = np.asarray(temp)\n","    np.save(folder + title + Patient_array[i], final_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NErfv7ZJ7Bxr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594266973584,"user_tz":-330,"elapsed":3682,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"0137f803-9105-4542-b084-753eeade8fd6"},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/4 Class/ER/ResNet/\"\n","model_names = os.listdir(MODELS_PATH)\n","print(model_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['ResNet_ER_0.h5']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2bo0X0lXSwE6","colab_type":"code","colab":{}},"source":["SAVE_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/ER/ResNet/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-zmdlCcbBGn","colab_type":"code","colab":{}},"source":["# Axis 0 = Folds\n","# Axis 1 = Class (Strong Intermediate,Weak,Background)\n","# Axis 2 = Evaluation Technique (Precision, Recall, Dice coefficient)\n","pixEvaluationTrain = np.empty((0,4,3))\n","pixEvaluationTest = np.empty((0,4,3))\n","score = np.zeros((1,4,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wl31sylb0qvs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594267755549,"user_tz":-330,"elapsed":256053,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"9ac8dbbd-9224-4db8-e5e5-4b345b55cc82"},"source":["fold = 0\n","\n","for train_index, test_index in fold_split:\n","  print(\"FOLD:\",fold,\"\\tTRAIN:\", train_index, \"TEST:\", test_index)\n","  # Splitting Train and Test data\n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  train_no = [patient_no[i] for i in train_index]\n","  train_size = [size[i] for i in train_index]\n","\n","  test_no = [patient_no[i] for i in test_index]\n","  test_size = [size[i] for i in test_index]\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","\n","  convertToLabels(TrainY)\n","  convertToLabels(TestY)\n","\n","  # Loading corrosponding fold of model\n","  model = keras.models.load_model(MODELS_PATH + model_names[fold],custom_objects={ 'combined_loss': combined_loss, 'dice_coef': dice_coef })\n","\n","  # Predicting results using model\n","  trainResult = model.predict(TrainX, batch_size=8)\n","  testResult = model.predict(TestX,batch_size=8)\n","\n","  trainResult = np.argmax(trainResult,axis=-1)\n","  testResult = np.argmax(testResult,axis=-1)\n","\n","  # Obtaining pixel-wise results: Precision recall and dice coefficient\n","  # For TRAIN\n","  y_true = np.reshape(TrainY,(-1))\n","  y_pred = np.reshape(trainResult,(-1))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(4):\n","    score[0][i][0] = prec[3-i]\n","    score[0][i][1] = recall[3-i]\n","    score[0][i][2] = dice[3-i]\n","\n","  pixEvaluationTrain = np.append(pixEvaluationTrain,score,axis=0)\n"," \n","  # For TEST\n","  y_true = np.reshape(TestY,(-1))\n","  y_pred = np.reshape(testResult,(-1))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(4):\n","    score[0][i][0] = prec[3-i]\n","    score[0][i][1] = recall[3-i]\n","    score[0][i][2] = dice[3-i]\n","\n","  pixEvaluationTest = np.append(pixEvaluationTest,score,axis=0)\n","\n","  # Converting predicted labels to required output format\n","  convertFromLabels(trainResult)\n","  convertFromLabels(testResult)\n","\n","  # Saving numpy arrays\n","  path = os.path.join(SAVE_PATH,\"Fold \" + str(fold))\n","  os.mkdir(path)\n","  os.mkdir(path + '/Train')\n","  os.mkdir(path + '/Test')\n","\n","  saveNumpyOutput(trainResult, train_no, train_size,\"/Train/\",path)\n","  saveNumpyOutput(testResult, test_no, test_size,\"/Test/\",path)\n","\n","  fold +=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FOLD: 0 \tTRAIN: [2, 3, 4, 5, 6, 7, 8] TEST: [0, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IeQAQsZexovM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1594267961757,"user_tz":-330,"elapsed":950,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"33a0b46a-8c47-41c0-ad23-3e6cdc190540"},"source":["print(pixEvaluationTrain.shape)\n","print(pixEvaluationTest.shape)\n","print(pixEvaluationTrain)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2, 4, 3)\n","(2, 4, 3)\n","[[[0.80606553 0.78006769 0.79285355]\n","  [0.56341628 0.63071181 0.59516782]\n","  [0.47188978 0.35537566 0.40542765]\n","  [0.98738064 0.98781684 0.98759869]]\n","\n"," [[0.80606553 0.78006769 0.79285355]\n","  [0.56341617 0.63071181 0.59516775]\n","  [0.47188978 0.35537566 0.40542765]\n","  [0.98738064 0.98781684 0.98759869]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBNZbrAiyEhO","colab_type":"code","colab":{}},"source":["np.save(SAVE_PATH + \"Pixel-wise Metrics Train.npy\", pixEvaluationTrain)\n","np.save(SAVE_PATH + \"Pixel-wise Metrics Test.npy\", pixEvaluationTest)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uT2MzD4mn3mt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1594282301439,"user_tz":-330,"elapsed":1102,"user":{"displayName":"Ramya B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GieTE9FAgUSC7kmQGLqSOw7FsRQJ3KKuc3OyVfEyQ=s64","userId":"15349008009844832706"}},"outputId":"d67e9673-bc9e-401d-dea1-3bdefa8363c1"},"source":["train = np.load(SAVE_PATH + \"Pixel-wise Metrics Train.npy\")\n","print(train.shape)\n","test = np.load(SAVE_PATH + \"Pixel-wise Metrics Test.npy\")\n","print(test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2, 4, 3)\n","[[[0.91100908 0.3050208  0.45702285]\n","  [0.39661825 0.468831   0.42971193]\n","  [0.32470528 0.21065519 0.25553195]\n","  [0.9575788  0.99334929 0.97513612]]\n","\n"," [[0.91100908 0.3050208  0.45702285]\n","  [0.39661825 0.468831   0.42971193]\n","  [0.32470528 0.21065519 0.25553195]\n","  [0.9575788  0.99334929 0.97513612]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZwjDP44MUTa6","colab_type":"text"},"source":["# **DISPLAY**"]},{"cell_type":"code","metadata":{"id":"DzUOdXOKU2nb","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","\n","plt.figure(figsize=(20,20))\n","id = 48   # enter between 0- 50 since there are 5 patients with 10 images each\n","\n","id = id * 48\n","final_input = TestX[id:id+48]\n","Mask_input = TestGT[id:id+48]\n","final_output = testResult[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","final_output = stitchMaskPatches(final_output)\n","\n","print(final_input.shape)\n","print(final_output.shape)\n","print(Mask_input.shape)\n","\n","print(np.unique(final_output))\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","plt.subplot(132).imshow(Mask_input,'gray')\n","plt.subplot(133).imshow(final_output,'gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5IqVx01JeWn","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","\n","plt.figure(figsize=(20,20))\n","id = 25  # enter between 0- 40 since there are 4 patients with 10 images each\n","\n","id = id * 48\n","final_input = TrainX[id:id+48]\n","Mask_input = TrainGT[id:id+48]\n","final_output = trainResult[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","final_output = stitchMaskPatches(final_output)\n","\n","print(final_input.shape)\n","print(final_output.shape)\n","print(Mask_input.shape)\n","\n","print(np.unique(final_output))\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","plt.subplot(132).imshow(Mask_input,'gray')\n","plt.subplot(133).imshow(final_output,'gray')"],"execution_count":null,"outputs":[]}]}