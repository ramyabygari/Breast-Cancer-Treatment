{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PR 3Fold LadderNet.ipynb","provenance":[{"file_id":"18CLxlwQAPe3Nri9khEriPE7Fo2Dz_zoW","timestamp":1592200356037},{"file_id":"1yrzaA6g0-hX5EbB9EVCwufTXAfk2Z_M6","timestamp":1592073984971},{"file_id":"1abkYuSvojPmWb7wyA7FWLvFC15PhBNmh","timestamp":1592062059570},{"file_id":"16hqggEiNT-NR-gwzWl-JDg6OSUab1SSE","timestamp":1590932441130},{"file_id":"1dLxM_AMOSs32Mxu42FNwumVVm11sLpeG","timestamp":1589304160359},{"file_id":"17lvwlvqQV7B-wqN2ajx7Q2UwCZwCd-WD","timestamp":1586698406636},{"file_id":"1SAeOlks1aRTndKfvFcMtNB7V3Ik6nfN0","timestamp":1586361815646},{"file_id":"1puNfvA8GEtqbsfDMP30_RS6XRrNM8Ky8","timestamp":1586249758540},{"file_id":"1QPxGukBl9nFKfyxsNhM4lUw4rYauJaY1","timestamp":1586242198727},{"file_id":"1txy9g7gYnELmPTY6sT4JtfbhwQthIyoG","timestamp":1583812009231},{"file_id":"1a9BwVwMfQ4iFdte5xgs4kzj58JNqs4Vu","timestamp":1579539718864},{"file_id":"1KyLESiefS0uSAi_kTOAZ9NmNUSYTs9lL","timestamp":1578995412588},{"file_id":"1YDTADQrLw8-aYCSjOEYxDuIB1nuy3Xzm","timestamp":1577686452735},{"file_id":"1DqrMpMvIbzPtWFjsL_eNwrVM-xaFvx6c","timestamp":1571727299009}],"collapsed_sections":["ZwjDP44MUTa6"],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ixvBWa23MB7e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1592278603165,"user_tz":-330,"elapsed":60503,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"10328899499454425616"}},"outputId":"838f417a-2c44-4b7a-ef7c-0ec68961b79c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LzNbXYWE4I5E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592278727042,"user_tz":-330,"elapsed":87374,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"10328899499454425616"}},"outputId":"e88dae3e-b374-473f-e20b-45de8fc3d975"},"source":["import os\n","import cv2\n","import numpy as np\n","!pip install -U keras\n","!pip install tensorflow-gpu==2.1.0rc0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n","Collecting tensorflow-gpu==2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/24/f94a1b8f779471f53b814a96c5109994ccf65b0103b771ff208c8a937d37/tensorflow_gpu-2.1.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (402.3MB)\n","\u001b[K     |████████████████████████████████| 402.3MB 36kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.29.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.18.5)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.9.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.34.2)\n","Collecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 52.0MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 57.6MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (3.2.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.12.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.8.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.2.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (3.10.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (0.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.2.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.7.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (47.1.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0rc0) (2.10.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (2020.4.5.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (4.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (0.2.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (0.4.8)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=264a30993a1c47f0af02e5c9c723ba1a90f9d13f13e0f5174d450ce9abbe8170\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow-gpu\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.1.0rc0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Mk6pnB6tFp0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592278728733,"user_tz":-330,"elapsed":88041,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"10328899499454425616"}},"outputId":"8407b3c6-d18b-452f-fa25-ff1f09f5a1cc"},"source":["import math\n","import random\n","import keras\n","from keras.layers import *\n","from keras.models import Sequential\n","from keras import Model\n","from keras import backend as K  \n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","\n","from sklearn.model_selection import LeaveOneOut\n","from sklearn import metrics"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U4SPHrcLZH4a","colab":{}},"source":["def get_conv_block(input_layer,nFilters,size):\n","    conv1 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(input_layer)\n","    bn1 = BatchNormalization()(conv1)\n","    conv2 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(bn1)\n","    bn2 = BatchNormalization()(conv2)\n","    return bn2\n","    \n","def get_UNET(input_layer,nFilters,flag): \n","\n","    block1 = get_conv_block(input_layer[0],nFilters,3)\n","    mp1 = MaxPooling2D(pool_size=(2, 2))(block1)\n","    dr1 = Dropout(0.1)(mp1)\n","   \n","    if(flag==1):\n","      dr1 = concatenate([dr1,input_layer[1]])\n","\n","    block2 = get_conv_block(dr1,nFilters*2,3)\n","    mp2 = MaxPooling2D(pool_size=(2, 2))(block2)\n","    dr2 = Dropout(0.1)(mp2)\n","\n","    if(flag==1):\n","      dr2 = concatenate([dr2,input_layer[2]])\n","   \n","    block3 = get_conv_block(dr2,nFilters*4,3)\n","    mp3 = MaxPooling2D(pool_size=(2, 2))(block3)\n","    dr3 = Dropout(0.1)(mp3)\n","\n","    if(flag==1):\n","      dr3 = concatenate([dr3,input_layer[3]])\n","       \n","    block4 = get_conv_block(dr3,nFilters*8,3)\n","    mp4 = MaxPooling2D(pool_size=(2, 2))(block4)\n","    dr4 = Dropout(0.1)(mp4)\n","\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(dr4)\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(conv5)\n","\n","    up1 = Conv2DTranspose(nFilters*8,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(conv5)\n","    cat1 = concatenate([block4, up1, mp3])\n","    dr1 = Dropout(0.1)(cat1)\n","    block5 = get_conv_block(dr1,nFilters*8,3)\n","\n","    up2 = Conv2DTranspose(nFilters*4,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block5)\n","    b4_upsample = Conv2DTranspose(nFilters*4,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block4)\n","    cat2 = concatenate([block3, up2, b4_upsample, mp2])\n","    dr2 = Dropout(0.1)(cat2)\n","    block6 = get_conv_block(dr2,nFilters*4,3)\n","    \n","    up3 = Conv2DTranspose(nFilters*2,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block6)\n","    b3_upsample = Conv2DTranspose(nFilters*2,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block3)\n","    cat3 = concatenate([block2, up3, mp1, b3_upsample])\n","    dr3 = Dropout(0.1)(cat3)\n","    block7 = get_conv_block(dr3,nFilters*2,3)\n","    \n","    up4 = Conv2DTranspose(nFilters,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block7)\n","    b2_upsample = Conv2DTranspose(nFilters,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block2)\n","    cat4 = concatenate([block1, up4, b2_upsample])\n","    dr4 = Dropout(0.1)(cat4)\n","    block8 = get_conv_block(dr4,nFilters,3)\n","\n","    conv10 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(block8)\n","    conv11 = Conv2D(4,(1,1), activation='softmax', padding = 'same',kernel_regularizer=l2(1e-4))(conv10)\n","\n","    return (conv11, block7, block6, block5)\n","\n","def get_model(input_shape,nFilters1,nFilters2):\n","\n","    input_layer = Input(shape=input_shape)\n","    out1,out2,out3,out4 = get_UNET([input_layer],nFilters1,0)\n","\n","    out1,out2,out3,out4 = get_UNET([out1,out2,out3,out4],nFilters2,1)\n","\n","    model = Model(input_layer,out1)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiXrY-SjvEMW","colab_type":"code","colab":{}},"source":["PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/4 Class PR\"\n","\n","# Loading the data patient wise\n","X1 = np.load(PATH + '/PR IHC 230 Images.npy')\n","Y1 = np.load(PATH + '/PR IHC 230 Masks.npy')\n","\n","X2 = np.load(PATH + '/PR IHC 232 Images.npy')\n","Y2 = np.load(PATH + '/PR IHC 232 Masks.npy')\n","\n","X3 = np.load(PATH + '/PR IHC 242 Images.npy')\n","Y3 = np.load(PATH + '/PR IHC 242 Masks.npy')\n","\n","X4 = np.load(PATH + '/PR IHC 263 Images.npy')\n","Y4 = np.load(PATH + '/PR IHC 263 Masks.npy')\n","\n","X5 = np.load(PATH + '/PR IHC 221 Images.npy')\n","Y5 = np.load(PATH + '/PR IHC 221 Masks.npy')\n","\n","X6 = np.load(PATH + '/PR IHC 229 Images.npy')\n","Y6 = np.load(PATH + '/PR IHC 229 Masks.npy')\n","\n","X7 = np.load(PATH + '/PR IHC 239 Images.npy')\n","Y7 = np.load(PATH + '/PR IHC 239 Masks.npy')\n","\n","X8 = np.load(PATH + '/PR IHC 246 Images.npy')\n","Y8 = np.load(PATH + '/PR IHC 246 Masks.npy')\n","\n","X9 = np.load(PATH + '/PR IHC 252 Images.npy')\n","Y9 = np.load(PATH + '/PR IHC 252 Masks.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgAEBm703KCC","colab_type":"code","colab":{}},"source":["X = [X1, X2, X3, X4, X5, X6, X7, X8, X9]\n","Y = [Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y9]\n","patient_no = ['230','232','242','263','221','229','239','246','252']\n","size = [14,10,10,10,10,10,10,10,10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWA9VymZTZzS","colab_type":"code","colab":{}},"source":["fold_split = []\n","\n","#test patient = 230, 232 \n","fold_split.append(([2,3,4,5,6,7,8],[0,1]))\n","\n","#test_patient = 239, 242\n","fold_split.append(([0,1,3,4,5,7,8],[2,6]))\n","\n","#test_patient = 252,263\n","fold_split.append(([0,1,2,4,5,6,7],[3,8]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MujkbhpsnE9","colab_type":"code","colab":{}},"source":["def convertToLabels(data):\n","  data[data==85]=1\n","  data[data==170]=2\n","  data[data==255]=3\n","\n","def convertFromLabels(data):\n","  data[data==1]=85\n","  data[data==2]=170\n","  data[data==3]=255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDodKs-AMB81","colab_type":"code","colab":{}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3giXDJkT7GtK","colab_type":"code","colab":{}},"source":["def tversky_loss_1(y_true, y_pred):\n","    alpha = 0.7\n","    beta  = 0.3\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","  \n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    # \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def tversky_loss_2(y_true, y_pred):\n","    alpha = 0.3\n","    beta  = 0.7\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    # \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def focal_tversky_loss_1(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_1(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","  \n","def focal_tversky_loss_2(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_2(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","\n","def combined_loss(y_true, y_pred):\n","  return (0.2*K.categorical_crossentropy(y_true, y_pred))+(0.8*focal_tversky_loss_1(y_true, y_pred)+(0.8*focal_tversky_loss_2(y_true, y_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaGvHbqtarli","colab_type":"code","colab":{}},"source":["batch_size = 8\n","def get_batch(batch_size, X_train, Y_train): \n","    size_batch = batch_size\n","    last_index = len(X_train) - 1\n","    x_train = X_train\n","    y_train = Y_train \n","    while True:\n","        batch_data = [[],[]]\n","        for i in range(0, size_batch):\n","            random_index = random.randint(0, last_index)\n","            batch_data[0].append(x_train[random_index])\n","            batch_data[1].append(y_train[random_index])\n","\n","        yield (np.array(batch_data[0]), np.array(batch_data[1]))     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"59LOrWNyeE9X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592126194492,"user_tz":-330,"elapsed":16920275,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"9d362884-c6ff-4e7c-c425-fa890850ae01"},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/4 Class/PR/3Fold LadderNet\"\n","\n","fold=1\n","\n","for train_index, test_index in fold_split:\n","  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","  \n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  Train = list(zip(TrainX,TrainY))\n","  random.shuffle(Train)\n","  TrainX,TrainY = zip(*Train)\n","  TrainX = np.asarray(list(TrainX))\n","  TrainY = np.asarray(list(TrainY))\n","\n","  Test = list(zip(TestX,TestY))\n","  random.shuffle(Test)\n","  TestX,TestY = zip(*Test)\n","  TestX = np.asarray(list(TestX))\n","  TestY = np.asarray(list(TestY))\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","  convertToLabels(TrainY)\n","  TrainY = keras.utils.to_categorical(TrainY,num_classes=4,dtype='int16')\n","  convertToLabels(TestY)\n","  TestY = keras.utils.to_categorical(TestY,num_classes=4,dtype='int16')\n","  ValX = TrainX[(int)(0.8*TrainX.shape[0]):]\n","  ValY = TrainY[(int)(0.8*TrainY.shape[0]):]\n","  model = get_model((240,240,3),32,64)\n","\n","  #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","  mc = ModelCheckpoint('Checkpoint.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","  optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)\n","\n","  model.compile(loss=combined_loss, optimizer= optimizer , metrics=[dice_coef,'accuracy']) \n","  num_epoch = 100\n","  datagen = get_batch(batch_size, TrainX, TrainY)\n","  n_points = len(TrainX)\n","  print('-----------fold {}--------------'.format(fold))\n","  history = model.fit(datagen, validation_data = [ValX, ValY],\n","                  epochs=num_epoch,steps_per_epoch = math.ceil(n_points / batch_size), callbacks =[mc],  shuffle =True)\n","  model.save(MODELS_PATH + '/FoC_TVCombined_LadderNet_PR'+ str(fold) +'.h5')\n","  fold = fold + 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN: [0, 1, 3, 4, 5, 7, 8] TEST: [2, 6]\n","-----------fold 1--------------\n","Epoch 1/100\n","444/444 [==============================] - 351s 790ms/step - loss: 5.1922 - dice_coef: 0.9294 - accuracy: 0.9476 - val_loss: 5.0322 - val_dice_coef: 0.9741 - val_accuracy: 0.9775\n","\n","Epoch 00001: val_loss improved from inf to 5.03225, saving model to Checkpoint.h5\n","Epoch 2/100\n","444/444 [==============================] - 328s 740ms/step - loss: 4.9350 - dice_coef: 0.9756 - accuracy: 0.9782 - val_loss: 4.8305 - val_dice_coef: 0.9741 - val_accuracy: 0.9767\n","\n","Epoch 00002: val_loss improved from 5.03225 to 4.83049, saving model to Checkpoint.h5\n","Epoch 3/100\n","444/444 [==============================] - 328s 740ms/step - loss: 4.7165 - dice_coef: 0.9773 - accuracy: 0.9789 - val_loss: 4.7524 - val_dice_coef: 0.9793 - val_accuracy: 0.9782\n","\n","Epoch 00003: val_loss improved from 4.83049 to 4.75236, saving model to Checkpoint.h5\n","Epoch 4/100\n","444/444 [==============================] - 328s 739ms/step - loss: 4.5029 - dice_coef: 0.9757 - accuracy: 0.9783 - val_loss: 4.4285 - val_dice_coef: 0.9779 - val_accuracy: 0.9812\n","\n","Epoch 00004: val_loss improved from 4.75236 to 4.42850, saving model to Checkpoint.h5\n","Epoch 5/100\n","444/444 [==============================] - 328s 739ms/step - loss: 4.3283 - dice_coef: 0.9762 - accuracy: 0.9791 - val_loss: 4.2665 - val_dice_coef: 0.9801 - val_accuracy: 0.9833\n","\n","Epoch 00005: val_loss improved from 4.42850 to 4.26650, saving model to Checkpoint.h5\n","Epoch 6/100\n","444/444 [==============================] - 328s 740ms/step - loss: 4.1719 - dice_coef: 0.9776 - accuracy: 0.9805 - val_loss: 4.1369 - val_dice_coef: 0.9789 - val_accuracy: 0.9820\n","\n","Epoch 00006: val_loss improved from 4.26650 to 4.13694, saving model to Checkpoint.h5\n","Epoch 7/100\n","444/444 [==============================] - 328s 739ms/step - loss: 4.0422 - dice_coef: 0.9774 - accuracy: 0.9800 - val_loss: 3.9696 - val_dice_coef: 0.9787 - val_accuracy: 0.9804\n","\n","Epoch 00007: val_loss improved from 4.13694 to 3.96956, saving model to Checkpoint.h5\n","Epoch 8/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.8898 - dice_coef: 0.9762 - accuracy: 0.9775 - val_loss: 3.8855 - val_dice_coef: 0.9684 - val_accuracy: 0.9701\n","\n","Epoch 00008: val_loss improved from 3.96956 to 3.88547, saving model to Checkpoint.h5\n","Epoch 9/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.7727 - dice_coef: 0.9733 - accuracy: 0.9747 - val_loss: 3.7775 - val_dice_coef: 0.9658 - val_accuracy: 0.9681\n","\n","Epoch 00009: val_loss improved from 3.88547 to 3.77748, saving model to Checkpoint.h5\n","Epoch 10/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.6750 - dice_coef: 0.9758 - accuracy: 0.9773 - val_loss: 3.7114 - val_dice_coef: 0.9772 - val_accuracy: 0.9789\n","\n","Epoch 00010: val_loss improved from 3.77748 to 3.71144, saving model to Checkpoint.h5\n","Epoch 11/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.6522 - dice_coef: 0.9783 - accuracy: 0.9799 - val_loss: 3.5957 - val_dice_coef: 0.9777 - val_accuracy: 0.9797\n","\n","Epoch 00011: val_loss improved from 3.71144 to 3.59569, saving model to Checkpoint.h5\n","Epoch 12/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.5600 - dice_coef: 0.9797 - accuracy: 0.9808 - val_loss: 3.5472 - val_dice_coef: 0.9751 - val_accuracy: 0.9774\n","\n","Epoch 00012: val_loss improved from 3.59569 to 3.54721, saving model to Checkpoint.h5\n","Epoch 13/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.4891 - dice_coef: 0.9763 - accuracy: 0.9774 - val_loss: 3.5068 - val_dice_coef: 0.9808 - val_accuracy: 0.9829\n","\n","Epoch 00013: val_loss improved from 3.54721 to 3.50684, saving model to Checkpoint.h5\n","Epoch 14/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.4297 - dice_coef: 0.9773 - accuracy: 0.9782 - val_loss: 3.4316 - val_dice_coef: 0.9816 - val_accuracy: 0.9834\n","\n","Epoch 00014: val_loss improved from 3.50684 to 3.43156, saving model to Checkpoint.h5\n","Epoch 15/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.4487 - dice_coef: 0.9777 - accuracy: 0.9788 - val_loss: 3.4811 - val_dice_coef: 0.9798 - val_accuracy: 0.9807\n","\n","Epoch 00015: val_loss did not improve from 3.43156\n","Epoch 16/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.4307 - dice_coef: 0.9777 - accuracy: 0.9786 - val_loss: 3.4066 - val_dice_coef: 0.9813 - val_accuracy: 0.9837\n","\n","Epoch 00016: val_loss improved from 3.43156 to 3.40662, saving model to Checkpoint.h5\n","Epoch 17/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.3632 - dice_coef: 0.9798 - accuracy: 0.9807 - val_loss: 3.4399 - val_dice_coef: 0.9780 - val_accuracy: 0.9806\n","\n","Epoch 00017: val_loss did not improve from 3.40662\n","Epoch 18/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.3530 - dice_coef: 0.9785 - accuracy: 0.9793 - val_loss: 3.3579 - val_dice_coef: 0.9803 - val_accuracy: 0.9822\n","\n","Epoch 00018: val_loss improved from 3.40662 to 3.35791, saving model to Checkpoint.h5\n","Epoch 19/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.3211 - dice_coef: 0.9802 - accuracy: 0.9810 - val_loss: 3.3431 - val_dice_coef: 0.9821 - val_accuracy: 0.9838\n","\n","Epoch 00019: val_loss improved from 3.35791 to 3.34313, saving model to Checkpoint.h5\n","Epoch 20/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.2789 - dice_coef: 0.9777 - accuracy: 0.9784 - val_loss: 3.3311 - val_dice_coef: 0.9743 - val_accuracy: 0.9756\n","\n","Epoch 00020: val_loss improved from 3.34313 to 3.33108, saving model to Checkpoint.h5\n","Epoch 21/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.3289 - dice_coef: 0.9767 - accuracy: 0.9779 - val_loss: 3.3978 - val_dice_coef: 0.9809 - val_accuracy: 0.9834\n","\n","Epoch 00021: val_loss did not improve from 3.33108\n","Epoch 22/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.3088 - dice_coef: 0.9793 - accuracy: 0.9799 - val_loss: 3.3012 - val_dice_coef: 0.9802 - val_accuracy: 0.9804\n","\n","Epoch 00022: val_loss improved from 3.33108 to 3.30122, saving model to Checkpoint.h5\n","Epoch 23/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.2605 - dice_coef: 0.9773 - accuracy: 0.9776 - val_loss: 3.3181 - val_dice_coef: 0.9747 - val_accuracy: 0.9729\n","\n","Epoch 00023: val_loss did not improve from 3.30122\n","Epoch 24/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.2647 - dice_coef: 0.9801 - accuracy: 0.9802 - val_loss: 3.3088 - val_dice_coef: 0.9766 - val_accuracy: 0.9748\n","\n","Epoch 00024: val_loss did not improve from 3.30122\n","Epoch 25/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1994 - dice_coef: 0.9786 - accuracy: 0.9785 - val_loss: 3.3073 - val_dice_coef: 0.9815 - val_accuracy: 0.9821\n","\n","Epoch 00025: val_loss did not improve from 3.30122\n","Epoch 26/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.2215 - dice_coef: 0.9775 - accuracy: 0.9777 - val_loss: 3.2611 - val_dice_coef: 0.9804 - val_accuracy: 0.9819\n","\n","Epoch 00026: val_loss improved from 3.30122 to 3.26113, saving model to Checkpoint.h5\n","Epoch 27/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.2203 - dice_coef: 0.9799 - accuracy: 0.9802 - val_loss: 3.3112 - val_dice_coef: 0.9785 - val_accuracy: 0.9772\n","\n","Epoch 00027: val_loss did not improve from 3.26113\n","Epoch 28/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1676 - dice_coef: 0.9805 - accuracy: 0.9806 - val_loss: 3.2751 - val_dice_coef: 0.9809 - val_accuracy: 0.9809\n","\n","Epoch 00028: val_loss did not improve from 3.26113\n","Epoch 29/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1586 - dice_coef: 0.9780 - accuracy: 0.9783 - val_loss: 3.2614 - val_dice_coef: 0.9807 - val_accuracy: 0.9800\n","\n","Epoch 00029: val_loss did not improve from 3.26113\n","Epoch 30/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.2078 - dice_coef: 0.9797 - accuracy: 0.9799 - val_loss: 3.2670 - val_dice_coef: 0.9797 - val_accuracy: 0.9795\n","\n","Epoch 00030: val_loss did not improve from 3.26113\n","Epoch 31/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1761 - dice_coef: 0.9799 - accuracy: 0.9800 - val_loss: 3.2685 - val_dice_coef: 0.9777 - val_accuracy: 0.9769\n","\n","Epoch 00031: val_loss did not improve from 3.26113\n","Epoch 32/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1210 - dice_coef: 0.9782 - accuracy: 0.9784 - val_loss: 3.2646 - val_dice_coef: 0.9779 - val_accuracy: 0.9774\n","\n","Epoch 00032: val_loss did not improve from 3.26113\n","Epoch 33/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1596 - dice_coef: 0.9787 - accuracy: 0.9789 - val_loss: 3.3495 - val_dice_coef: 0.9718 - val_accuracy: 0.9744\n","\n","Epoch 00033: val_loss did not improve from 3.26113\n","Epoch 34/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1573 - dice_coef: 0.9811 - accuracy: 0.9812 - val_loss: 3.2597 - val_dice_coef: 0.9802 - val_accuracy: 0.9806\n","\n","Epoch 00034: val_loss improved from 3.26113 to 3.25972, saving model to Checkpoint.h5\n","Epoch 35/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.3237 - dice_coef: 0.9710 - accuracy: 0.9714 - val_loss: 3.2979 - val_dice_coef: 0.9793 - val_accuracy: 0.9795\n","\n","Epoch 00035: val_loss did not improve from 3.25972\n","Epoch 36/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1790 - dice_coef: 0.9771 - accuracy: 0.9774 - val_loss: 3.2506 - val_dice_coef: 0.9807 - val_accuracy: 0.9804\n","\n","Epoch 00036: val_loss improved from 3.25972 to 3.25062, saving model to Checkpoint.h5\n","Epoch 37/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1918 - dice_coef: 0.9809 - accuracy: 0.9812 - val_loss: 3.3548 - val_dice_coef: 0.9746 - val_accuracy: 0.9745\n","\n","Epoch 00037: val_loss did not improve from 3.25062\n","Epoch 38/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.2140 - dice_coef: 0.9787 - accuracy: 0.9790 - val_loss: 3.4258 - val_dice_coef: 0.9754 - val_accuracy: 0.9746\n","\n","Epoch 00038: val_loss did not improve from 3.25062\n","Epoch 39/100\n","444/444 [==============================] - 328s 738ms/step - loss: 3.1947 - dice_coef: 0.9798 - accuracy: 0.9800 - val_loss: 3.2785 - val_dice_coef: 0.9732 - val_accuracy: 0.9792\n","\n","Epoch 00039: val_loss did not improve from 3.25062\n","Epoch 40/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1678 - dice_coef: 0.9803 - accuracy: 0.9805 - val_loss: 3.2760 - val_dice_coef: 0.9794 - val_accuracy: 0.9794\n","\n","Epoch 00040: val_loss did not improve from 3.25062\n","Epoch 41/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1469 - dice_coef: 0.9789 - accuracy: 0.9792 - val_loss: 3.3645 - val_dice_coef: 0.9771 - val_accuracy: 0.9769\n","\n","Epoch 00041: val_loss did not improve from 3.25062\n","Epoch 42/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1760 - dice_coef: 0.9814 - accuracy: 0.9816 - val_loss: 3.2791 - val_dice_coef: 0.9782 - val_accuracy: 0.9781\n","\n","Epoch 00042: val_loss did not improve from 3.25062\n","Epoch 43/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1515 - dice_coef: 0.9809 - accuracy: 0.9812 - val_loss: 3.2465 - val_dice_coef: 0.9781 - val_accuracy: 0.9778\n","\n","Epoch 00043: val_loss improved from 3.25062 to 3.24654, saving model to Checkpoint.h5\n","Epoch 44/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1692 - dice_coef: 0.9806 - accuracy: 0.9808 - val_loss: 3.3916 - val_dice_coef: 0.9748 - val_accuracy: 0.9744\n","\n","Epoch 00044: val_loss did not improve from 3.24654\n","Epoch 45/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1115 - dice_coef: 0.9804 - accuracy: 0.9806 - val_loss: 3.2083 - val_dice_coef: 0.9815 - val_accuracy: 0.9817\n","\n","Epoch 00045: val_loss improved from 3.24654 to 3.20830, saving model to Checkpoint.h5\n","Epoch 46/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1819 - dice_coef: 0.9800 - accuracy: 0.9802 - val_loss: 3.2506 - val_dice_coef: 0.9787 - val_accuracy: 0.9787\n","\n","Epoch 00046: val_loss did not improve from 3.20830\n","Epoch 47/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1963 - dice_coef: 0.9809 - accuracy: 0.9811 - val_loss: 3.2816 - val_dice_coef: 0.9771 - val_accuracy: 0.9767\n","\n","Epoch 00047: val_loss did not improve from 3.20830\n","Epoch 48/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1468 - dice_coef: 0.9804 - accuracy: 0.9807 - val_loss: 3.2024 - val_dice_coef: 0.9795 - val_accuracy: 0.9794\n","\n","Epoch 00048: val_loss improved from 3.20830 to 3.20245, saving model to Checkpoint.h5\n","Epoch 49/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1483 - dice_coef: 0.9805 - accuracy: 0.9807 - val_loss: 3.2264 - val_dice_coef: 0.9807 - val_accuracy: 0.9807\n","\n","Epoch 00049: val_loss did not improve from 3.20245\n","Epoch 50/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1412 - dice_coef: 0.9800 - accuracy: 0.9803 - val_loss: 3.4181 - val_dice_coef: 0.8931 - val_accuracy: 0.9013\n","\n","Epoch 00050: val_loss did not improve from 3.20245\n","Epoch 51/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1379 - dice_coef: 0.9817 - accuracy: 0.9819 - val_loss: 3.2114 - val_dice_coef: 0.9787 - val_accuracy: 0.9792\n","\n","Epoch 00051: val_loss did not improve from 3.20245\n","Epoch 52/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1544 - dice_coef: 0.9806 - accuracy: 0.9808 - val_loss: 3.2029 - val_dice_coef: 0.9766 - val_accuracy: 0.9765\n","\n","Epoch 00052: val_loss did not improve from 3.20245\n","Epoch 53/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1057 - dice_coef: 0.9804 - accuracy: 0.9806 - val_loss: 3.2732 - val_dice_coef: 0.9827 - val_accuracy: 0.9827\n","\n","Epoch 00053: val_loss did not improve from 3.20245\n","Epoch 54/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1372 - dice_coef: 0.9810 - accuracy: 0.9813 - val_loss: 3.5732 - val_dice_coef: 0.8795 - val_accuracy: 0.9183\n","\n","Epoch 00054: val_loss did not improve from 3.20245\n","Epoch 55/100\n","444/444 [==============================] - 328s 738ms/step - loss: 3.1604 - dice_coef: 0.9790 - accuracy: 0.9792 - val_loss: 3.3261 - val_dice_coef: 0.9813 - val_accuracy: 0.9813\n","\n","Epoch 00055: val_loss did not improve from 3.20245\n","Epoch 56/100\n","444/444 [==============================] - 328s 738ms/step - loss: 3.1790 - dice_coef: 0.9789 - accuracy: 0.9791 - val_loss: 3.2455 - val_dice_coef: 0.9718 - val_accuracy: 0.9772\n","\n","Epoch 00056: val_loss did not improve from 3.20245\n","Epoch 57/100\n","444/444 [==============================] - 328s 738ms/step - loss: 3.2016 - dice_coef: 0.9814 - accuracy: 0.9816 - val_loss: 3.2198 - val_dice_coef: 0.9796 - val_accuracy: 0.9814\n","\n","Epoch 00057: val_loss did not improve from 3.20245\n","Epoch 58/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1083 - dice_coef: 0.9778 - accuracy: 0.9780 - val_loss: 3.2780 - val_dice_coef: 0.9790 - val_accuracy: 0.9806\n","\n","Epoch 00058: val_loss did not improve from 3.20245\n","Epoch 59/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1115 - dice_coef: 0.9801 - accuracy: 0.9804 - val_loss: 3.1849 - val_dice_coef: 0.9805 - val_accuracy: 0.9815\n","\n","Epoch 00059: val_loss improved from 3.20245 to 3.18491, saving model to Checkpoint.h5\n","Epoch 60/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1236 - dice_coef: 0.9811 - accuracy: 0.9813 - val_loss: 3.2151 - val_dice_coef: 0.9800 - val_accuracy: 0.9798\n","\n","Epoch 00060: val_loss did not improve from 3.18491\n","Epoch 61/100\n","444/444 [==============================] - 328s 738ms/step - loss: 3.0695 - dice_coef: 0.9796 - accuracy: 0.9798 - val_loss: 3.1546 - val_dice_coef: 0.9832 - val_accuracy: 0.9833\n","\n","Epoch 00061: val_loss improved from 3.18491 to 3.15457, saving model to Checkpoint.h5\n","Epoch 62/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1555 - dice_coef: 0.9797 - accuracy: 0.9799 - val_loss: 3.2134 - val_dice_coef: 0.9784 - val_accuracy: 0.9787\n","\n","Epoch 00062: val_loss did not improve from 3.15457\n","Epoch 63/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.0868 - dice_coef: 0.9813 - accuracy: 0.9815 - val_loss: 3.1908 - val_dice_coef: 0.9805 - val_accuracy: 0.9821\n","\n","Epoch 00063: val_loss did not improve from 3.15457\n","Epoch 64/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1204 - dice_coef: 0.9819 - accuracy: 0.9821 - val_loss: 3.1572 - val_dice_coef: 0.9835 - val_accuracy: 0.9836\n","\n","Epoch 00064: val_loss did not improve from 3.15457\n","Epoch 65/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1427 - dice_coef: 0.9807 - accuracy: 0.9809 - val_loss: 3.2233 - val_dice_coef: 0.9803 - val_accuracy: 0.9807\n","\n","Epoch 00065: val_loss did not improve from 3.15457\n","Epoch 66/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1647 - dice_coef: 0.9819 - accuracy: 0.9820 - val_loss: 3.3843 - val_dice_coef: 0.9813 - val_accuracy: 0.9812\n","\n","Epoch 00066: val_loss did not improve from 3.15457\n","Epoch 67/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1436 - dice_coef: 0.9803 - accuracy: 0.9805 - val_loss: 3.2133 - val_dice_coef: 0.9779 - val_accuracy: 0.9780\n","\n","Epoch 00067: val_loss did not improve from 3.15457\n","Epoch 68/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1589 - dice_coef: 0.9797 - accuracy: 0.9799 - val_loss: 3.2650 - val_dice_coef: 0.9749 - val_accuracy: 0.9778\n","\n","Epoch 00068: val_loss did not improve from 3.15457\n","Epoch 69/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1731 - dice_coef: 0.9812 - accuracy: 0.9814 - val_loss: 3.1947 - val_dice_coef: 0.9825 - val_accuracy: 0.9825\n","\n","Epoch 00069: val_loss did not improve from 3.15457\n","Epoch 70/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1174 - dice_coef: 0.9809 - accuracy: 0.9811 - val_loss: 3.1850 - val_dice_coef: 0.9803 - val_accuracy: 0.9807\n","\n","Epoch 00070: val_loss did not improve from 3.15457\n","Epoch 71/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.1237 - dice_coef: 0.9792 - accuracy: 0.9794 - val_loss: 3.2040 - val_dice_coef: 0.9782 - val_accuracy: 0.9787\n","\n","Epoch 00071: val_loss did not improve from 3.15457\n","Epoch 72/100\n","444/444 [==============================] - 328s 739ms/step - loss: 3.0943 - dice_coef: 0.9808 - accuracy: 0.9811 - val_loss: 3.2702 - val_dice_coef: 0.9796 - val_accuracy: 0.9795\n","\n","Epoch 00072: val_loss did not improve from 3.15457\n","Epoch 73/100\n","131/444 [=======>......................] - ETA: 3:38 - loss: 3.1352 - dice_coef: 0.9803 - accuracy: 0.9805"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XzwipgD8UuIy","colab_type":"code","colab":{}},"source":["def stitchMaskPatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img\n","\n","\n","def stitchImagePatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920,3])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240,:] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KNI0eyqvGcy","colab_type":"code","colab":{}},"source":["def saveNumpyOutput(mask, Patient_array,Patient_length,title,folder):\n","  idx = 0\n","  for i in range(len(Patient_length)):\n","    temp = []\n","    for j in range(Patient_length[i]):\n","      final_output = mask[idx:idx+48]\n","      idx = idx + 48\n","      final_output = stitchMaskPatches(final_output)\n","      temp.append(final_output)\n","    final_output = np.asarray(temp)\n","    np.save(folder + title + Patient_array[i], final_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NErfv7ZJ7Bxr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592127682622,"user_tz":-330,"elapsed":1051,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"01b6657e-18d9-42bd-c840-f2e832c66bf7"},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/4 Class/PR/3Fold LadderNet/\"\n","model_names = os.listdir(MODELS_PATH)\n","print(model_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['LadderNet_ER_v2_0.h5', 'LadderNet_ER_v2_1.h5', 'LadderNet_ER_v2_2.h5', 'FoC_TVCombined_LadderNet_ER_v2_30.h5']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2bo0X0lXSwE6","colab_type":"code","colab":{}},"source":["SAVE_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/ER/3Fold LadderNet/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-zmdlCcbBGn","colab_type":"code","colab":{}},"source":["# Axis 0 = Folds\n","# Axis 1 = Class (Strong Intermediate,Weak,Background)\n","# Axis 2 = Evaluation Technique (Precision, Recall, Dice coefficient)\n","pixEvaluationTrain = np.empty((0,4,3))\n","pixEvaluationTest = np.empty((0,4,3))\n","score = np.zeros((1,4,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wl31sylb0qvs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592128068731,"user_tz":-330,"elapsed":317759,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"43331138-a68f-48d5-c504-267bf44ba1ec"},"source":["fold = 0\n","\n","for train_index, test_index in fold_split:\n","  print(\"FOLD:\",fold,\"\\tTRAIN:\", train_index, \"TEST:\", test_index)\n","  # Splitting Train and Test data\n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  train_no = [patient_no[i] for i in train_index]\n","  train_size = [size[i] for i in train_index]\n","\n","  test_no = [patient_no[i] for i in test_index]\n","  test_size = [size[i] for i in test_index]\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","\n","  convertToLabels(TrainY)\n","  convertToLabels(TestY)\n","\n","  # TrainY = keras.utils.to_categorical(TrainY,num_classes=4,dtype='int16')\n","  # TestY = keras.utils.to_categorical(TestY,num_classes=4,dtype='int16')\n","  \n","  # Loading corrosponding fold of model\n","  model = keras.models.load_model(MODELS_PATH + model_names[i],custom_objects={ 'combined_loss': combined_loss, 'dice_coef': dice_coef })\n","\n","  # Predicting results using model\n","  trainResult = model.predict(TrainX, batch_size=8)\n","  testResult = model.predict(TestX,batch_size=8)\n","\n","  trainResult = np.argmax(trainResult,axis=-1)\n","  testResult = np.argmax(testResult,axis=-1)\n","\n","  # trainOneHot = keras.utils.to_categorical(trainResult,num_classes=4,dtype='int16')\n","  # testOneHot = keras.utils.to_categorical(testResult,num_classes=4,dtype='int16')\n","\n","  # Obtaining pixel-wise results: Precision recall and dice coefficient\n","  # For TRAIN\n","  y_true = np.reshape(TrainY,(-1))\n","  y_pred = np.reshape(trainResult,(-1))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(4):\n","    score[0][i][0] = prec[3-i]\n","    score[0][i][1] = recall[3-i]\n","    score[0][i][2] = dice[3-i]\n","\n","  pixEvaluationTrain = np.append(pixEvaluationTrain,score,axis=0)\n"," \n","  # For TEST\n","  y_true = np.reshape(TestY,(-1))\n","  y_pred = np.reshape(testResult,(-1))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2,3],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(4):\n","    score[0][i][0] = prec[3-i]\n","    score[0][i][1] = recall[3-i]\n","    score[0][i][2] = dice[3-i]\n","\n","  pixEvaluationTest = np.append(pixEvaluationTest,score,axis=0)\n","\n","  # Converting predicted labels to required output format\n","  # convertFromLabels(trainResult)\n","  # convertFromLabels(testResult)\n","\n","  # # Saving numpy arrays\n","  # path = os.path.join(SAVE_PATH,\"Fold \" + str(fold))\n","  # os.mkdir(path)\n","  # os.mkdir(path + '/Train')\n","  # os.mkdir(path + '/Test')\n","\n","  # saveNumpyOutput(trainResult, train_no, train_size,\"/Train/\",path)\n","  # saveNumpyOutput(testResult, test_no, test_size,\"/Test/\",path)\n","\n","  fold +=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FOLD: 0 \tTRAIN: [2, 3, 4, 5, 6, 7, 8] TEST: [0, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IeQAQsZexovM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1592128075889,"user_tz":-330,"elapsed":1017,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"843ae3df-1565-46ed-faf0-9670a3a3b970"},"source":["print(pixEvaluationTrain.shape)\n","print(pixEvaluationTest.shape)\n","print(pixEvaluationTest)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 4, 3)\n","(1, 4, 3)\n","[[[0.88057365 0.38439159 0.53516902]\n","  [0.44256609 0.71980221 0.5481224 ]\n","  [0.46586629 0.1725451  0.25182178]\n","  [0.97250802 0.98358452 0.97801491]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBNZbrAiyEhO","colab_type":"code","colab":{}},"source":["np.save(SAVE_PATH + \"Pixel-wise Metrics Train.npy\", pixEvaluationTrain)\n","np.save(SAVE_PATH + \"Pixel-wise Metrics Test.npy\", pixEvaluationTest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZwjDP44MUTa6","colab_type":"text"},"source":["# **DISPLAY**"]},{"cell_type":"code","metadata":{"id":"DzUOdXOKU2nb","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","\n","plt.figure(figsize=(20,20))\n","id = 48   # enter between 0- 50 since there are 5 patients with 10 images each\n","\n","id = id * 48\n","final_input = TestX[id:id+48]\n","Mask_input = TestGT[id:id+48]\n","final_output = testResult[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","final_output = stitchMaskPatches(final_output)\n","\n","print(final_input.shape)\n","print(final_output.shape)\n","print(Mask_input.shape)\n","\n","print(np.unique(final_output))\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","plt.subplot(132).imshow(Mask_input,'gray')\n","plt.subplot(133).imshow(final_output,'gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5IqVx01JeWn","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","\n","plt.figure(figsize=(20,20))\n","id = 25  # enter between 0- 40 since there are 4 patients with 10 images each\n","\n","id = id * 48\n","final_input = TrainX[id:id+48]\n","Mask_input = TrainGT[id:id+48]\n","final_output = trainResult[id:id+48]\n","\n","final_input = stitchImagePatches(final_input)\n","Mask_input =  stitchMaskPatches(Mask_input)\n","final_output = stitchMaskPatches(final_output)\n","\n","print(final_input.shape)\n","print(final_output.shape)\n","print(Mask_input.shape)\n","\n","print(np.unique(final_output))\n","copy1  = np.copy(final_input)\n","copy2 = copy1.astype('float32')*255\n","copy2 = copy2.astype('uint8')\n","final_input = np.reshape(copy2,(1440, 1920,3))\n","final_input = cv2.cvtColor(final_input,cv2.COLOR_BGR2RGB)\n","\n","plt.subplot(131).imshow(final_input)\n","plt.subplot(132).imshow(Mask_input,'gray')\n","plt.subplot(133).imshow(final_output,'gray')"],"execution_count":null,"outputs":[]}]}