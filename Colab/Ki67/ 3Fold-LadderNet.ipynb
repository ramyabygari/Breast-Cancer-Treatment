{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" 3Fold-LadderNet.ipynb","provenance":[{"file_id":"1pTDK7f8kySKtgvQS3laO9se6YJ9cmygK","timestamp":1592249134658},{"file_id":"1kclRk2A0EQRyBAn_W2Zq4bnWtfFnFgWX","timestamp":1592200615366},{"file_id":"1dLxM_AMOSs32Mxu42FNwumVVm11sLpeG","timestamp":1589298710575},{"file_id":"17lvwlvqQV7B-wqN2ajx7Q2UwCZwCd-WD","timestamp":1586698406636},{"file_id":"1SAeOlks1aRTndKfvFcMtNB7V3Ik6nfN0","timestamp":1586361815646},{"file_id":"1puNfvA8GEtqbsfDMP30_RS6XRrNM8Ky8","timestamp":1586249758540},{"file_id":"1QPxGukBl9nFKfyxsNhM4lUw4rYauJaY1","timestamp":1586242198727},{"file_id":"1txy9g7gYnELmPTY6sT4JtfbhwQthIyoG","timestamp":1583812009231},{"file_id":"1a9BwVwMfQ4iFdte5xgs4kzj58JNqs4Vu","timestamp":1579539718864},{"file_id":"1KyLESiefS0uSAi_kTOAZ9NmNUSYTs9lL","timestamp":1578995412588},{"file_id":"1YDTADQrLw8-aYCSjOEYxDuIB1nuy3Xzm","timestamp":1577686452735},{"file_id":"1DqrMpMvIbzPtWFjsL_eNwrVM-xaFvx6c","timestamp":1571727299009}],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ixvBWa23MB7e","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzNbXYWE4I5E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":881},"executionInfo":{"status":"ok","timestamp":1593694008840,"user_tz":-330,"elapsed":10563,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"de26fb68-f3c4-46ab-852e-1cf50bda07f2"},"source":["import os\n","import cv2\n","import numpy as np\n","!pip install -U keras\n","!pip install tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting keras\n","  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.12.0)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.3.1\n","    Uninstalling Keras-2.3.1:\n","      Successfully uninstalled Keras-2.3.1\n","Successfully installed keras-2.4.3\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (47.3.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Mk6pnB6tFp0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":674},"executionInfo":{"status":"ok","timestamp":1593694016463,"user_tz":-330,"elapsed":6454,"user":{"displayName":"Rachita Naik","photoUrl":"","userId":"14510745843387847980"}},"outputId":"c6635869-9279-417a-b8ba-c1a18e8d3bda"},"source":["import math\n","import random\n","import keras\n","from keras.layers import *\n","from keras.models import Sequential\n","from keras import Model\n","from keras import backend as K  \n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","!pip install tensorflow\n","\n","import tensorflow as tf\n","from sklearn.model_selection import LeaveOneOut\n","from sklearn import metrics"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (47.3.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U4SPHrcLZH4a","colab":{}},"source":["def get_conv_block(input_layer,nFilters,size):\n","    conv1 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(input_layer)\n","    bn1 = BatchNormalization()(conv1)\n","    conv2 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(bn1)\n","    bn2 = BatchNormalization()(conv2)\n","    return bn2\n","    \n","def get_UNET(input_layer,nFilters,flag): \n","\n","    block1 = get_conv_block(input_layer[0],nFilters,3)\n","    mp1 = MaxPooling2D(pool_size=(2, 2))(block1)\n","    dr1 = Dropout(0.1)(mp1)\n","   \n","    if(flag==1):\n","      dr1 = concatenate([dr1,input_layer[1]])\n","\n","    block2 = get_conv_block(dr1,nFilters*2,3)\n","    mp2 = MaxPooling2D(pool_size=(2, 2))(block2)\n","    dr2 = Dropout(0.1)(mp2)\n","\n","    if(flag==1):\n","      dr2 = concatenate([dr2,input_layer[2]])\n","   \n","    block3 = get_conv_block(dr2,nFilters*4,3)\n","    mp3 = MaxPooling2D(pool_size=(2, 2))(block3)\n","    dr3 = Dropout(0.1)(mp3)\n","\n","    if(flag==1):\n","      dr3 = concatenate([dr3,input_layer[3]])\n","       \n","    block4 = get_conv_block(dr3,nFilters*8,3)\n","    mp4 = MaxPooling2D(pool_size=(2, 2))(block4)\n","    dr4 = Dropout(0.1)(mp4)\n","\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(dr4)\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(conv5)\n","\n","    up1 = Conv2DTranspose(nFilters*8,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(conv5)\n","    cat1 = concatenate([block4, up1])\n","    dr1 = Dropout(0.1)(cat1)\n","    block5 = get_conv_block(dr1,nFilters*8,3)\n","\n","    up2 = Conv2DTranspose(nFilters*4,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block5)\n","    cat2 = concatenate([block3, up2,])\n","    dr2 = Dropout(0.1)(cat2)\n","    block6 = get_conv_block(dr2,nFilters*4,3)\n","    \n","    up3 = Conv2DTranspose(nFilters*2,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block6)\n","    cat3 = concatenate([block2, up3])\n","    dr3 = Dropout(0.1)(cat3)\n","    block7 = get_conv_block(dr3,nFilters*2,3)\n","    \n","    up4 = Conv2DTranspose(nFilters,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block7)\n","    cat4 = concatenate([block1, up4])\n","    dr4 = Dropout(0.1)(cat4)\n","    block8 = get_conv_block(dr4,nFilters,3)\n","\n","    conv10 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(block8)\n","    conv11 = Conv2D(3,(1,1), activation='softmax', padding = 'same',kernel_regularizer=l2(1e-4))(conv10)\n","\n","    return (conv11, block7, block6, block5)\n","\n","def get_model(input_shape,nFilters1,nFilters2):\n","\n","    input_layer = Input(shape=input_shape)\n","    out1,out2,out3,out4 = get_UNET([input_layer],nFilters1,0)\n","\n","    out1,out2,out3,out4 = get_UNET([out1,out2,out3,out4],nFilters2,1)\n","\n","    model = Model(input_layer,out1)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiXrY-SjvEMW","colab_type":"code","colab":{}},"source":["PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Ki67\"\n","\n","\n","X1  = np.load(PATH + '/Ki67 IHC 230 Images.npy')\n","Y1  = np.load(PATH + '/Ki67 IHC 230 Masks.npy')\n","\n","X2  = np.load(PATH + '/Ki67 IHC 232 Images.npy')\n","Y2  = np.load(PATH + '/Ki67 IHC 232 Masks.npy')\n","\n","X3  = np.load(PATH + '/Ki67 IHC 242 Images.npy')\n","Y3  = np.load(PATH + '/Ki67 IHC 242 Masks.npy')\n","\n","X4  = np.load(PATH + '/Ki67 IHC 263 Images.npy')\n","Y4  = np.load(PATH + '/Ki67 IHC 263 Masks.npy')\n","\n","X5 = np.load(PATH + '/Ki67 IHC 221 Images.npy')\n","Y5 = np.load(PATH + '/Ki67 IHC 221 Masks.npy')\n","\n","X6 = np.load(PATH + '/Ki67 IHC 229 Images.npy')\n","Y6 = np.load(PATH + '/Ki67 IHC 229 Masks.npy')\n","\n","X7 = np.load(PATH + '/Ki67 IHC 239 Images.npy')\n","Y7 = np.load(PATH + '/Ki67 IHC 239 Masks.npy')\n","\n","X8 = np.load(PATH + '/Ki67 IHC 246 Images.npy')\n","Y8 = np.load(PATH + '/Ki67 IHC 246 Masks.npy')\n","\n","X9 = np.load(PATH + '/Ki67 IHC 252 Images.npy')\n","Y9 = np.load(PATH + '/Ki67 IHC 252 Masks.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8B4TY8y22Zgp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1593186460225,"user_tz":-330,"elapsed":76073,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"outputId":"89e2b1a0-22d8-49df-92a7-bd7571fabc84"},"source":["print(X1.shape[0]/48)\n","print(X2.shape[0]/48)\n","print(X3.shape[0]/48)\n","print(X4.shape[0]/48)\n","print(X5.shape[0]/48)\n","print(X6.shape[0]/48)\n","print(X7.shape[0]/48)\n","print(X8.shape[0]/48)\n","print(X9.shape[0]/48)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10.0\n","10.0\n","11.0\n","11.0\n","10.0\n","10.0\n","10.0\n","10.0\n","10.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"URoo6JnVKIk8","colab_type":"code","colab":{}},"source":["X = [X1, X2, X3, X4, X5, X6, X7, X8, X9]\n","Y = [Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y9]\n","patient_no = ['230','232','242','263','221','229','239','246','252']\n","size = [10,10,11,11,10,10,10,10,10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4pG3Bj-uKD9","colab_type":"code","colab":{}},"source":["fold_split = []\n","\n","#test patient = 230, 232 \n","fold_split.append(([2,3,4,5,6,7,8],[0,1]))\n","\n","#test_patient = 239, 242\n","fold_split.append(([0,1,3,4,5,7,8],[2,6]))\n","\n","#test_patient = 252,263\n","fold_split.append(([0,1,2,4,5,6,7],[3,8]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MujkbhpsnE9","colab_type":"code","colab":{}},"source":["def convertToLabels(data):\n","  data[data==128]=1\n","  data[data==255]=2\n","\n","def convertFromLabels(data):\n","  data[data==1]=128\n","  data[data==2]=255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDodKs-AMB81","colab_type":"code","colab":{}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TH9yDcoO6Kyg","colab_type":"code","colab":{}},"source":["def tversky_loss_1(y_true, y_pred):\n","    alpha = 0.7\n","    beta  = 0.3\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","  \n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    # \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def tversky_loss_2(y_true, y_pred):\n","    alpha = 0.3\n","    beta  = 0.7\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    # \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def focal_tversky_loss_1(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_1(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","  \n","def focal_tversky_loss_2(y_true, y_pred, gamma=0.75):\n","    tversky_index = tversky_loss_2(y_true, y_pred)\n","    return K.pow((tversky_index), gamma)\n","\n","def combined_loss(y_true, y_pred):\n","  return (0.2*K.categorical_crossentropy(y_true, y_pred))+(0.8*focal_tversky_loss_1(y_true, y_pred)+(0.8*focal_tversky_loss_2(y_true, y_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMnXb4wMMB88","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping,ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyEYstIcMB9B","colab_type":"code","colab":{}},"source":["optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaGvHbqtarli","colab_type":"code","colab":{}},"source":["batch_size = 8\n","def get_batch(batch_size, X_train, Y_train): \n","    size_batch = batch_size\n","    last_index = len(X_train) - 1\n","    x_train = X_train\n","    y_train = Y_train \n","    while True:\n","        batch_data = [[],[]]\n","        for i in range(0, size_batch):\n","            random_index = random.randint(0, last_index)\n","            batch_data[0].append(x_train[random_index])\n","            batch_data[1].append(y_train[random_index])\n","\n","        yield (np.array(batch_data[0]), np.array(batch_data[1]))     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZyYYJKGUS42X","colab_type":"code","colab":{}},"source":["tf.compat.v1.disable_eager_execution()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2oPUnPxoA6B","colab_type":"code","colab":{}},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/Ki67/Combined FTL\"\n","\n","fold = 2\n","\n","for train_index, test_index in fold_split:\n","  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","  if(test_index[0]==0 or test_index[0]==2):\n","    continue\n","  \n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  # Train = list(zip(TrainX,TrainY))\n","  # random.shuffle(Train)\n","  # TrainX,TrainY = zip(*Train)\n","  # TrainX = np.asarray(list(TrainX))\n","  # TrainY = np.asarray(list(TrainY))\n","\n","  # Test = list(zip(TestX,TestY))\n","  # random.shuffle(Test)\n","  # TestX,TestY = zip(*Test)\n","  # TestX = np.asarray(list(TestX))\n","  # TestY = np.asarray(list(TestY))\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","  convertToLabels(TrainY)\n","  TrainY = keras.utils.to_categorical(TrainY,num_classes=3,dtype='int16')\n","  convertToLabels(TestY)\n","  TestY = keras.utils.to_categorical(TestY,num_classes=3,dtype='int16')\n","  ValX = TrainX[(int)(0.8*TrainX.shape[0]):]\n","  ValY = TrainY[(int)(0.8*TrainY.shape[0]):]\n","  model = get_model((240,240,3),32,64)\n","\n","  \n","  mc = ModelCheckpoint(MODELS_PATH +'/Checkpoints/Checkpoint '+str(fold) +'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","  optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)\n","\n","  model.compile(loss=combined_loss, optimizer= optimizer , metrics=[dice_coef,'accuracy']) \n","  num_epoch = 100\n","  datagen = get_batch(batch_size, TrainX, TrainY)\n","  n_points = len(TrainX)\n","  print('-----------fold {}--------------'.format(fold))\n","  history = model.fit(datagen, validation_data = [ValX, ValY],\n","                  epochs=num_epoch,steps_per_epoch = math.ceil(n_points / batch_size), callbacks =[mc],  shuffle =True)\n","  model.save(MODELS_PATH + '/Ki67 '+ str(fold) +'.h5')\n","  fold = fold + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XzwipgD8UuIy","colab_type":"code","colab":{}},"source":["def stitchMaskPatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img\n","\n","\n","def stitchImagePatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920,3])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240,:] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7rOZOq1M7lm","colab_type":"code","colab":{}},"source":["def saveNumpyOutput(mask, Patient_array,Patient_length,title,folder):\n","  idx = 0\n","  for i in range(len(Patient_length)):\n","    temp = []\n","    for j in range(Patient_length[i]):\n","      final_output = mask[idx:idx+48]\n","      idx = idx + 48\n","      final_output = stitchMaskPatches(final_output)\n","      temp.append(final_output)\n","    final_output = np.asarray(temp)\n","    np.save(folder + title + Patient_array[i], final_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_seHRjOYNLO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593186515452,"user_tz":-330,"elapsed":1795,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"outputId":"5f1f68ba-a95b-47cc-dcc9-116847a29aa6"},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/Ki67/Combined FTL/Ki67/\"\n","model_names = os.listdir(MODELS_PATH)\n","print(model_names)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Ki67 0.h5', 'Ki67 2.h5', 'Ki67 1.h5']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x-ad_aPT0HPU","colab_type":"code","colab":{}},"source":["SAVE_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/Ki67/3Fold LadderNet/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrOgLuXs0fzn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1593188676513,"user_tz":-330,"elapsed":1035,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"outputId":"6e6bc676-e646-418f-f155-2a326c753bdf"},"source":["# Axis 0 = Folds\n","# Axis 1 = Class (Backround, Immunopositive,Immunongative)\n","# Axis 2 = Evaluation Technique (Precision, Recall, Dice coefficient)\n","pixEvaluationTrain = np.empty((0,3,3))\n","pixEvaluationTest = np.empty((0,3,3))\n","score = np.zeros((1,3,3))\n","print(pixEvaluationTrain.shape)\n","print(pixEvaluationTest.shape)\n","print(score.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0, 3, 3)\n","(0, 3, 3)\n","(1, 3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qIijdgE31k8S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":903},"executionInfo":{"status":"ok","timestamp":1593190117948,"user_tz":-330,"elapsed":1360675,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"outputId":"26bd0eca-40d4-4860-ee56-ce5843deae61"},"source":["\n","fold = 0\n","\n","for train_index, test_index in fold_split:\n"," \n","  print(\"FOLD:\",fold,\"\\tTRAIN:\", train_index, \"TEST:\", test_index)\n"," #Splitting Train and Test data\n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  train_no = [patient_no[i] for i in train_index]\n","  train_size = [size[i] for i in train_index]\n","  print(train_no)\n","\n","  test_no = [patient_no[i] for i in test_index]\n","  test_size = [size[i] for i in test_index]\n","  print(test_no)\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","\n","  convertToLabels(TrainY)\n","  convertToLabels(TestY)\n","\n","  TrainY = keras.utils.to_categorical(TrainY,num_classes=3, dtype='int16')\n","  TestY  = keras.utils.to_categorical(TestY, num_classes=3, dtype='int16')\n","  \n","  # Loading corrosponding fold of model\n","  model = keras.models.load_model(MODELS_PATH + model_names[fold],custom_objects={ 'combined_loss': combined_loss, 'dice_coef': dice_coef })\n","\n","  # Predicting results using model\n","  trainResult = model.predict(TrainX, batch_size=8)\n","  testResult = model.predict(TestX,batch_size=8)\n","\n","  trainResult = np.argmax(trainResult,axis=-1)\n","  testResult = np.argmax(testResult,axis=-1)\n","\n","  trainOneHot = keras.utils.to_categorical(trainResult,num_classes=3, dtype='int16')\n","  testOneHot = keras.utils.to_categorical(testResult,  num_classes=3, dtype='int16')\n","\n","  # Obtaining pixel-wise results: Precision recall and dice coefficient\n","  # For TRAIN\n","  y_true = np.reshape(TrainY,(-1, TrainY.shape[3]))\n","  y_pred = np.reshape(trainOneHot,(-1, trainOneHot.shape[3]))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  \n","  #Precision Recall Dice for each class  #0 : Background, 1 : Immunonegative, 2:Immunopositive \n","  for i in range(3):\n","    score[0][i][0] = prec[i]\n","    score[0][i][1] = recall[i]\n","    score[0][i][2] = dice[i]\n","\n","  pixEvaluationTrain = np.append(pixEvaluationTrain,score,axis=0)\n","  print(pixEvaluationTrain)\n"," \n","  # For TEST\n","  y_true = np.reshape(TestY,(-1, TestY.shape[3]))\n","  y_pred = np.reshape(testOneHot,(-1, testOneHot.shape[3]))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(3):\n","    score[0][i][0] = prec[i]\n","    score[0][i][1] = recall[i]\n","    score[0][i][2] = dice[i]\n","\n","  pixEvaluationTest = np.append(pixEvaluationTest,score,axis=0)\n","  print(pixEvaluationTest)\n","\n","#   # Converting predicted labels to required output format\n","#   convertFromLabels(trainResult)\n","#   convertFromLabels(testResult)\n","\n","#  # Saving numpy arrays\n","#   path = os.path.join(SAVE_PATH,\"Fold \" + str(fold))\n","#   os.mkdir(path)\n","#   os.mkdir(path + '/Train')\n","#   os.mkdir(path + '/Test')\n","\n","#   saveNumpyOutput(trainResult, train_no, train_size,\"/Train/\",path)\n","#   saveNumpyOutput(testResult, test_no, test_size,\"/Test/\",path)\n","\n","  fold +=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FOLD: 0 \tTRAIN: [2, 3, 4, 5, 6, 7, 8] TEST: [0, 1]\n","['242', '263', '221', '229', '239', '246', '252']\n","['230', '232']\n","[[[0.95641806 0.96895468 0.96264556]\n","  [0.87621469 0.84015417 0.85780562]\n","  [0.90193241 0.85918155 0.88003809]]]\n","[[[0.92102706 0.94215552 0.93147149]\n","  [0.76701273 0.75982919 0.76340407]\n","  [0.89976114 0.72169478 0.80095044]]]\n","FOLD: 0 \tTRAIN: [0, 1, 3, 4, 5, 7, 8] TEST: [2, 6]\n","['230', '232', '263', '221', '229', '246', '252']\n","['242', '239']\n","[[[0.95641806 0.96895468 0.96264556]\n","  [0.87621469 0.84015417 0.85780562]\n","  [0.90193241 0.85918155 0.88003809]]\n","\n"," [[0.95019373 0.96422227 0.9571566 ]\n","  [0.83326969 0.80874431 0.82082384]\n","  [0.90573671 0.82040347 0.86096083]]]\n","[[[0.92102706 0.94215552 0.93147149]\n","  [0.76701273 0.75982919 0.76340407]\n","  [0.89976114 0.72169478 0.80095044]]\n","\n"," [[0.94426542 0.96001749 0.9520763 ]\n","  [0.88811384 0.85019871 0.86874279]\n","  [0.89446372 0.85813998 0.87592544]]]\n","FOLD: 0 \tTRAIN: [0, 1, 2, 4, 5, 6, 7] TEST: [3, 8]\n","['230', '232', '242', '221', '229', '239', '246']\n","['263', '252']\n","[[[0.95641806 0.96895468 0.96264556]\n","  [0.87621469 0.84015417 0.85780562]\n","  [0.90193241 0.85918155 0.88003809]]\n","\n"," [[0.95019373 0.96422227 0.9571566 ]\n","  [0.83326969 0.80874431 0.82082384]\n","  [0.90573671 0.82040347 0.86096083]]\n","\n"," [[0.94263725 0.95948164 0.95098486]\n","  [0.84179227 0.80949871 0.82532972]\n","  [0.89692922 0.83266641 0.86360398]]]\n","[[[0.92102706 0.94215552 0.93147149]\n","  [0.76701273 0.75982919 0.76340407]\n","  [0.89976114 0.72169478 0.80095044]]\n","\n"," [[0.94426542 0.96001749 0.9520763 ]\n","  [0.88811384 0.85019871 0.86874279]\n","  [0.89446372 0.85813998 0.87592544]]\n","\n"," [[0.96838825 0.9750883  0.97172672]\n","  [0.85860671 0.84941867 0.85398798]\n","  [0.94564281 0.8441281  0.89200653]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t-oUz3CNd30L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593190970375,"user_tz":-330,"elapsed":1321,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"outputId":"05d2381c-8b2d-4af3-d7ba-0b14cfb9948f"},"source":["print(pixEvaluationTrain.shape)\n","print(pixEvaluationTest.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3, 3, 3)\n","(3, 3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BWlJ0gSReCpZ","colab_type":"code","colab":{}},"source":["np.save(SAVE_PATH + \"Pixel-wise Metrics Train.npy\", pixEvaluationTrain)\n","np.save(SAVE_PATH + \"Pixel-wise Metrics Test.npy\", pixEvaluationTest)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-K-j8Hn0wu2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593187895753,"user_tz":-330,"elapsed":1109,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"outputId":"bf6ce8d6-64ee-45de-884d-885c679a48a9"},"source":["LOAD_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/Ki67/KFold LadderNet/\"\n","trainMetrics = np.load(LOAD_PATH + \"Pixel-wise Metrics Train.npy\")\n","testMetrics  = np.load(LOAD_PATH + \"Pixel-wise Metrics Test.npy\")\n","print(trainMetrics.shape)\n","print(testMetrics.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3, 3, 3)\n","(3, 3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6T6WjW7H1RMk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1591551064967,"user_tz":-330,"elapsed":1804,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"outputId":"ca44992e-abaa-4b24-8010-ffa793e7c65c"},"source":["\n","#For pixel-wise background is included and for object-wise background is not included\n","numClasses = 3\n","avgTrainMetrics  = np.zeros([numClasses, 3])\n","avgTestMetrics   = np.zeros([numClasses, 3])\n","\n","def calculateMetrics(AvgMetrics, ValidationMetrics):\n","  for patientNum in range(ValidationMetrics.shape[0]):\n","    for row in range(numClasses):\n","      for col in range(3):\n","        AvgMetrics[row][col] += ValidationMetrics[patientNum][row][col]\n","  AvgMetrics = np.divide(AvgMetrics,ValidationMetrics.shape[0] )\n","  return AvgMetrics\n","\n","\n","avgTrainMetrics = calculateMetrics(avgTrainMetrics, trainMetrics)\n","print('TRAIN :')\n","print(avgTrainMetrics)\n","\n","avgTestMetrics = calculateMetrics(avgTestMetrics, testMetrics)\n","print('TEST :')\n","print(avgTestMetrics)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN :\n","[[0.9558469  0.957932   0.95671614]\n"," [0.8550969  0.81991115 0.83443751]\n"," [0.86590669 0.89296803 0.87713484]]\n","TEST :\n","[[0.93093541 0.93941124 0.93411226]\n"," [0.79153604 0.66190771 0.68281195]\n"," [0.83019238 0.82337968 0.82415122]]\n"],"name":"stdout"}]}]}