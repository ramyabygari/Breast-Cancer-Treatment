{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KFold-LadderNet.ipynb","provenance":[{"file_id":"1dLxM_AMOSs32Mxu42FNwumVVm11sLpeG","timestamp":1589298710575},{"file_id":"17lvwlvqQV7B-wqN2ajx7Q2UwCZwCd-WD","timestamp":1586698406636},{"file_id":"1SAeOlks1aRTndKfvFcMtNB7V3Ik6nfN0","timestamp":1586361815646},{"file_id":"1puNfvA8GEtqbsfDMP30_RS6XRrNM8Ky8","timestamp":1586249758540},{"file_id":"1QPxGukBl9nFKfyxsNhM4lUw4rYauJaY1","timestamp":1586242198727},{"file_id":"1txy9g7gYnELmPTY6sT4JtfbhwQthIyoG","timestamp":1583812009231},{"file_id":"1a9BwVwMfQ4iFdte5xgs4kzj58JNqs4Vu","timestamp":1579539718864},{"file_id":"1KyLESiefS0uSAi_kTOAZ9NmNUSYTs9lL","timestamp":1578995412588},{"file_id":"1YDTADQrLw8-aYCSjOEYxDuIB1nuy3Xzm","timestamp":1577686452735},{"file_id":"1DqrMpMvIbzPtWFjsL_eNwrVM-xaFvx6c","timestamp":1571727299009}],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ixvBWa23MB7e","colab_type":"code","outputId":"0ca4effb-16c4-4bac-9a78-b9385b60de32","executionInfo":{"status":"ok","timestamp":1591550965170,"user_tz":-330,"elapsed":25985,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LzNbXYWE4I5E","colab_type":"code","outputId":"84a2461a-3882-4501-df96-9e086473385a","executionInfo":{"status":"ok","timestamp":1591551037486,"user_tz":-330,"elapsed":78043,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import os\n","import cv2\n","import numpy as np\n","!pip install -U keras\n","!pip install tensorflow-gpu==2.1.0rc0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.4)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Collecting tensorflow-gpu==2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/24/f94a1b8f779471f53b814a96c5109994ccf65b0103b771ff208c8a937d37/tensorflow_gpu-2.1.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (402.3MB)\n","\u001b[K     |████████████████████████████████| 402.3MB 37kB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (3.2.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.34.2)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.12.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.18.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.9.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.1.0)\n","Collecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 469kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (1.29.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.2.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (0.8.1)\n","Collecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 407kB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0rc0) (3.10.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0rc0) (2.10.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.7.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.2.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (47.1.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (0.2.8)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (4.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.1.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.6.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.0.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.1.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1.0rc0) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=7a7729d5c2725859049487a9dbd8ccd810062b1ea2533a94fc691e357be3e93f\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.1.0rc0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Mk6pnB6tFp0","colab_type":"code","outputId":"72e91830-5894-4bbd-b840-11efb609bbd5","executionInfo":{"status":"ok","timestamp":1591551051482,"user_tz":-330,"elapsed":89378,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import math\n","import random\n","import keras\n","from keras.layers import *\n","from keras.models import Sequential\n","from keras import Model\n","from keras import backend as K  \n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","\n","from sklearn.model_selection import LeaveOneOut\n","from sklearn import metrics"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U4SPHrcLZH4a","colab":{}},"source":["def get_conv_block(input_layer,nFilters,size):\n","    conv1 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(input_layer)\n","    bn1 = BatchNormalization()(conv1)\n","    conv2 = Conv2D(nFilters, size, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(bn1)\n","    bn2 = BatchNormalization()(conv2)\n","    return bn2\n","    \n","def get_UNET(input_layer,nFilters,flag): \n","\n","    block1 = get_conv_block(input_layer[0],nFilters,3)\n","    mp1 = MaxPooling2D(pool_size=(2, 2))(block1)\n","    dr1 = Dropout(0.1)(mp1)\n","   \n","    if(flag==1):\n","      dr1 = concatenate([dr1,input_layer[1]])\n","\n","    block2 = get_conv_block(dr1,nFilters*2,3)\n","    mp2 = MaxPooling2D(pool_size=(2, 2))(block2)\n","    dr2 = Dropout(0.1)(mp2)\n","\n","    if(flag==1):\n","      dr2 = concatenate([dr2,input_layer[2]])\n","   \n","    block3 = get_conv_block(dr2,nFilters*4,3)\n","    mp3 = MaxPooling2D(pool_size=(2, 2))(block3)\n","    dr3 = Dropout(0.1)(mp3)\n","\n","    if(flag==1):\n","      dr3 = concatenate([dr3,input_layer[3]])\n","       \n","    block4 = get_conv_block(dr3,nFilters*8,3)\n","    mp4 = MaxPooling2D(pool_size=(2, 2))(block4)\n","    dr4 = Dropout(0.1)(mp4)\n","\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(dr4)\n","    conv5 = Conv2D(nFilters*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(conv5)\n","\n","    up1 = Conv2DTranspose(nFilters*8,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(conv5)\n","    cat1 = concatenate([block4, up1, mp3])\n","    dr1 = Dropout(0.1)(cat1)\n","    block5 = get_conv_block(dr1,nFilters*8,3)\n","\n","    up2 = Conv2DTranspose(nFilters*4,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block5)\n","    b4_upsample = Conv2DTranspose(nFilters*4,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block4)\n","    cat2 = concatenate([block3, up2, b4_upsample, mp2])\n","    dr2 = Dropout(0.1)(cat2)\n","    block6 = get_conv_block(dr2,nFilters*4,3)\n","    \n","    up3 = Conv2DTranspose(nFilters*2,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block6)\n","    b3_upsample = Conv2DTranspose(nFilters*2,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block3)\n","    cat3 = concatenate([block2, up3, mp1, b3_upsample])\n","    dr3 = Dropout(0.1)(cat3)\n","    block7 = get_conv_block(dr3,nFilters*2,3)\n","    \n","    up4 = Conv2DTranspose(nFilters,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block7)\n","    b2_upsample = Conv2DTranspose(nFilters,(3,3),strides =(2,2),activation='relu',padding='same',kernel_initializer = 'he_normal')(block2)\n","    cat4 = concatenate([block1, up4, b2_upsample])\n","    dr4 = Dropout(0.1)(cat4)\n","    block8 = get_conv_block(dr4,nFilters,3)\n","\n","    conv10 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=l2(1e-4))(block8)\n","    conv11 = Conv2D(3,(1,1), activation='softmax', padding = 'same',kernel_regularizer=l2(1e-4))(conv10)\n","\n","    return (conv11, block7, block6, block5)\n","\n","def get_model(input_shape,nFilters1,nFilters2):\n","\n","    input_layer = Input(shape=input_shape)\n","    out1,out2,out3,out4 = get_UNET([input_layer],nFilters1,0)\n","\n","    out1,out2,out3,out4 = get_UNET([out1,out2,out3,out4],nFilters2,1)\n","\n","    model = Model(input_layer,out1)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAdwXbmXEJL5","colab_type":"code","outputId":"38717c8a-1e3c-4867-f3ab-e8ae13c48c49","executionInfo":{"status":"ok","timestamp":1591535355880,"user_tz":-330,"elapsed":40072,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = get_model((240,240,3),16,4)\n","model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 240, 240, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 240, 240, 16) 448         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 240, 240, 16) 64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 240, 240, 16) 2320        batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 240, 240, 16) 64          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 120, 120, 16) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 120, 120, 16) 0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 120, 120, 32) 4640        dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 120, 120, 32) 128         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 120, 120, 32) 9248        batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 120, 120, 32) 128         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 60, 60, 32)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 60, 60, 32)   0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 60, 60, 64)   18496       dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 60, 60, 64)   256         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 60, 60, 64)   36928       batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 60, 60, 64)   256         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 30, 30, 64)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 30, 30, 64)   0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 30, 30, 128)  73856       dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 30, 30, 128)  512         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 30, 30, 128)  147584      batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 30, 30, 128)  512         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 128)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 15, 15, 128)  0           max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 15, 15, 256)  295168      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 15, 15, 256)  590080      conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 30, 30, 128)  295040      conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 30, 30, 320)  0           batch_normalization_8[0][0]      \n","                                                                 conv2d_transpose_1[0][0]         \n","                                                                 max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 30, 30, 320)  0           concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 30, 30, 128)  368768      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 30, 30, 128)  512         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 30, 30, 128)  147584      batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 30, 30, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 60, 60, 64)   73792       batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 60, 60, 64)   73792       batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 60, 60, 224)  0           batch_normalization_6[0][0]      \n","                                                                 conv2d_transpose_2[0][0]         \n","                                                                 conv2d_transpose_3[0][0]         \n","                                                                 max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 60, 60, 224)  0           concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 60, 60, 64)   129088      dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 60, 60, 64)   256         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 60, 60, 64)   36928       batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 60, 60, 64)   256         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_4 (Conv2DTrans (None, 120, 120, 32) 18464       batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_5 (Conv2DTrans (None, 120, 120, 32) 18464       batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 120, 120, 112 0           batch_normalization_4[0][0]      \n","                                                                 conv2d_transpose_4[0][0]         \n","                                                                 max_pooling2d_1[0][0]            \n","                                                                 conv2d_transpose_5[0][0]         \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 120, 120, 112 0           concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 120, 120, 32) 32288       dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 120, 120, 32) 128         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 120, 120, 32) 9248        batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 120, 120, 32) 128         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_6 (Conv2DTrans (None, 240, 240, 16) 4624        batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_7 (Conv2DTrans (None, 240, 240, 16) 4624        batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 240, 240, 48) 0           batch_normalization_2[0][0]      \n","                                                                 conv2d_transpose_6[0][0]         \n","                                                                 conv2d_transpose_7[0][0]         \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 240, 240, 48) 0           concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 240, 240, 16) 6928        dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 240, 240, 16) 64          conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 240, 240, 16) 2320        batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 240, 240, 16) 64          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 240, 240, 2)  290         batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 240, 240, 3)  9           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 240, 240, 4)  112         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 240, 240, 4)  16          conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 240, 240, 4)  148         batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 240, 240, 4)  16          conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 120, 120, 4)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 120, 120, 4)  0           max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 120, 120, 36) 0           dropout_9[0][0]                  \n","                                                                 batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 120, 120, 8)  2600        concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 120, 120, 8)  32          conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 120, 120, 8)  584         batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 120, 120, 8)  32          conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 60, 60, 8)    0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 60, 60, 8)    0           max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 60, 60, 72)   0           dropout_10[0][0]                 \n","                                                                 batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 60, 60, 16)   10384       concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 60, 60, 16)   64          conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 60, 60, 16)   2320        batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 60, 60, 16)   64          conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 30, 30, 16)   0           max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 30, 30, 144)  0           dropout_11[0][0]                 \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 30, 30, 32)   41504       concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 30, 30, 32)   128         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 30, 30, 32)   9248        batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 30, 30, 32)   128         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 15, 15, 32)   0           max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 15, 15, 64)   18496       dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 15, 15, 64)   36928       conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_8 (Conv2DTrans (None, 30, 30, 32)   18464       conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 30, 30, 80)   0           batch_normalization_24[0][0]     \n","                                                                 conv2d_transpose_8[0][0]         \n","                                                                 max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 30, 30, 80)   0           concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 30, 30, 32)   23072       dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 30, 30, 32)   128         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 30, 30, 32)   9248        batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 30, 30, 32)   128         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_9 (Conv2DTrans (None, 60, 60, 16)   4624        batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_10 (Conv2DTran (None, 60, 60, 16)   4624        batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 60, 60, 56)   0           batch_normalization_22[0][0]     \n","                                                                 conv2d_transpose_9[0][0]         \n","                                                                 conv2d_transpose_10[0][0]        \n","                                                                 max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 60, 60, 56)   0           concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 60, 60, 16)   8080        dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 60, 60, 16)   64          conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 60, 60, 16)   2320        batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 60, 60, 16)   64          conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_11 (Conv2DTran (None, 120, 120, 8)  1160        batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_12 (Conv2DTran (None, 120, 120, 8)  1160        batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 120, 120, 28) 0           batch_normalization_20[0][0]     \n","                                                                 conv2d_transpose_11[0][0]        \n","                                                                 max_pooling2d_5[0][0]            \n","                                                                 conv2d_transpose_12[0][0]        \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 120, 120, 28) 0           concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 120, 120, 8)  2024        dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 120, 120, 8)  32          conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 120, 120, 8)  584         batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 120, 120, 8)  32          conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_13 (Conv2DTran (None, 240, 240, 4)  292         batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_14 (Conv2DTran (None, 240, 240, 4)  292         batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 240, 240, 12) 0           batch_normalization_18[0][0]     \n","                                                                 conv2d_transpose_13[0][0]        \n","                                                                 conv2d_transpose_14[0][0]        \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 240, 240, 12) 0           concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 240, 240, 4)  436         dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 240, 240, 4)  16          conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 240, 240, 4)  148         batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 240, 240, 4)  16          conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 240, 240, 2)  74          batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 240, 240, 3)  9           conv2d_39[0][0]                  \n","==================================================================================================\n","Total params: 2,604,754\n","Trainable params: 2,602,354\n","Non-trainable params: 2,400\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xiXrY-SjvEMW","colab_type":"code","colab":{}},"source":["PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Ki67\"\n","\n","\n","X1  = np.load(PATH + '/Ki67 IHC 230 Images.npy')\n","Y1  = np.load(PATH + '/Ki67 IHC 230 Masks.npy')\n","\n","X2  = np.load(PATH + '/Ki67 IHC 242 Images.npy')\n","Y2  = np.load(PATH + '/Ki67 IHC 242 Masks.npy')\n","\n","X3  = np.load(PATH + '/Ki67 IHC 263 Images.npy')\n","Y3  = np.load(PATH + '/Ki67 IHC 263 Masks.npy')\n","\n","X4  = np.load(PATH + '/Ki67 IHC 232 Images.npy')\n","Y4  = np.load(PATH + '/Ki67 IHC 232 Masks.npy')\n","\n","X5 = np.load(PATH + '/Ki67 IHC 221 Images.npy')\n","Y5 = np.load(PATH + '/Ki67 IHC 221 Masks.npy')\n","\n","X6 = np.load(PATH + '/Ki67 IHC 229 Images.npy')\n","Y6 = np.load(PATH + '/Ki67 IHC 229 Masks.npy')\n","\n","X7 = np.load(PATH + '/Ki67 IHC 246 Images.npy')\n","Y7 = np.load(PATH + '/Ki67 IHC 246 Masks.npy')\n","\n","X8 = np.load(PATH + '/Ki67 IHC 252 Images.npy')\n","Y8 = np.load(PATH + '/Ki67 IHC 252 Masks.npy')\n","\n","X9 = np.load(PATH + '/Ki67 IHC 239 Images.npy')\n","Y9 = np.load(PATH + '/Ki67 IHC 239 Masks.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8B4TY8y22Zgp","colab_type":"code","outputId":"15935971-a0eb-46d3-f1b7-29eb637e8b7a","executionInfo":{"status":"ok","timestamp":1591535416778,"user_tz":-330,"elapsed":1632,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["print(X1.shape[0]/48)\n","print(X2.shape[0]/48)\n","print(X3.shape[0]/48)\n","print(X4.shape[0]/48)\n","print(X5.shape[0]/48)\n","print(X6.shape[0]/48)\n","print(X7.shape[0]/48)\n","print(X8.shape[0]/48)\n","print(X9.shape[0]/48)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["10.0\n","11.0\n","11.0\n","10.0\n","10.0\n","10.0\n","10.0\n","10.0\n","10.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"URoo6JnVKIk8","colab_type":"code","colab":{}},"source":["X = [X1, X2, X3, X4, X5, X6, X7, X8, X9]\n","Y = [Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y9]\n","patient_no = ['230','242','263','232','221','229','246','252','239']\n","size = [10,11,11,10,10,10,10,10,10]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MujkbhpsnE9","colab_type":"code","colab":{}},"source":["def convertToLabels(data):\n","  data[data==128]=1\n","  data[data==255]=2\n","\n","def convertFromLabels(data):\n","  data[data==1]=128\n","  data[data==2]=255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDodKs-AMB81","colab_type":"code","colab":{}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TH9yDcoO6Kyg","colab_type":"code","colab":{}},"source":["def tversky_loss(y_true, y_pred):\n","    alpha = 0.45\n","    beta  = 0.55\n","    \n","    ones = K.ones(K.shape(y_true))\n","    p0 = y_pred      # proba that voxels are class i\n","    p1 = ones-y_pred # proba that voxels are not class i\n","    g0 = y_true\n","    g1 = ones-y_true\n","    \n","    num = K.sum(p0*g0, (0,1,2))\n","    den = num + alpha*K.sum(p0*g1,(0,1,2)) + beta*K.sum(p1*g0,(0,1,2))\n","    \n","    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n","    \n","    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n","    return Ncl-T\n","\n","def combined_loss(y_true, y_pred):\n","  return (0.5*K.categorical_crossentropy(y_true, y_pred))+(1*tversky_loss(y_true, y_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMnXb4wMMB88","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping,ModelCheckpoint\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","mc = ModelCheckpoint('Checkpoint.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyEYstIcMB9B","colab_type":"code","colab":{}},"source":["optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaGvHbqtarli","colab_type":"code","colab":{}},"source":["batch_size = 16\n","def get_batch(batch_size, X_train, Y_train): \n","    size_batch = batch_size\n","    last_index = len(X_train) - 1\n","    x_train = X_train\n","    y_train = Y_train \n","    while True:\n","        batch_data = [[],[]]\n","        for i in range(0, size_batch):\n","            random_index = random.randint(0, last_index)\n","            batch_data[0].append(x_train[random_index])\n","            batch_data[1].append(y_train[random_index])\n","\n","        yield (np.array(batch_data[0]), np.array(batch_data[1]))     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C--tafyWkzgL","colab_type":"code","outputId":"ccb3f4d4-a634-47ea-d059-af85cc82dcca","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/4 Class/Ki67/KFold\"\n","\n","# oneOut = LeaveOneOut()\n","#num_epoch = 100\n","# fold=0\n","\n","# for train_index, test_index in oneOut.split(X):\n","#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","#   if(te)\n","#   TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","#   TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","#   TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","#   TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","#   TrainX = TrainX.astype('float32')/255\n","#   TestX = TestX.astype('float32')/255\n","#   convertToLabels(TrainY)\n","#   TrainY = keras.utils.to_categorical(TrainY,num_classes=3,dtype='int16')\n","#   convertToLabels(TestY)\n","#   TestY = keras.utils.to_categorical(TestY, num_classes=3,dtype='int16')\n","#   ValX = TrainX[(int)(0.8*TrainX.shape[0]):]\n","#   ValY = TrainY[(int)(0.8*TrainY.shape[0]):]\n","#   model = get_model((240,240,3),16,4)\n","\n","#   es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","#   mc = ModelCheckpoint('Checkpoint.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n","\n","#   optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.001, decay=0.0, amsgrad=True)\n","\n","#   model.compile(loss=combined_loss, optimizer= optimizer , metrics=[dice_coef,'accuracy']) \n","#   num_epoch = 100\n","#   datagen = get_batch(batch_size, TrainX, TrainY)\n","#   n_points = len(TrainX)\n","#   print('-----------fold {}--------------'.format(fold))\n","#   model.fit(datagen, validation_data = [ValX, ValY],\n","#                   epochs=num_epoch,steps_per_epoch = math.ceil(n_points / batch_size), callbacks =[es,mc],  shuffle =True)\n","#   model.save(MODELS_PATH + '/LadderNet_Ki67_'+ str(fold) +'.h5')\n","#   fold = fold + 1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAIN: [1 2 3 4 5 6 7 8] TEST: [0]\n","-----------fold 0--------------\n","Epoch 1/100\n","246/246 [==============================] - 101s 411ms/step - loss: 2.2187 - dice_coef: 0.7052 - accuracy: 0.7866 - val_loss: 2.2779 - val_dice_coef: 0.7746 - val_accuracy: 0.8134\n","\n","Epoch 00001: val_loss improved from inf to 2.27789, saving model to Checkpoint.h5\n","Epoch 2/100\n","246/246 [==============================] - 80s 327ms/step - loss: 1.9822 - dice_coef: 0.7826 - accuracy: 0.8186 - val_loss: 1.9938 - val_dice_coef: 0.7581 - val_accuracy: 0.8389\n","\n","Epoch 00002: val_loss improved from 2.27789 to 1.99381, saving model to Checkpoint.h5\n","Epoch 3/100\n","246/246 [==============================] - 80s 327ms/step - loss: 1.8767 - dice_coef: 0.7959 - accuracy: 0.8207 - val_loss: 1.8292 - val_dice_coef: 0.7932 - val_accuracy: 0.7442\n","\n","Epoch 00003: val_loss improved from 1.99381 to 1.82919, saving model to Checkpoint.h5\n","Epoch 4/100\n","246/246 [==============================] - 80s 327ms/step - loss: 1.6623 - dice_coef: 0.8099 - accuracy: 0.8865 - val_loss: 1.5858 - val_dice_coef: 0.8226 - val_accuracy: 0.9016\n","\n","Epoch 00004: val_loss improved from 1.82919 to 1.58576, saving model to Checkpoint.h5\n","Epoch 5/100\n","246/246 [==============================] - 80s 327ms/step - loss: 1.4185 - dice_coef: 0.8329 - accuracy: 0.9084 - val_loss: 1.3589 - val_dice_coef: 0.8377 - val_accuracy: 0.9109\n","\n","Epoch 00005: val_loss improved from 1.58576 to 1.35892, saving model to Checkpoint.h5\n","Epoch 6/100\n","246/246 [==============================] - 80s 327ms/step - loss: 1.2497 - dice_coef: 0.8540 - accuracy: 0.9102 - val_loss: 1.1885 - val_dice_coef: 0.8613 - val_accuracy: 0.9081\n","\n","Epoch 00006: val_loss improved from 1.35892 to 1.18851, saving model to Checkpoint.h5\n","Epoch 7/100\n","246/246 [==============================] - 80s 327ms/step - loss: 1.0561 - dice_coef: 0.8832 - accuracy: 0.9130 - val_loss: 1.0808 - val_dice_coef: 0.8860 - val_accuracy: 0.9020\n","\n","Epoch 00007: val_loss improved from 1.18851 to 1.08082, saving model to Checkpoint.h5\n","Epoch 8/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.9250 - dice_coef: 0.8999 - accuracy: 0.9183 - val_loss: 1.0538 - val_dice_coef: 0.8851 - val_accuracy: 0.9039\n","\n","Epoch 00008: val_loss improved from 1.08082 to 1.05382, saving model to Checkpoint.h5\n","Epoch 9/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.8714 - dice_coef: 0.9036 - accuracy: 0.9192 - val_loss: 0.9521 - val_dice_coef: 0.8953 - val_accuracy: 0.9088\n","\n","Epoch 00009: val_loss improved from 1.05382 to 0.95210, saving model to Checkpoint.h5\n","Epoch 10/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.8345 - dice_coef: 0.9080 - accuracy: 0.9214 - val_loss: 0.7940 - val_dice_coef: 0.9065 - val_accuracy: 0.9180\n","\n","Epoch 00010: val_loss improved from 0.95210 to 0.79398, saving model to Checkpoint.h5\n","Epoch 11/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.8080 - dice_coef: 0.9087 - accuracy: 0.9212 - val_loss: 0.7736 - val_dice_coef: 0.9056 - val_accuracy: 0.9163\n","\n","Epoch 00011: val_loss improved from 0.79398 to 0.77357, saving model to Checkpoint.h5\n","Epoch 12/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.7712 - dice_coef: 0.9123 - accuracy: 0.9239 - val_loss: 0.7328 - val_dice_coef: 0.9153 - val_accuracy: 0.9257\n","\n","Epoch 00012: val_loss improved from 0.77357 to 0.73281, saving model to Checkpoint.h5\n","Epoch 13/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.7528 - dice_coef: 0.9137 - accuracy: 0.9242 - val_loss: 0.7052 - val_dice_coef: 0.9119 - val_accuracy: 0.9199\n","\n","Epoch 00013: val_loss improved from 0.73281 to 0.70521, saving model to Checkpoint.h5\n","Epoch 14/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.7324 - dice_coef: 0.9140 - accuracy: 0.9245 - val_loss: 0.7048 - val_dice_coef: 0.9091 - val_accuracy: 0.9188\n","\n","Epoch 00014: val_loss improved from 0.70521 to 0.70479, saving model to Checkpoint.h5\n","Epoch 15/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.7062 - dice_coef: 0.9178 - accuracy: 0.9275 - val_loss: 0.6587 - val_dice_coef: 0.9218 - val_accuracy: 0.9304\n","\n","Epoch 00015: val_loss improved from 0.70479 to 0.65868, saving model to Checkpoint.h5\n","Epoch 16/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6840 - dice_coef: 0.9184 - accuracy: 0.9278 - val_loss: 1.1056 - val_dice_coef: 0.8746 - val_accuracy: 0.8793\n","\n","Epoch 00016: val_loss did not improve from 0.65868\n","Epoch 17/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6797 - dice_coef: 0.9185 - accuracy: 0.9276 - val_loss: 0.6936 - val_dice_coef: 0.9191 - val_accuracy: 0.9251\n","\n","Epoch 00017: val_loss did not improve from 0.65868\n","Epoch 18/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6717 - dice_coef: 0.9194 - accuracy: 0.9282 - val_loss: 0.7267 - val_dice_coef: 0.9132 - val_accuracy: 0.9211\n","\n","Epoch 00018: val_loss did not improve from 0.65868\n","Epoch 19/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6532 - dice_coef: 0.9215 - accuracy: 0.9300 - val_loss: 0.6410 - val_dice_coef: 0.9171 - val_accuracy: 0.9274\n","\n","Epoch 00019: val_loss improved from 0.65868 to 0.64104, saving model to Checkpoint.h5\n","Epoch 20/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6409 - dice_coef: 0.9214 - accuracy: 0.9296 - val_loss: 0.6108 - val_dice_coef: 0.9180 - val_accuracy: 0.9276\n","\n","Epoch 00020: val_loss improved from 0.64104 to 0.61075, saving model to Checkpoint.h5\n","Epoch 21/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6358 - dice_coef: 0.9224 - accuracy: 0.9304 - val_loss: 0.7017 - val_dice_coef: 0.9112 - val_accuracy: 0.9199\n","\n","Epoch 00021: val_loss did not improve from 0.61075\n","Epoch 22/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.6250 - dice_coef: 0.9230 - accuracy: 0.9308 - val_loss: 0.5880 - val_dice_coef: 0.9213 - val_accuracy: 0.9290\n","\n","Epoch 00022: val_loss improved from 0.61075 to 0.58805, saving model to Checkpoint.h5\n","Epoch 23/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6144 - dice_coef: 0.9245 - accuracy: 0.9322 - val_loss: 0.6278 - val_dice_coef: 0.9189 - val_accuracy: 0.9268\n","\n","Epoch 00023: val_loss did not improve from 0.58805\n","Epoch 24/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6065 - dice_coef: 0.9242 - accuracy: 0.9318 - val_loss: 0.6435 - val_dice_coef: 0.9210 - val_accuracy: 0.9293\n","\n","Epoch 00024: val_loss did not improve from 0.58805\n","Epoch 25/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.6024 - dice_coef: 0.9250 - accuracy: 0.9324 - val_loss: 0.5453 - val_dice_coef: 0.9303 - val_accuracy: 0.9366\n","\n","Epoch 00025: val_loss improved from 0.58805 to 0.54529, saving model to Checkpoint.h5\n","Epoch 26/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5838 - dice_coef: 0.9276 - accuracy: 0.9349 - val_loss: 0.5905 - val_dice_coef: 0.9208 - val_accuracy: 0.9302\n","\n","Epoch 00026: val_loss did not improve from 0.54529\n","Epoch 27/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5902 - dice_coef: 0.9265 - accuracy: 0.9337 - val_loss: 0.5262 - val_dice_coef: 0.9292 - val_accuracy: 0.9368\n","\n","Epoch 00027: val_loss improved from 0.54529 to 0.52619, saving model to Checkpoint.h5\n","Epoch 28/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5660 - dice_coef: 0.9307 - accuracy: 0.9375 - val_loss: 0.6282 - val_dice_coef: 0.9113 - val_accuracy: 0.9177\n","\n","Epoch 00028: val_loss did not improve from 0.52619\n","Epoch 29/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5797 - dice_coef: 0.9285 - accuracy: 0.9352 - val_loss: 0.5636 - val_dice_coef: 0.9261 - val_accuracy: 0.9330\n","\n","Epoch 00029: val_loss did not improve from 0.52619\n","Epoch 30/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5715 - dice_coef: 0.9283 - accuracy: 0.9352 - val_loss: 0.5643 - val_dice_coef: 0.9221 - val_accuracy: 0.9282\n","\n","Epoch 00030: val_loss did not improve from 0.52619\n","Epoch 31/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.5615 - dice_coef: 0.9302 - accuracy: 0.9368 - val_loss: 0.4985 - val_dice_coef: 0.9354 - val_accuracy: 0.9429\n","\n","Epoch 00031: val_loss improved from 0.52619 to 0.49853, saving model to Checkpoint.h5\n","Epoch 32/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5460 - dice_coef: 0.9328 - accuracy: 0.9392 - val_loss: 0.5748 - val_dice_coef: 0.9211 - val_accuracy: 0.9276\n","\n","Epoch 00032: val_loss did not improve from 0.49853\n","Epoch 33/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.5496 - dice_coef: 0.9323 - accuracy: 0.9387 - val_loss: 0.8194 - val_dice_coef: 0.9025 - val_accuracy: 0.9068\n","\n","Epoch 00033: val_loss did not improve from 0.49853\n","Epoch 34/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5620 - dice_coef: 0.9306 - accuracy: 0.9371 - val_loss: 0.5870 - val_dice_coef: 0.9283 - val_accuracy: 0.9354\n","\n","Epoch 00034: val_loss did not improve from 0.49853\n","Epoch 35/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5459 - dice_coef: 0.9331 - accuracy: 0.9394 - val_loss: 0.5475 - val_dice_coef: 0.9281 - val_accuracy: 0.9362\n","\n","Epoch 00035: val_loss did not improve from 0.49853\n","Epoch 36/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5309 - dice_coef: 0.9349 - accuracy: 0.9410 - val_loss: 0.4938 - val_dice_coef: 0.9342 - val_accuracy: 0.9411\n","\n","Epoch 00036: val_loss improved from 0.49853 to 0.49378, saving model to Checkpoint.h5\n","Epoch 37/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5291 - dice_coef: 0.9354 - accuracy: 0.9414 - val_loss: 0.4977 - val_dice_coef: 0.9351 - val_accuracy: 0.9435\n","\n","Epoch 00037: val_loss did not improve from 0.49378\n","Epoch 38/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5299 - dice_coef: 0.9341 - accuracy: 0.9402 - val_loss: 0.5350 - val_dice_coef: 0.9284 - val_accuracy: 0.9376\n","\n","Epoch 00038: val_loss did not improve from 0.49378\n","Epoch 39/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.5389 - dice_coef: 0.9325 - accuracy: 0.9387 - val_loss: 0.5035 - val_dice_coef: 0.9338 - val_accuracy: 0.9400\n","\n","Epoch 00039: val_loss did not improve from 0.49378\n","Epoch 40/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5176 - dice_coef: 0.9362 - accuracy: 0.9422 - val_loss: 0.5268 - val_dice_coef: 0.9254 - val_accuracy: 0.9327\n","\n","Epoch 00040: val_loss did not improve from 0.49378\n","Epoch 41/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.5233 - dice_coef: 0.9360 - accuracy: 0.9419 - val_loss: 0.4805 - val_dice_coef: 0.9346 - val_accuracy: 0.9422\n","\n","Epoch 00041: val_loss improved from 0.49378 to 0.48051, saving model to Checkpoint.h5\n","Epoch 42/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5277 - dice_coef: 0.9351 - accuracy: 0.9409 - val_loss: 0.5352 - val_dice_coef: 0.9293 - val_accuracy: 0.9376\n","\n","Epoch 00042: val_loss did not improve from 0.48051\n","Epoch 43/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5167 - dice_coef: 0.9369 - accuracy: 0.9427 - val_loss: 0.5023 - val_dice_coef: 0.9354 - val_accuracy: 0.9421\n","\n","Epoch 00043: val_loss did not improve from 0.48051\n","Epoch 44/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5202 - dice_coef: 0.9365 - accuracy: 0.9421 - val_loss: 0.5777 - val_dice_coef: 0.9277 - val_accuracy: 0.9339\n","\n","Epoch 00044: val_loss did not improve from 0.48051\n","Epoch 45/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5082 - dice_coef: 0.9384 - accuracy: 0.9440 - val_loss: 0.5706 - val_dice_coef: 0.9194 - val_accuracy: 0.9263\n","\n","Epoch 00045: val_loss did not improve from 0.48051\n","Epoch 46/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5072 - dice_coef: 0.9388 - accuracy: 0.9444 - val_loss: 0.4946 - val_dice_coef: 0.9357 - val_accuracy: 0.9414\n","\n","Epoch 00046: val_loss did not improve from 0.48051\n","Epoch 47/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5153 - dice_coef: 0.9378 - accuracy: 0.9434 - val_loss: 0.5255 - val_dice_coef: 0.9323 - val_accuracy: 0.9386\n","\n","Epoch 00047: val_loss did not improve from 0.48051\n","Epoch 48/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5007 - dice_coef: 0.9392 - accuracy: 0.9448 - val_loss: 0.4453 - val_dice_coef: 0.9421 - val_accuracy: 0.9490\n","\n","Epoch 00048: val_loss improved from 0.48051 to 0.44530, saving model to Checkpoint.h5\n","Epoch 49/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5113 - dice_coef: 0.9385 - accuracy: 0.9440 - val_loss: 0.4776 - val_dice_coef: 0.9387 - val_accuracy: 0.9447\n","\n","Epoch 00049: val_loss did not improve from 0.44530\n","Epoch 50/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5175 - dice_coef: 0.9379 - accuracy: 0.9434 - val_loss: 0.5864 - val_dice_coef: 0.9297 - val_accuracy: 0.9335\n","\n","Epoch 00050: val_loss did not improve from 0.44530\n","Epoch 51/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5102 - dice_coef: 0.9397 - accuracy: 0.9450 - val_loss: 0.4949 - val_dice_coef: 0.9361 - val_accuracy: 0.9423\n","\n","Epoch 00051: val_loss did not improve from 0.44530\n","Epoch 52/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4982 - dice_coef: 0.9408 - accuracy: 0.9461 - val_loss: 0.5774 - val_dice_coef: 0.9319 - val_accuracy: 0.9360\n","\n","Epoch 00052: val_loss did not improve from 0.44530\n","Epoch 53/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4969 - dice_coef: 0.9406 - accuracy: 0.9459 - val_loss: 0.5268 - val_dice_coef: 0.9306 - val_accuracy: 0.9380\n","\n","Epoch 00053: val_loss did not improve from 0.44530\n","Epoch 54/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4955 - dice_coef: 0.9412 - accuracy: 0.9465 - val_loss: 0.4933 - val_dice_coef: 0.9386 - val_accuracy: 0.9443\n","\n","Epoch 00054: val_loss did not improve from 0.44530\n","Epoch 55/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4757 - dice_coef: 0.9440 - accuracy: 0.9490 - val_loss: 0.4601 - val_dice_coef: 0.9431 - val_accuracy: 0.9485\n","\n","Epoch 00055: val_loss did not improve from 0.44530\n","Epoch 56/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4723 - dice_coef: 0.9447 - accuracy: 0.9496 - val_loss: 0.4832 - val_dice_coef: 0.9376 - val_accuracy: 0.9453\n","\n","Epoch 00056: val_loss did not improve from 0.44530\n","Epoch 57/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4745 - dice_coef: 0.9442 - accuracy: 0.9492 - val_loss: 0.6142 - val_dice_coef: 0.9245 - val_accuracy: 0.9293\n","\n","Epoch 00057: val_loss did not improve from 0.44530\n","Epoch 58/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4808 - dice_coef: 0.9428 - accuracy: 0.9479 - val_loss: 0.4407 - val_dice_coef: 0.9451 - val_accuracy: 0.9503\n","\n","Epoch 00058: val_loss improved from 0.44530 to 0.44069, saving model to Checkpoint.h5\n","Epoch 59/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4899 - dice_coef: 0.9424 - accuracy: 0.9474 - val_loss: 0.4856 - val_dice_coef: 0.9398 - val_accuracy: 0.9461\n","\n","Epoch 00059: val_loss did not improve from 0.44069\n","Epoch 60/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4865 - dice_coef: 0.9435 - accuracy: 0.9484 - val_loss: 0.7293 - val_dice_coef: 0.9145 - val_accuracy: 0.9211\n","\n","Epoch 00060: val_loss did not improve from 0.44069\n","Epoch 61/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.5109 - dice_coef: 0.9406 - accuracy: 0.9457 - val_loss: 0.4491 - val_dice_coef: 0.9454 - val_accuracy: 0.9504\n","\n","Epoch 00061: val_loss did not improve from 0.44069\n","Epoch 62/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4945 - dice_coef: 0.9431 - accuracy: 0.9481 - val_loss: 0.4723 - val_dice_coef: 0.9397 - val_accuracy: 0.9459\n","\n","Epoch 00062: val_loss did not improve from 0.44069\n","Epoch 63/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4961 - dice_coef: 0.9422 - accuracy: 0.9473 - val_loss: 0.4389 - val_dice_coef: 0.9469 - val_accuracy: 0.9525\n","\n","Epoch 00063: val_loss improved from 0.44069 to 0.43894, saving model to Checkpoint.h5\n","Epoch 64/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4806 - dice_coef: 0.9449 - accuracy: 0.9498 - val_loss: 0.5368 - val_dice_coef: 0.9354 - val_accuracy: 0.9409\n","\n","Epoch 00064: val_loss did not improve from 0.43894\n","Epoch 65/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4894 - dice_coef: 0.9436 - accuracy: 0.9486 - val_loss: 0.5069 - val_dice_coef: 0.9365 - val_accuracy: 0.9414\n","\n","Epoch 00065: val_loss did not improve from 0.43894\n","Epoch 66/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4766 - dice_coef: 0.9452 - accuracy: 0.9500 - val_loss: 0.4752 - val_dice_coef: 0.9444 - val_accuracy: 0.9491\n","\n","Epoch 00066: val_loss did not improve from 0.43894\n","Epoch 67/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4727 - dice_coef: 0.9460 - accuracy: 0.9507 - val_loss: 0.4806 - val_dice_coef: 0.9375 - val_accuracy: 0.9418\n","\n","Epoch 00067: val_loss did not improve from 0.43894\n","Epoch 68/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4708 - dice_coef: 0.9454 - accuracy: 0.9502 - val_loss: 0.4385 - val_dice_coef: 0.9455 - val_accuracy: 0.9516\n","\n","Epoch 00068: val_loss improved from 0.43894 to 0.43852, saving model to Checkpoint.h5\n","Epoch 69/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4663 - dice_coef: 0.9473 - accuracy: 0.9519 - val_loss: 0.4759 - val_dice_coef: 0.9444 - val_accuracy: 0.9488\n","\n","Epoch 00069: val_loss did not improve from 0.43852\n","Epoch 70/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4624 - dice_coef: 0.9475 - accuracy: 0.9521 - val_loss: 0.6970 - val_dice_coef: 0.9015 - val_accuracy: 0.9072\n","\n","Epoch 00070: val_loss did not improve from 0.43852\n","Epoch 71/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4852 - dice_coef: 0.9450 - accuracy: 0.9497 - val_loss: 0.5112 - val_dice_coef: 0.9370 - val_accuracy: 0.9447\n","\n","Epoch 00071: val_loss did not improve from 0.43852\n","Epoch 72/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4822 - dice_coef: 0.9453 - accuracy: 0.9500 - val_loss: 0.4504 - val_dice_coef: 0.9469 - val_accuracy: 0.9514\n","\n","Epoch 00072: val_loss did not improve from 0.43852\n","Epoch 73/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4778 - dice_coef: 0.9462 - accuracy: 0.9508 - val_loss: 0.6331 - val_dice_coef: 0.9209 - val_accuracy: 0.9267\n","\n","Epoch 00073: val_loss did not improve from 0.43852\n","Epoch 74/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4666 - dice_coef: 0.9475 - accuracy: 0.9520 - val_loss: 0.4103 - val_dice_coef: 0.9519 - val_accuracy: 0.9566\n","\n","Epoch 00074: val_loss improved from 0.43852 to 0.41030, saving model to Checkpoint.h5\n","Epoch 75/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4684 - dice_coef: 0.9473 - accuracy: 0.9518 - val_loss: 0.5315 - val_dice_coef: 0.9317 - val_accuracy: 0.9397\n","\n","Epoch 00075: val_loss did not improve from 0.41030\n","Epoch 76/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4798 - dice_coef: 0.9455 - accuracy: 0.9502 - val_loss: 0.5793 - val_dice_coef: 0.9258 - val_accuracy: 0.9326\n","\n","Epoch 00076: val_loss did not improve from 0.41030\n","Epoch 77/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4804 - dice_coef: 0.9460 - accuracy: 0.9505 - val_loss: 0.4312 - val_dice_coef: 0.9492 - val_accuracy: 0.9545\n","\n","Epoch 00077: val_loss did not improve from 0.41030\n","Epoch 78/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4700 - dice_coef: 0.9474 - accuracy: 0.9519 - val_loss: 0.4287 - val_dice_coef: 0.9492 - val_accuracy: 0.9546\n","\n","Epoch 00078: val_loss did not improve from 0.41030\n","Epoch 79/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4721 - dice_coef: 0.9472 - accuracy: 0.9517 - val_loss: 0.4105 - val_dice_coef: 0.9515 - val_accuracy: 0.9572\n","\n","Epoch 00079: val_loss did not improve from 0.41030\n","Epoch 80/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4708 - dice_coef: 0.9472 - accuracy: 0.9517 - val_loss: 0.6615 - val_dice_coef: 0.9263 - val_accuracy: 0.9303\n","\n","Epoch 00080: val_loss did not improve from 0.41030\n","Epoch 81/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4732 - dice_coef: 0.9465 - accuracy: 0.9512 - val_loss: 0.5415 - val_dice_coef: 0.9352 - val_accuracy: 0.9398\n","\n","Epoch 00081: val_loss did not improve from 0.41030\n","Epoch 82/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4760 - dice_coef: 0.9468 - accuracy: 0.9514 - val_loss: 0.4457 - val_dice_coef: 0.9490 - val_accuracy: 0.9540\n","\n","Epoch 00082: val_loss did not improve from 0.41030\n","Epoch 83/100\n","246/246 [==============================] - 80s 326ms/step - loss: 0.4659 - dice_coef: 0.9484 - accuracy: 0.9528 - val_loss: 0.4913 - val_dice_coef: 0.9350 - val_accuracy: 0.9436\n","\n","Epoch 00083: val_loss did not improve from 0.41030\n","Epoch 84/100\n","246/246 [==============================] - 80s 327ms/step - loss: 0.4917 - dice_coef: 0.9443 - accuracy: 0.9490 - val_loss: 0.4528 - val_dice_coef: 0.9447 - val_accuracy: 0.9503\n","\n","Epoch 00084: val_loss did not improve from 0.41030\n","Epoch 00084: early stopping\n","TRAIN: [0 2 3 4 5 6 7 8] TEST: [1]\n","-----------fold 1--------------\n","Epoch 1/100\n","243/243 [==============================] - 93s 384ms/step - loss: 2.3097 - dice_coef: 0.6702 - accuracy: 0.7475 - val_loss: 2.1248 - val_dice_coef: 0.7765 - val_accuracy: 0.8365\n","\n","Epoch 00001: val_loss improved from inf to 2.12482, saving model to Checkpoint.h5\n","Epoch 2/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.9990 - dice_coef: 0.7790 - accuracy: 0.8269 - val_loss: 1.9702 - val_dice_coef: 0.7650 - val_accuracy: 0.8291\n","\n","Epoch 00002: val_loss improved from 2.12482 to 1.97018, saving model to Checkpoint.h5\n","Epoch 3/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.8990 - dice_coef: 0.7982 - accuracy: 0.8406 - val_loss: 1.8880 - val_dice_coef: 0.7815 - val_accuracy: 0.8323\n","\n","Epoch 00003: val_loss improved from 1.97018 to 1.88797, saving model to Checkpoint.h5\n","Epoch 4/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.8272 - dice_coef: 0.8031 - accuracy: 0.8387 - val_loss: 1.8532 - val_dice_coef: 0.7940 - val_accuracy: 0.7727\n","\n","Epoch 00004: val_loss improved from 1.88797 to 1.85321, saving model to Checkpoint.h5\n","Epoch 5/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.6433 - dice_coef: 0.8182 - accuracy: 0.8420 - val_loss: 1.4437 - val_dice_coef: 0.8295 - val_accuracy: 0.9090\n","\n","Epoch 00005: val_loss improved from 1.85321 to 1.44371, saving model to Checkpoint.h5\n","Epoch 6/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.1884 - dice_coef: 0.8613 - accuracy: 0.9028 - val_loss: 1.8926 - val_dice_coef: 0.8228 - val_accuracy: 0.8276\n","\n","Epoch 00006: val_loss did not improve from 1.44371\n","Epoch 7/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.8997 - dice_coef: 0.9005 - accuracy: 0.9122 - val_loss: 0.7987 - val_dice_coef: 0.9016 - val_accuracy: 0.9137\n","\n","Epoch 00007: val_loss improved from 1.44371 to 0.79870, saving model to Checkpoint.h5\n","Epoch 8/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.8555 - dice_coef: 0.9071 - accuracy: 0.9163 - val_loss: 0.8033 - val_dice_coef: 0.9046 - val_accuracy: 0.9145\n","\n","Epoch 00008: val_loss did not improve from 0.79870\n","Epoch 9/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.8170 - dice_coef: 0.9099 - accuracy: 0.9182 - val_loss: 0.7764 - val_dice_coef: 0.8966 - val_accuracy: 0.9113\n","\n","Epoch 00009: val_loss improved from 0.79870 to 0.77635, saving model to Checkpoint.h5\n","Epoch 10/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.7934 - dice_coef: 0.9126 - accuracy: 0.9206 - val_loss: 0.7384 - val_dice_coef: 0.9120 - val_accuracy: 0.9202\n","\n","Epoch 00010: val_loss improved from 0.77635 to 0.73840, saving model to Checkpoint.h5\n","Epoch 11/100\n","243/243 [==============================] - 80s 328ms/step - loss: 0.7661 - dice_coef: 0.9143 - accuracy: 0.9220 - val_loss: 0.6868 - val_dice_coef: 0.9151 - val_accuracy: 0.9233\n","\n","Epoch 00011: val_loss improved from 0.73840 to 0.68678, saving model to Checkpoint.h5\n","Epoch 12/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.7411 - dice_coef: 0.9163 - accuracy: 0.9237 - val_loss: 0.7334 - val_dice_coef: 0.8991 - val_accuracy: 0.9129\n","\n","Epoch 00012: val_loss did not improve from 0.68678\n","Epoch 13/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.7317 - dice_coef: 0.9164 - accuracy: 0.9240 - val_loss: 0.6777 - val_dice_coef: 0.9150 - val_accuracy: 0.9226\n","\n","Epoch 00013: val_loss improved from 0.68678 to 0.67766, saving model to Checkpoint.h5\n","Epoch 14/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.7184 - dice_coef: 0.9168 - accuracy: 0.9244 - val_loss: 0.6592 - val_dice_coef: 0.9191 - val_accuracy: 0.9280\n","\n","Epoch 00014: val_loss improved from 0.67766 to 0.65917, saving model to Checkpoint.h5\n","Epoch 15/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6852 - dice_coef: 0.9195 - accuracy: 0.9268 - val_loss: 0.6468 - val_dice_coef: 0.9211 - val_accuracy: 0.9281\n","\n","Epoch 00015: val_loss improved from 0.65917 to 0.64681, saving model to Checkpoint.h5\n","Epoch 16/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6747 - dice_coef: 0.9210 - accuracy: 0.9279 - val_loss: 0.6591 - val_dice_coef: 0.9180 - val_accuracy: 0.9269\n","\n","Epoch 00016: val_loss did not improve from 0.64681\n","Epoch 17/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6722 - dice_coef: 0.9210 - accuracy: 0.9280 - val_loss: 0.6984 - val_dice_coef: 0.9061 - val_accuracy: 0.9115\n","\n","Epoch 00017: val_loss did not improve from 0.64681\n","Epoch 18/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6575 - dice_coef: 0.9221 - accuracy: 0.9290 - val_loss: 0.7057 - val_dice_coef: 0.9100 - val_accuracy: 0.9199\n","\n","Epoch 00018: val_loss did not improve from 0.64681\n","Epoch 19/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6384 - dice_coef: 0.9226 - accuracy: 0.9295 - val_loss: 0.6189 - val_dice_coef: 0.9173 - val_accuracy: 0.9261\n","\n","Epoch 00019: val_loss improved from 0.64681 to 0.61892, saving model to Checkpoint.h5\n","Epoch 20/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6352 - dice_coef: 0.9238 - accuracy: 0.9304 - val_loss: 0.6566 - val_dice_coef: 0.9197 - val_accuracy: 0.9255\n","\n","Epoch 00020: val_loss did not improve from 0.61892\n","Epoch 21/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6277 - dice_coef: 0.9234 - accuracy: 0.9303 - val_loss: 0.8205 - val_dice_coef: 0.9070 - val_accuracy: 0.9107\n","\n","Epoch 00021: val_loss did not improve from 0.61892\n","Epoch 22/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6178 - dice_coef: 0.9249 - accuracy: 0.9312 - val_loss: 0.6498 - val_dice_coef: 0.9227 - val_accuracy: 0.9291\n","\n","Epoch 00022: val_loss did not improve from 0.61892\n","Epoch 23/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6201 - dice_coef: 0.9228 - accuracy: 0.9296 - val_loss: 0.6852 - val_dice_coef: 0.9149 - val_accuracy: 0.9237\n","\n","Epoch 00023: val_loss did not improve from 0.61892\n","Epoch 24/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5962 - dice_coef: 0.9268 - accuracy: 0.9333 - val_loss: 0.6333 - val_dice_coef: 0.9198 - val_accuracy: 0.9270\n","\n","Epoch 00024: val_loss did not improve from 0.61892\n","Epoch 25/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5983 - dice_coef: 0.9263 - accuracy: 0.9327 - val_loss: 0.5743 - val_dice_coef: 0.9279 - val_accuracy: 0.9335\n","\n","Epoch 00025: val_loss improved from 0.61892 to 0.57428, saving model to Checkpoint.h5\n","Epoch 26/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5916 - dice_coef: 0.9273 - accuracy: 0.9337 - val_loss: 0.5681 - val_dice_coef: 0.9229 - val_accuracy: 0.9288\n","\n","Epoch 00026: val_loss improved from 0.57428 to 0.56810, saving model to Checkpoint.h5\n","Epoch 27/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5737 - dice_coef: 0.9288 - accuracy: 0.9350 - val_loss: 0.6478 - val_dice_coef: 0.9216 - val_accuracy: 0.9284\n","\n","Epoch 00027: val_loss did not improve from 0.56810\n","Epoch 28/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5782 - dice_coef: 0.9280 - accuracy: 0.9344 - val_loss: 0.6592 - val_dice_coef: 0.9156 - val_accuracy: 0.9215\n","\n","Epoch 00028: val_loss did not improve from 0.56810\n","Epoch 29/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5845 - dice_coef: 0.9277 - accuracy: 0.9340 - val_loss: 0.5798 - val_dice_coef: 0.9188 - val_accuracy: 0.9255\n","\n","Epoch 00029: val_loss did not improve from 0.56810\n","Epoch 30/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.5594 - dice_coef: 0.9307 - accuracy: 0.9368 - val_loss: 0.5411 - val_dice_coef: 0.9239 - val_accuracy: 0.9337\n","\n","Epoch 00030: val_loss improved from 0.56810 to 0.54112, saving model to Checkpoint.h5\n","Epoch 31/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5815 - dice_coef: 0.9268 - accuracy: 0.9332 - val_loss: 0.6026 - val_dice_coef: 0.9253 - val_accuracy: 0.9321\n","\n","Epoch 00031: val_loss did not improve from 0.54112\n","Epoch 32/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.5720 - dice_coef: 0.9288 - accuracy: 0.9349 - val_loss: 0.5204 - val_dice_coef: 0.9303 - val_accuracy: 0.9373\n","\n","Epoch 00032: val_loss improved from 0.54112 to 0.52041, saving model to Checkpoint.h5\n","Epoch 33/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5558 - dice_coef: 0.9302 - accuracy: 0.9364 - val_loss: 0.6386 - val_dice_coef: 0.9158 - val_accuracy: 0.9262\n","\n","Epoch 00033: val_loss did not improve from 0.52041\n","Epoch 34/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5482 - dice_coef: 0.9319 - accuracy: 0.9379 - val_loss: 0.5362 - val_dice_coef: 0.9313 - val_accuracy: 0.9361\n","\n","Epoch 00034: val_loss did not improve from 0.52041\n","Epoch 35/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.5503 - dice_coef: 0.9305 - accuracy: 0.9366 - val_loss: 0.5252 - val_dice_coef: 0.9296 - val_accuracy: 0.9358\n","\n","Epoch 00035: val_loss did not improve from 0.52041\n","Epoch 36/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5456 - dice_coef: 0.9311 - accuracy: 0.9371 - val_loss: 0.4873 - val_dice_coef: 0.9326 - val_accuracy: 0.9389\n","\n","Epoch 00036: val_loss improved from 0.52041 to 0.48729, saving model to Checkpoint.h5\n","Epoch 37/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5391 - dice_coef: 0.9324 - accuracy: 0.9383 - val_loss: 0.5386 - val_dice_coef: 0.9290 - val_accuracy: 0.9357\n","\n","Epoch 00037: val_loss did not improve from 0.48729\n","Epoch 38/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5418 - dice_coef: 0.9330 - accuracy: 0.9388 - val_loss: 0.5416 - val_dice_coef: 0.9289 - val_accuracy: 0.9359\n","\n","Epoch 00038: val_loss did not improve from 0.48729\n","Epoch 39/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5359 - dice_coef: 0.9332 - accuracy: 0.9390 - val_loss: 0.6437 - val_dice_coef: 0.9211 - val_accuracy: 0.9269\n","\n","Epoch 00039: val_loss did not improve from 0.48729\n","Epoch 40/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5438 - dice_coef: 0.9331 - accuracy: 0.9388 - val_loss: 1.2045 - val_dice_coef: 0.8686 - val_accuracy: 0.8725\n","\n","Epoch 00040: val_loss did not improve from 0.48729\n","Epoch 41/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5257 - dice_coef: 0.9339 - accuracy: 0.9397 - val_loss: 0.4903 - val_dice_coef: 0.9321 - val_accuracy: 0.9389\n","\n","Epoch 00041: val_loss did not improve from 0.48729\n","Epoch 42/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5255 - dice_coef: 0.9354 - accuracy: 0.9410 - val_loss: 0.5236 - val_dice_coef: 0.9295 - val_accuracy: 0.9345\n","\n","Epoch 00042: val_loss did not improve from 0.48729\n","Epoch 43/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.5343 - dice_coef: 0.9347 - accuracy: 0.9403 - val_loss: 0.6241 - val_dice_coef: 0.9211 - val_accuracy: 0.9269\n","\n","Epoch 00043: val_loss did not improve from 0.48729\n","Epoch 44/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5094 - dice_coef: 0.9367 - accuracy: 0.9421 - val_loss: 0.5385 - val_dice_coef: 0.9299 - val_accuracy: 0.9356\n","\n","Epoch 00044: val_loss did not improve from 0.48729\n","Epoch 45/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.5198 - dice_coef: 0.9357 - accuracy: 0.9413 - val_loss: 0.9051 - val_dice_coef: 0.8924 - val_accuracy: 0.8963\n","\n","Epoch 00045: val_loss did not improve from 0.48729\n","Epoch 46/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.5192 - dice_coef: 0.9358 - accuracy: 0.9412 - val_loss: 0.7023 - val_dice_coef: 0.9199 - val_accuracy: 0.9243\n","\n","Epoch 00046: val_loss did not improve from 0.48729\n","Epoch 00046: early stopping\n","TRAIN: [0 1 3 4 5 6 7 8] TEST: [2]\n","-----------fold 2--------------\n","Epoch 1/100\n","243/243 [==============================] - 93s 383ms/step - loss: 1.9156 - dice_coef: 0.7489 - accuracy: 0.8153 - val_loss: 1.7858 - val_dice_coef: 0.8054 - val_accuracy: 0.8076\n","\n","Epoch 00001: val_loss improved from inf to 1.78576, saving model to Checkpoint.h5\n","Epoch 2/100\n","243/243 [==============================] - 80s 327ms/step - loss: 1.4886 - dice_coef: 0.8419 - accuracy: 0.8909 - val_loss: 1.6521 - val_dice_coef: 0.7963 - val_accuracy: 0.8264\n","\n","Epoch 00002: val_loss improved from 1.78576 to 1.65208, saving model to Checkpoint.h5\n","Epoch 3/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.3123 - dice_coef: 0.8575 - accuracy: 0.8978 - val_loss: 1.1645 - val_dice_coef: 0.8696 - val_accuracy: 0.9035\n","\n","Epoch 00003: val_loss improved from 1.65208 to 1.16452, saving model to Checkpoint.h5\n","Epoch 4/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.1690 - dice_coef: 0.8751 - accuracy: 0.9066 - val_loss: 1.0503 - val_dice_coef: 0.8902 - val_accuracy: 0.9144\n","\n","Epoch 00004: val_loss improved from 1.16452 to 1.05034, saving model to Checkpoint.h5\n","Epoch 5/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.0858 - dice_coef: 0.8816 - accuracy: 0.9077 - val_loss: 0.9951 - val_dice_coef: 0.8910 - val_accuracy: 0.9154\n","\n","Epoch 00005: val_loss improved from 1.05034 to 0.99510, saving model to Checkpoint.h5\n","Epoch 6/100\n","243/243 [==============================] - 79s 327ms/step - loss: 1.0053 - dice_coef: 0.8904 - accuracy: 0.9124 - val_loss: 0.9201 - val_dice_coef: 0.8936 - val_accuracy: 0.9157\n","\n","Epoch 00006: val_loss improved from 0.99510 to 0.92011, saving model to Checkpoint.h5\n","Epoch 7/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.9562 - dice_coef: 0.8934 - accuracy: 0.9129 - val_loss: 0.9928 - val_dice_coef: 0.8960 - val_accuracy: 0.9095\n","\n","Epoch 00007: val_loss did not improve from 0.92011\n","Epoch 8/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.9090 - dice_coef: 0.8979 - accuracy: 0.9149 - val_loss: 0.8137 - val_dice_coef: 0.9071 - val_accuracy: 0.9236\n","\n","Epoch 00008: val_loss improved from 0.92011 to 0.81366, saving model to Checkpoint.h5\n","Epoch 9/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.8743 - dice_coef: 0.9017 - accuracy: 0.9168 - val_loss: 0.7844 - val_dice_coef: 0.9117 - val_accuracy: 0.9270\n","\n","Epoch 00009: val_loss improved from 0.81366 to 0.78443, saving model to Checkpoint.h5\n","Epoch 10/100\n","243/243 [==============================] - 80s 328ms/step - loss: 0.8382 - dice_coef: 0.9052 - accuracy: 0.9190 - val_loss: 0.8230 - val_dice_coef: 0.9109 - val_accuracy: 0.9216\n","\n","Epoch 00010: val_loss did not improve from 0.78443\n","Epoch 11/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.8209 - dice_coef: 0.9067 - accuracy: 0.9196 - val_loss: 0.7951 - val_dice_coef: 0.8951 - val_accuracy: 0.9097\n","\n","Epoch 00011: val_loss did not improve from 0.78443\n","Epoch 12/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.7978 - dice_coef: 0.9077 - accuracy: 0.9199 - val_loss: 0.7843 - val_dice_coef: 0.9089 - val_accuracy: 0.9190\n","\n","Epoch 00012: val_loss improved from 0.78443 to 0.78432, saving model to Checkpoint.h5\n","Epoch 13/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.7755 - dice_coef: 0.9099 - accuracy: 0.9213 - val_loss: 0.9200 - val_dice_coef: 0.8964 - val_accuracy: 0.9041\n","\n","Epoch 00013: val_loss did not improve from 0.78432\n","Epoch 14/100\n","243/243 [==============================] - 80s 328ms/step - loss: 0.7591 - dice_coef: 0.9114 - accuracy: 0.9223 - val_loss: 0.7217 - val_dice_coef: 0.9062 - val_accuracy: 0.9162\n","\n","Epoch 00014: val_loss improved from 0.78432 to 0.72167, saving model to Checkpoint.h5\n","Epoch 15/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.7450 - dice_coef: 0.9126 - accuracy: 0.9230 - val_loss: 0.9437 - val_dice_coef: 0.8781 - val_accuracy: 0.8882\n","\n","Epoch 00015: val_loss did not improve from 0.72167\n","Epoch 16/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.7303 - dice_coef: 0.9129 - accuracy: 0.9231 - val_loss: 1.0808 - val_dice_coef: 0.8851 - val_accuracy: 0.8909\n","\n","Epoch 00016: val_loss did not improve from 0.72167\n","Epoch 17/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.7093 - dice_coef: 0.9156 - accuracy: 0.9252 - val_loss: 0.7577 - val_dice_coef: 0.8976 - val_accuracy: 0.9072\n","\n","Epoch 00017: val_loss did not improve from 0.72167\n","Epoch 18/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.7012 - dice_coef: 0.9150 - accuracy: 0.9245 - val_loss: 0.6366 - val_dice_coef: 0.9218 - val_accuracy: 0.9322\n","\n","Epoch 00018: val_loss improved from 0.72167 to 0.63664, saving model to Checkpoint.h5\n","Epoch 19/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.6926 - dice_coef: 0.9161 - accuracy: 0.9253 - val_loss: 0.6803 - val_dice_coef: 0.9059 - val_accuracy: 0.9174\n","\n","Epoch 00019: val_loss did not improve from 0.63664\n","Epoch 20/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6812 - dice_coef: 0.9163 - accuracy: 0.9254 - val_loss: 0.6386 - val_dice_coef: 0.9168 - val_accuracy: 0.9254\n","\n","Epoch 00020: val_loss did not improve from 0.63664\n","Epoch 21/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6693 - dice_coef: 0.9187 - accuracy: 0.9275 - val_loss: 0.7052 - val_dice_coef: 0.9001 - val_accuracy: 0.9102\n","\n","Epoch 00021: val_loss did not improve from 0.63664\n","Epoch 22/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.6597 - dice_coef: 0.9187 - accuracy: 0.9273 - val_loss: 0.8740 - val_dice_coef: 0.8961 - val_accuracy: 0.9021\n","\n","Epoch 00022: val_loss did not improve from 0.63664\n","Epoch 23/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6574 - dice_coef: 0.9182 - accuracy: 0.9268 - val_loss: 0.7566 - val_dice_coef: 0.8880 - val_accuracy: 0.9001\n","\n","Epoch 00023: val_loss did not improve from 0.63664\n","Epoch 24/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6331 - dice_coef: 0.9228 - accuracy: 0.9308 - val_loss: 1.7689 - val_dice_coef: 0.8223 - val_accuracy: 0.8229\n","\n","Epoch 00024: val_loss did not improve from 0.63664\n","Epoch 25/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6339 - dice_coef: 0.9216 - accuracy: 0.9296 - val_loss: 0.6200 - val_dice_coef: 0.9202 - val_accuracy: 0.9282\n","\n","Epoch 00025: val_loss improved from 0.63664 to 0.61997, saving model to Checkpoint.h5\n","Epoch 26/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6242 - dice_coef: 0.9219 - accuracy: 0.9299 - val_loss: 0.6713 - val_dice_coef: 0.8975 - val_accuracy: 0.9099\n","\n","Epoch 00026: val_loss did not improve from 0.61997\n","Epoch 27/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6157 - dice_coef: 0.9233 - accuracy: 0.9313 - val_loss: 0.6831 - val_dice_coef: 0.8985 - val_accuracy: 0.9070\n","\n","Epoch 00027: val_loss did not improve from 0.61997\n","Epoch 28/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6129 - dice_coef: 0.9238 - accuracy: 0.9315 - val_loss: 1.0466 - val_dice_coef: 0.8806 - val_accuracy: 0.8860\n","\n","Epoch 00028: val_loss did not improve from 0.61997\n","Epoch 29/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6108 - dice_coef: 0.9241 - accuracy: 0.9316 - val_loss: 0.5965 - val_dice_coef: 0.9250 - val_accuracy: 0.9326\n","\n","Epoch 00029: val_loss improved from 0.61997 to 0.59647, saving model to Checkpoint.h5\n","Epoch 30/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6094 - dice_coef: 0.9243 - accuracy: 0.9318 - val_loss: 0.5820 - val_dice_coef: 0.9230 - val_accuracy: 0.9312\n","\n","Epoch 00030: val_loss improved from 0.59647 to 0.58203, saving model to Checkpoint.h5\n","Epoch 31/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.6009 - dice_coef: 0.9248 - accuracy: 0.9323 - val_loss: 0.6435 - val_dice_coef: 0.9160 - val_accuracy: 0.9258\n","\n","Epoch 00031: val_loss did not improve from 0.58203\n","Epoch 32/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.6044 - dice_coef: 0.9238 - accuracy: 0.9312 - val_loss: 0.5293 - val_dice_coef: 0.9330 - val_accuracy: 0.9401\n","\n","Epoch 00032: val_loss improved from 0.58203 to 0.52929, saving model to Checkpoint.h5\n","Epoch 33/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5838 - dice_coef: 0.9266 - accuracy: 0.9338 - val_loss: 0.5625 - val_dice_coef: 0.9276 - val_accuracy: 0.9366\n","\n","Epoch 00033: val_loss did not improve from 0.52929\n","Epoch 34/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.5913 - dice_coef: 0.9254 - accuracy: 0.9326 - val_loss: 0.7179 - val_dice_coef: 0.8985 - val_accuracy: 0.9091\n","\n","Epoch 00034: val_loss did not improve from 0.52929\n","Epoch 35/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5896 - dice_coef: 0.9267 - accuracy: 0.9338 - val_loss: 0.9628 - val_dice_coef: 0.8909 - val_accuracy: 0.8959\n","\n","Epoch 00035: val_loss did not improve from 0.52929\n","Epoch 36/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5746 - dice_coef: 0.9280 - accuracy: 0.9351 - val_loss: 0.5416 - val_dice_coef: 0.9292 - val_accuracy: 0.9381\n","\n","Epoch 00036: val_loss did not improve from 0.52929\n","Epoch 37/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5715 - dice_coef: 0.9292 - accuracy: 0.9362 - val_loss: 0.6055 - val_dice_coef: 0.9153 - val_accuracy: 0.9254\n","\n","Epoch 00037: val_loss did not improve from 0.52929\n","Epoch 38/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5679 - dice_coef: 0.9298 - accuracy: 0.9365 - val_loss: 0.5761 - val_dice_coef: 0.9272 - val_accuracy: 0.9344\n","\n","Epoch 00038: val_loss did not improve from 0.52929\n","Epoch 39/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.5605 - dice_coef: 0.9305 - accuracy: 0.9372 - val_loss: 0.5375 - val_dice_coef: 0.9311 - val_accuracy: 0.9389\n","\n","Epoch 00039: val_loss did not improve from 0.52929\n","Epoch 40/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5512 - dice_coef: 0.9316 - accuracy: 0.9382 - val_loss: 0.5892 - val_dice_coef: 0.9241 - val_accuracy: 0.9356\n","\n","Epoch 00040: val_loss did not improve from 0.52929\n","Epoch 41/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5662 - dice_coef: 0.9302 - accuracy: 0.9368 - val_loss: 0.5216 - val_dice_coef: 0.9304 - val_accuracy: 0.9383\n","\n","Epoch 00041: val_loss improved from 0.52929 to 0.52162, saving model to Checkpoint.h5\n","Epoch 42/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5660 - dice_coef: 0.9295 - accuracy: 0.9362 - val_loss: 1.6264 - val_dice_coef: 0.8291 - val_accuracy: 0.8306\n","\n","Epoch 00042: val_loss did not improve from 0.52162\n","Epoch 43/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5466 - dice_coef: 0.9321 - accuracy: 0.9387 - val_loss: 0.5401 - val_dice_coef: 0.9260 - val_accuracy: 0.9354\n","\n","Epoch 00043: val_loss did not improve from 0.52162\n","Epoch 44/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5554 - dice_coef: 0.9311 - accuracy: 0.9376 - val_loss: 0.6382 - val_dice_coef: 0.9134 - val_accuracy: 0.9208\n","\n","Epoch 00044: val_loss did not improve from 0.52162\n","Epoch 45/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5471 - dice_coef: 0.9328 - accuracy: 0.9390 - val_loss: 0.6099 - val_dice_coef: 0.9243 - val_accuracy: 0.9300\n","\n","Epoch 00045: val_loss did not improve from 0.52162\n","Epoch 46/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.5398 - dice_coef: 0.9330 - accuracy: 0.9394 - val_loss: 0.5217 - val_dice_coef: 0.9376 - val_accuracy: 0.9433\n","\n","Epoch 00046: val_loss did not improve from 0.52162\n","Epoch 47/100\n","243/243 [==============================] - 80s 327ms/step - loss: 0.5457 - dice_coef: 0.9327 - accuracy: 0.9389 - val_loss: 0.5211 - val_dice_coef: 0.9357 - val_accuracy: 0.9412\n","\n","Epoch 00047: val_loss improved from 0.52162 to 0.52110, saving model to Checkpoint.h5\n","Epoch 48/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5500 - dice_coef: 0.9328 - accuracy: 0.9390 - val_loss: 0.4712 - val_dice_coef: 0.9411 - val_accuracy: 0.9472\n","\n","Epoch 00048: val_loss improved from 0.52110 to 0.47122, saving model to Checkpoint.h5\n","Epoch 49/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5339 - dice_coef: 0.9346 - accuracy: 0.9407 - val_loss: 0.4879 - val_dice_coef: 0.9368 - val_accuracy: 0.9432\n","\n","Epoch 00049: val_loss did not improve from 0.47122\n","Epoch 50/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5441 - dice_coef: 0.9333 - accuracy: 0.9395 - val_loss: 0.5630 - val_dice_coef: 0.9327 - val_accuracy: 0.9375\n","\n","Epoch 00050: val_loss did not improve from 0.47122\n","Epoch 51/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5424 - dice_coef: 0.9342 - accuracy: 0.9402 - val_loss: 0.6647 - val_dice_coef: 0.9179 - val_accuracy: 0.9236\n","\n","Epoch 00051: val_loss did not improve from 0.47122\n","Epoch 52/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5409 - dice_coef: 0.9341 - accuracy: 0.9402 - val_loss: 1.0361 - val_dice_coef: 0.8843 - val_accuracy: 0.8873\n","\n","Epoch 00052: val_loss did not improve from 0.47122\n","Epoch 53/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5304 - dice_coef: 0.9355 - accuracy: 0.9414 - val_loss: 0.4928 - val_dice_coef: 0.9386 - val_accuracy: 0.9447\n","\n","Epoch 00053: val_loss did not improve from 0.47122\n","Epoch 54/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5342 - dice_coef: 0.9348 - accuracy: 0.9408 - val_loss: 0.5059 - val_dice_coef: 0.9376 - val_accuracy: 0.9435\n","\n","Epoch 00054: val_loss did not improve from 0.47122\n","Epoch 55/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5222 - dice_coef: 0.9366 - accuracy: 0.9424 - val_loss: 0.4847 - val_dice_coef: 0.9438 - val_accuracy: 0.9494\n","\n","Epoch 00055: val_loss did not improve from 0.47122\n","Epoch 56/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5198 - dice_coef: 0.9377 - accuracy: 0.9434 - val_loss: 0.5067 - val_dice_coef: 0.9331 - val_accuracy: 0.9392\n","\n","Epoch 00056: val_loss did not improve from 0.47122\n","Epoch 57/100\n","243/243 [==============================] - 79s 327ms/step - loss: 0.5243 - dice_coef: 0.9362 - accuracy: 0.9421 - val_loss: 0.4878 - val_dice_coef: 0.9419 - val_accuracy: 0.9471\n","\n","Epoch 00057: val_loss did not improve from 0.47122\n","Epoch 58/100\n","243/243 [==============================] - 79s 326ms/step - loss: 0.5234 - dice_coef: 0.9373 - accuracy: 0.9430 - val_loss: 0.6570 - val_dice_coef: 0.9233 - val_accuracy: 0.9280\n","\n","Epoch 00058: val_loss did not improve from 0.47122\n","Epoch 00058: early stopping\n","TRAIN: [0 1 2 4 5 6 7 8] TEST: [3]\n","-----------fold 3--------------\n","Epoch 1/100\n","246/246 [==============================] - 94s 383ms/step - loss: 1.9476 - dice_coef: 0.7270 - accuracy: 0.8130 - val_loss: 1.6413 - val_dice_coef: 0.8447 - val_accuracy: 0.8923\n","\n","Epoch 00001: val_loss improved from inf to 1.64128, saving model to Checkpoint.h5\n","Epoch 2/100\n","246/246 [==============================] - 81s 328ms/step - loss: 1.4898 - dice_coef: 0.8466 - accuracy: 0.8920 - val_loss: 2.3796 - val_dice_coef: 0.6181 - val_accuracy: 0.6522\n","\n","Epoch 00002: val_loss did not improve from 1.64128\n","Epoch 3/100\n","246/246 [==============================] - 81s 328ms/step - loss: 1.3095 - dice_coef: 0.8646 - accuracy: 0.9027 - val_loss: 1.3372 - val_dice_coef: 0.8297 - val_accuracy: 0.8678\n","\n","Epoch 00003: val_loss improved from 1.64128 to 1.33722, saving model to Checkpoint.h5\n","Epoch 4/100\n","246/246 [==============================] - 81s 328ms/step - loss: 1.1840 - dice_coef: 0.8743 - accuracy: 0.9052 - val_loss: 1.5751 - val_dice_coef: 0.8494 - val_accuracy: 0.8637\n","\n","Epoch 00004: val_loss did not improve from 1.33722\n","Epoch 5/100\n","246/246 [==============================] - 81s 328ms/step - loss: 1.0796 - dice_coef: 0.8864 - accuracy: 0.9111 - val_loss: 0.9738 - val_dice_coef: 0.8945 - val_accuracy: 0.9162\n","\n","Epoch 00005: val_loss improved from 1.33722 to 0.97381, saving model to Checkpoint.h5\n","Epoch 6/100\n","246/246 [==============================] - 81s 328ms/step - loss: 1.0093 - dice_coef: 0.8926 - accuracy: 0.9135 - val_loss: 1.3825 - val_dice_coef: 0.8495 - val_accuracy: 0.8628\n","\n","Epoch 00006: val_loss did not improve from 0.97381\n","Epoch 7/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.9527 - dice_coef: 0.8973 - accuracy: 0.9158 - val_loss: 0.9658 - val_dice_coef: 0.8982 - val_accuracy: 0.9129\n","\n","Epoch 00007: val_loss improved from 0.97381 to 0.96579, saving model to Checkpoint.h5\n","Epoch 8/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.9052 - dice_coef: 0.9013 - accuracy: 0.9173 - val_loss: 1.1705 - val_dice_coef: 0.8794 - val_accuracy: 0.8876\n","\n","Epoch 00008: val_loss did not improve from 0.96579\n","Epoch 9/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.8650 - dice_coef: 0.9059 - accuracy: 0.9203 - val_loss: 0.8356 - val_dice_coef: 0.9073 - val_accuracy: 0.9192\n","\n","Epoch 00009: val_loss improved from 0.96579 to 0.83563, saving model to Checkpoint.h5\n","Epoch 10/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.8428 - dice_coef: 0.9064 - accuracy: 0.9196 - val_loss: 0.8704 - val_dice_coef: 0.8799 - val_accuracy: 0.8937\n","\n","Epoch 00010: val_loss did not improve from 0.83563\n","Epoch 11/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.8088 - dice_coef: 0.9092 - accuracy: 0.9214 - val_loss: 0.8436 - val_dice_coef: 0.9017 - val_accuracy: 0.9123\n","\n","Epoch 00011: val_loss did not improve from 0.83563\n","Epoch 12/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.7823 - dice_coef: 0.9114 - accuracy: 0.9229 - val_loss: 0.7362 - val_dice_coef: 0.9148 - val_accuracy: 0.9258\n","\n","Epoch 00012: val_loss improved from 0.83563 to 0.73619, saving model to Checkpoint.h5\n","Epoch 13/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.7677 - dice_coef: 0.9109 - accuracy: 0.9219 - val_loss: 1.0709 - val_dice_coef: 0.8774 - val_accuracy: 0.8890\n","\n","Epoch 00013: val_loss did not improve from 0.73619\n","Epoch 14/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.7380 - dice_coef: 0.9148 - accuracy: 0.9253 - val_loss: 0.7046 - val_dice_coef: 0.9115 - val_accuracy: 0.9230\n","\n","Epoch 00014: val_loss improved from 0.73619 to 0.70461, saving model to Checkpoint.h5\n","Epoch 15/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.7282 - dice_coef: 0.9151 - accuracy: 0.9251 - val_loss: 0.7587 - val_dice_coef: 0.9141 - val_accuracy: 0.9213\n","\n","Epoch 00015: val_loss did not improve from 0.70461\n","Epoch 16/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.7083 - dice_coef: 0.9165 - accuracy: 0.9261 - val_loss: 0.7503 - val_dice_coef: 0.8914 - val_accuracy: 0.9059\n","\n","Epoch 00016: val_loss did not improve from 0.70461\n","Epoch 17/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6907 - dice_coef: 0.9188 - accuracy: 0.9281 - val_loss: 0.7108 - val_dice_coef: 0.9115 - val_accuracy: 0.9216\n","\n","Epoch 00017: val_loss did not improve from 0.70461\n","Epoch 18/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6795 - dice_coef: 0.9180 - accuracy: 0.9272 - val_loss: 0.7064 - val_dice_coef: 0.9105 - val_accuracy: 0.9220\n","\n","Epoch 00018: val_loss did not improve from 0.70461\n","Epoch 19/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6686 - dice_coef: 0.9204 - accuracy: 0.9290 - val_loss: 0.9916 - val_dice_coef: 0.8845 - val_accuracy: 0.8937\n","\n","Epoch 00019: val_loss did not improve from 0.70461\n","Epoch 20/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6628 - dice_coef: 0.9203 - accuracy: 0.9288 - val_loss: 0.8659 - val_dice_coef: 0.8995 - val_accuracy: 0.9042\n","\n","Epoch 00020: val_loss did not improve from 0.70461\n","Epoch 21/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6541 - dice_coef: 0.9205 - accuracy: 0.9289 - val_loss: 0.6036 - val_dice_coef: 0.9247 - val_accuracy: 0.9338\n","\n","Epoch 00021: val_loss improved from 0.70461 to 0.60359, saving model to Checkpoint.h5\n","Epoch 22/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6349 - dice_coef: 0.9228 - accuracy: 0.9310 - val_loss: 0.6647 - val_dice_coef: 0.9099 - val_accuracy: 0.9188\n","\n","Epoch 00022: val_loss did not improve from 0.60359\n","Epoch 23/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6269 - dice_coef: 0.9238 - accuracy: 0.9317 - val_loss: 0.7420 - val_dice_coef: 0.9088 - val_accuracy: 0.9170\n","\n","Epoch 00023: val_loss did not improve from 0.60359\n","Epoch 24/100\n","246/246 [==============================] - 81s 329ms/step - loss: 0.6302 - dice_coef: 0.9237 - accuracy: 0.9315 - val_loss: 0.7710 - val_dice_coef: 0.9079 - val_accuracy: 0.9126\n","\n","Epoch 00024: val_loss did not improve from 0.60359\n","Epoch 25/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6193 - dice_coef: 0.9245 - accuracy: 0.9322 - val_loss: 0.6731 - val_dice_coef: 0.9173 - val_accuracy: 0.9249\n","\n","Epoch 00025: val_loss did not improve from 0.60359\n","Epoch 26/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6152 - dice_coef: 0.9239 - accuracy: 0.9316 - val_loss: 0.5889 - val_dice_coef: 0.9216 - val_accuracy: 0.9310\n","\n","Epoch 00026: val_loss improved from 0.60359 to 0.58891, saving model to Checkpoint.h5\n","Epoch 27/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.6055 - dice_coef: 0.9261 - accuracy: 0.9334 - val_loss: 0.7676 - val_dice_coef: 0.9085 - val_accuracy: 0.9156\n","\n","Epoch 00027: val_loss did not improve from 0.58891\n","Epoch 28/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.5947 - dice_coef: 0.9270 - accuracy: 0.9343 - val_loss: 0.9256 - val_dice_coef: 0.8907 - val_accuracy: 0.8959\n","\n","Epoch 00028: val_loss did not improve from 0.58891\n","Epoch 29/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.5805 - dice_coef: 0.9288 - accuracy: 0.9360 - val_loss: 0.6652 - val_dice_coef: 0.9173 - val_accuracy: 0.9232\n","\n","Epoch 00029: val_loss did not improve from 0.58891\n","Epoch 30/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.5923 - dice_coef: 0.9268 - accuracy: 0.9339 - val_loss: 0.6381 - val_dice_coef: 0.9150 - val_accuracy: 0.9234\n","\n","Epoch 00030: val_loss did not improve from 0.58891\n","Epoch 31/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.5673 - dice_coef: 0.9304 - accuracy: 0.9372 - val_loss: 0.6803 - val_dice_coef: 0.9145 - val_accuracy: 0.9234\n","\n","Epoch 00031: val_loss did not improve from 0.58891\n","Epoch 32/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.5744 - dice_coef: 0.9291 - accuracy: 0.9360 - val_loss: 0.7483 - val_dice_coef: 0.8965 - val_accuracy: 0.9087\n","\n","Epoch 00032: val_loss did not improve from 0.58891\n","Epoch 33/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.5772 - dice_coef: 0.9284 - accuracy: 0.9353 - val_loss: 0.5577 - val_dice_coef: 0.9273 - val_accuracy: 0.9342\n","\n","Epoch 00033: val_loss improved from 0.58891 to 0.55771, saving model to Checkpoint.h5\n","Epoch 34/100\n","246/246 [==============================] - 81s 328ms/step - loss: 0.5727 - dice_coef: 0.9293 - accuracy: 0.9362 - val_loss: 0.6344 - val_dice_coef: 0.9186 - val_accuracy: 0.9273\n","\n","Epoch 00034: val_loss did not improve from 0.55771\n","Epoch 35/100\n","200/246 [=======================>......] - ETA: 14s - loss: 0.5665 - dice_coef: 0.9303 - accuracy: 0.9368Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v2oPUnPxoA6B","colab_type":"code","outputId":"91503230-e52e-4c74-a042-aed653a71e58","executionInfo":{"status":"ok","timestamp":1591514129234,"user_tz":-330,"elapsed":11723086,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/4 Class/Ki67/KFold\"\n","\n","oneOut = LeaveOneOut()\n","fold = 0\n","num_epoch = 100\n","\n","for train_index, test_index in oneOut.split(X):\n","  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","  if test_index in (6, 7, 8):\n","    TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","    TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","    TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","    TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","    TrainX = TrainX.astype('float32')/255\n","    TestX = TestX.astype('float32')/255\n","    convertToLabels(TrainY)\n","    TrainY = keras.utils.to_categorical(TrainY,num_classes =3,dtype='int16')\n","    convertToLabels(TestY)\n","    TestY = keras.utils.to_categorical(TestY,num_classes =3,dtype='int16')\n","    ValX = TrainX[(int)(0.8*TrainX.shape[0]):]\n","    ValY = TrainY[(int)(0.8*TrainY.shape[0]):]\n","\n","    model = get_model((240,240,3),16,4)\n","    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","    mc = ModelCheckpoint('Checkpoint.h5', monitor='val_loss', mode='min', verbose = 1, save_best_only=True)\n","    model.compile(loss=combined_loss, optimizer= optimizer , metrics=[dice_coef,'accuracy']) \n","    datagen = get_batch(batch_size, TrainX, TrainY)\n","    n_points = len(TrainX)\n","\n","  \n","    print('-----------fold {}--------------'.format(fold))\n","    model.fit(datagen, validation_data = [ValX, ValY],\n","                  epochs = num_epoch, steps_per_epoch = math.ceil(n_points / batch_size), callbacks =[es,mc],  shuffle =True)\n","    model.save(MODELS_PATH + '/LadderNet_Ki67_'+ str(fold) +'.h5')\n","\n","  fold = fold + 1\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAIN: [1 2 3 4 5 6 7 8] TEST: [0]\n","TRAIN: [0 2 3 4 5 6 7 8] TEST: [1]\n","TRAIN: [0 1 3 4 5 6 7 8] TEST: [2]\n","TRAIN: [0 1 2 4 5 6 7 8] TEST: [3]\n","TRAIN: [0 1 2 3 5 6 7 8] TEST: [4]\n","TRAIN: [0 1 2 3 4 6 7 8] TEST: [5]\n","TRAIN: [0 1 2 3 4 5 7 8] TEST: [6]\n","-----------fold 6--------------\n","Epoch 1/100\n","246/246 [==============================] - 103s 419ms/step - loss: 2.2884 - dice_coef: 0.5917 - accuracy: 0.7431 - val_loss: 2.6924 - val_dice_coef: 0.7583 - val_accuracy: 0.7466\n","\n","Epoch 00001: val_loss improved from inf to 2.69242, saving model to Checkpoint.h5\n","Epoch 2/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.5365 - dice_coef: 0.8234 - accuracy: 0.8788 - val_loss: 1.5888 - val_dice_coef: 0.7761 - val_accuracy: 0.8599\n","\n","Epoch 00002: val_loss improved from 2.69242 to 1.58876, saving model to Checkpoint.h5\n","Epoch 3/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.3856 - dice_coef: 0.8420 - accuracy: 0.8989 - val_loss: 1.3371 - val_dice_coef: 0.8275 - val_accuracy: 0.9027\n","\n","Epoch 00003: val_loss improved from 1.58876 to 1.33709, saving model to Checkpoint.h5\n","Epoch 4/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.2481 - dice_coef: 0.8580 - accuracy: 0.9046 - val_loss: 1.2846 - val_dice_coef: 0.8261 - val_accuracy: 0.8830\n","\n","Epoch 00004: val_loss improved from 1.33709 to 1.28463, saving model to Checkpoint.h5\n","Epoch 5/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.1470 - dice_coef: 0.8676 - accuracy: 0.9075 - val_loss: 1.1970 - val_dice_coef: 0.8277 - val_accuracy: 0.8757\n","\n","Epoch 00005: val_loss improved from 1.28463 to 1.19705, saving model to Checkpoint.h5\n","Epoch 6/100\n","246/246 [==============================] - 82s 332ms/step - loss: 1.0486 - dice_coef: 0.8806 - accuracy: 0.9124 - val_loss: 1.0651 - val_dice_coef: 0.8545 - val_accuracy: 0.8974\n","\n","Epoch 00006: val_loss improved from 1.19705 to 1.06513, saving model to Checkpoint.h5\n","Epoch 7/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9826 - dice_coef: 0.8863 - accuracy: 0.9145 - val_loss: 0.9679 - val_dice_coef: 0.8773 - val_accuracy: 0.9086\n","\n","Epoch 00007: val_loss improved from 1.06513 to 0.96786, saving model to Checkpoint.h5\n","Epoch 8/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9310 - dice_coef: 0.8930 - accuracy: 0.9164 - val_loss: 0.9614 - val_dice_coef: 0.8735 - val_accuracy: 0.9082\n","\n","Epoch 00008: val_loss improved from 0.96786 to 0.96141, saving model to Checkpoint.h5\n","Epoch 9/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8875 - dice_coef: 0.8963 - accuracy: 0.9175 - val_loss: 0.9240 - val_dice_coef: 0.8802 - val_accuracy: 0.9085\n","\n","Epoch 00009: val_loss improved from 0.96141 to 0.92402, saving model to Checkpoint.h5\n","Epoch 10/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8510 - dice_coef: 0.9009 - accuracy: 0.9194 - val_loss: 1.1959 - val_dice_coef: 0.8707 - val_accuracy: 0.8864\n","\n","Epoch 00010: val_loss did not improve from 0.92402\n","Epoch 11/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8235 - dice_coef: 0.9024 - accuracy: 0.9197 - val_loss: 0.9649 - val_dice_coef: 0.8520 - val_accuracy: 0.8891\n","\n","Epoch 00011: val_loss did not improve from 0.92402\n","Epoch 12/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7916 - dice_coef: 0.9054 - accuracy: 0.9213 - val_loss: 0.7783 - val_dice_coef: 0.8988 - val_accuracy: 0.9186\n","\n","Epoch 00012: val_loss improved from 0.92402 to 0.77833, saving model to Checkpoint.h5\n","Epoch 13/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7775 - dice_coef: 0.9068 - accuracy: 0.9215 - val_loss: 0.7216 - val_dice_coef: 0.9070 - val_accuracy: 0.9249\n","\n","Epoch 00013: val_loss improved from 0.77833 to 0.72155, saving model to Checkpoint.h5\n","Epoch 14/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7525 - dice_coef: 0.9086 - accuracy: 0.9226 - val_loss: 0.8147 - val_dice_coef: 0.8946 - val_accuracy: 0.9140\n","\n","Epoch 00014: val_loss did not improve from 0.72155\n","Epoch 15/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7344 - dice_coef: 0.9113 - accuracy: 0.9242 - val_loss: 0.6923 - val_dice_coef: 0.9112 - val_accuracy: 0.9274\n","\n","Epoch 00015: val_loss improved from 0.72155 to 0.69232, saving model to Checkpoint.h5\n","Epoch 16/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7208 - dice_coef: 0.9118 - accuracy: 0.9242 - val_loss: 0.8708 - val_dice_coef: 0.9025 - val_accuracy: 0.9136\n","\n","Epoch 00016: val_loss did not improve from 0.69232\n","Epoch 17/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6984 - dice_coef: 0.9141 - accuracy: 0.9258 - val_loss: 0.7051 - val_dice_coef: 0.9032 - val_accuracy: 0.9192\n","\n","Epoch 00017: val_loss did not improve from 0.69232\n","Epoch 18/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6843 - dice_coef: 0.9147 - accuracy: 0.9262 - val_loss: 0.7018 - val_dice_coef: 0.9083 - val_accuracy: 0.9225\n","\n","Epoch 00018: val_loss did not improve from 0.69232\n","Epoch 19/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6836 - dice_coef: 0.9140 - accuracy: 0.9251 - val_loss: 0.6856 - val_dice_coef: 0.9146 - val_accuracy: 0.9264\n","\n","Epoch 00019: val_loss improved from 0.69232 to 0.68557, saving model to Checkpoint.h5\n","Epoch 20/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6721 - dice_coef: 0.9155 - accuracy: 0.9264 - val_loss: 0.9829 - val_dice_coef: 0.8862 - val_accuracy: 0.8934\n","\n","Epoch 00020: val_loss did not improve from 0.68557\n","Epoch 21/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6575 - dice_coef: 0.9181 - accuracy: 0.9284 - val_loss: 0.7538 - val_dice_coef: 0.9091 - val_accuracy: 0.9174\n","\n","Epoch 00021: val_loss did not improve from 0.68557\n","Epoch 22/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6357 - dice_coef: 0.9196 - accuracy: 0.9296 - val_loss: 0.9162 - val_dice_coef: 0.8881 - val_accuracy: 0.9024\n","\n","Epoch 00022: val_loss did not improve from 0.68557\n","Epoch 23/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6423 - dice_coef: 0.9184 - accuracy: 0.9282 - val_loss: 0.7101 - val_dice_coef: 0.8952 - val_accuracy: 0.9138\n","\n","Epoch 00023: val_loss did not improve from 0.68557\n","Epoch 24/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6242 - dice_coef: 0.9208 - accuracy: 0.9304 - val_loss: 0.6809 - val_dice_coef: 0.9152 - val_accuracy: 0.9234\n","\n","Epoch 00024: val_loss improved from 0.68557 to 0.68088, saving model to Checkpoint.h5\n","Epoch 25/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6159 - dice_coef: 0.9219 - accuracy: 0.9312 - val_loss: 0.6130 - val_dice_coef: 0.9188 - val_accuracy: 0.9318\n","\n","Epoch 00025: val_loss improved from 0.68088 to 0.61297, saving model to Checkpoint.h5\n","Epoch 26/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6081 - dice_coef: 0.9224 - accuracy: 0.9315 - val_loss: 0.6100 - val_dice_coef: 0.9176 - val_accuracy: 0.9273\n","\n","Epoch 00026: val_loss improved from 0.61297 to 0.60995, saving model to Checkpoint.h5\n","Epoch 27/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5986 - dice_coef: 0.9234 - accuracy: 0.9324 - val_loss: 0.6377 - val_dice_coef: 0.9132 - val_accuracy: 0.9217\n","\n","Epoch 00027: val_loss did not improve from 0.60995\n","Epoch 28/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5971 - dice_coef: 0.9242 - accuracy: 0.9329 - val_loss: 0.5498 - val_dice_coef: 0.9268 - val_accuracy: 0.9369\n","\n","Epoch 00028: val_loss improved from 0.60995 to 0.54982, saving model to Checkpoint.h5\n","Epoch 29/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6013 - dice_coef: 0.9233 - accuracy: 0.9320 - val_loss: 0.6391 - val_dice_coef: 0.9110 - val_accuracy: 0.9217\n","\n","Epoch 00029: val_loss did not improve from 0.54982\n","Epoch 30/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5928 - dice_coef: 0.9246 - accuracy: 0.9330 - val_loss: 0.5561 - val_dice_coef: 0.9233 - val_accuracy: 0.9335\n","\n","Epoch 00030: val_loss did not improve from 0.54982\n","Epoch 31/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5828 - dice_coef: 0.9255 - accuracy: 0.9338 - val_loss: 0.8851 - val_dice_coef: 0.8888 - val_accuracy: 0.9015\n","\n","Epoch 00031: val_loss did not improve from 0.54982\n","Epoch 32/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5800 - dice_coef: 0.9263 - accuracy: 0.9344 - val_loss: 0.5818 - val_dice_coef: 0.9218 - val_accuracy: 0.9310\n","\n","Epoch 00032: val_loss did not improve from 0.54982\n","Epoch 33/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5666 - dice_coef: 0.9269 - accuracy: 0.9350 - val_loss: 0.6873 - val_dice_coef: 0.9141 - val_accuracy: 0.9216\n","\n","Epoch 00033: val_loss did not improve from 0.54982\n","Epoch 34/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5638 - dice_coef: 0.9283 - accuracy: 0.9361 - val_loss: 1.0333 - val_dice_coef: 0.8832 - val_accuracy: 0.8866\n","\n","Epoch 00034: val_loss did not improve from 0.54982\n","Epoch 35/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5565 - dice_coef: 0.9286 - accuracy: 0.9365 - val_loss: 0.9352 - val_dice_coef: 0.8194 - val_accuracy: 0.8435\n","\n","Epoch 00035: val_loss did not improve from 0.54982\n","Epoch 36/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5564 - dice_coef: 0.9294 - accuracy: 0.9369 - val_loss: 0.5663 - val_dice_coef: 0.9217 - val_accuracy: 0.9302\n","\n","Epoch 00036: val_loss did not improve from 0.54982\n","Epoch 37/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5507 - dice_coef: 0.9297 - accuracy: 0.9374 - val_loss: 0.5159 - val_dice_coef: 0.9324 - val_accuracy: 0.9414\n","\n","Epoch 00037: val_loss improved from 0.54982 to 0.51589, saving model to Checkpoint.h5\n","Epoch 38/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5544 - dice_coef: 0.9295 - accuracy: 0.9369 - val_loss: 0.6295 - val_dice_coef: 0.9161 - val_accuracy: 0.9251\n","\n","Epoch 00038: val_loss did not improve from 0.51589\n","Epoch 39/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5559 - dice_coef: 0.9295 - accuracy: 0.9369 - val_loss: 0.5679 - val_dice_coef: 0.9205 - val_accuracy: 0.9322\n","\n","Epoch 00039: val_loss did not improve from 0.51589\n","Epoch 40/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5399 - dice_coef: 0.9319 - accuracy: 0.9391 - val_loss: 0.5951 - val_dice_coef: 0.9095 - val_accuracy: 0.9198\n","\n","Epoch 00040: val_loss did not improve from 0.51589\n","Epoch 41/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5425 - dice_coef: 0.9312 - accuracy: 0.9384 - val_loss: 0.8386 - val_dice_coef: 0.8999 - val_accuracy: 0.9049\n","\n","Epoch 00041: val_loss did not improve from 0.51589\n","Epoch 42/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5393 - dice_coef: 0.9324 - accuracy: 0.9395 - val_loss: 0.6025 - val_dice_coef: 0.9199 - val_accuracy: 0.9278\n","\n","Epoch 00042: val_loss did not improve from 0.51589\n","Epoch 43/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5320 - dice_coef: 0.9325 - accuracy: 0.9395 - val_loss: 0.6412 - val_dice_coef: 0.9077 - val_accuracy: 0.9190\n","\n","Epoch 00043: val_loss did not improve from 0.51589\n","Epoch 44/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5294 - dice_coef: 0.9336 - accuracy: 0.9404 - val_loss: 0.5962 - val_dice_coef: 0.9224 - val_accuracy: 0.9295\n","\n","Epoch 00044: val_loss did not improve from 0.51589\n","Epoch 45/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5393 - dice_coef: 0.9330 - accuracy: 0.9399 - val_loss: 0.6127 - val_dice_coef: 0.9132 - val_accuracy: 0.9256\n","\n","Epoch 00045: val_loss did not improve from 0.51589\n","Epoch 46/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5334 - dice_coef: 0.9328 - accuracy: 0.9397 - val_loss: 0.5506 - val_dice_coef: 0.9213 - val_accuracy: 0.9298\n","\n","Epoch 00046: val_loss did not improve from 0.51589\n","Epoch 47/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5205 - dice_coef: 0.9353 - accuracy: 0.9419 - val_loss: 0.6233 - val_dice_coef: 0.9086 - val_accuracy: 0.9187\n","\n","Epoch 00047: val_loss did not improve from 0.51589\n","Epoch 00047: early stopping\n","TRAIN: [0 1 2 3 4 5 6 8] TEST: [7]\n","-----------fold 7--------------\n","Epoch 1/100\n","246/246 [==============================] - 95s 386ms/step - loss: 1.9213 - dice_coef: 0.7422 - accuracy: 0.7855 - val_loss: 1.8344 - val_dice_coef: 0.8261 - val_accuracy: 0.8243\n","\n","Epoch 00001: val_loss improved from inf to 1.83444, saving model to Checkpoint.h5\n","Epoch 2/100\n","246/246 [==============================] - 82s 332ms/step - loss: 1.3981 - dice_coef: 0.8516 - accuracy: 0.8885 - val_loss: 1.2739 - val_dice_coef: 0.8687 - val_accuracy: 0.9001\n","\n","Epoch 00002: val_loss improved from 1.83444 to 1.27386, saving model to Checkpoint.h5\n","Epoch 3/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.1722 - dice_coef: 0.8700 - accuracy: 0.9022 - val_loss: 1.0990 - val_dice_coef: 0.8814 - val_accuracy: 0.9060\n","\n","Epoch 00003: val_loss improved from 1.27386 to 1.09903, saving model to Checkpoint.h5\n","Epoch 4/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.0407 - dice_coef: 0.8852 - accuracy: 0.9089 - val_loss: 1.5657 - val_dice_coef: 0.7351 - val_accuracy: 0.7552\n","\n","Epoch 00004: val_loss did not improve from 1.09903\n","Epoch 5/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9573 - dice_coef: 0.8917 - accuracy: 0.9118 - val_loss: 0.9782 - val_dice_coef: 0.8823 - val_accuracy: 0.9012\n","\n","Epoch 00005: val_loss improved from 1.09903 to 0.97821, saving model to Checkpoint.h5\n","Epoch 6/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9048 - dice_coef: 0.8966 - accuracy: 0.9134 - val_loss: 0.8302 - val_dice_coef: 0.9049 - val_accuracy: 0.9190\n","\n","Epoch 00006: val_loss improved from 0.97821 to 0.83022, saving model to Checkpoint.h5\n","Epoch 7/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8655 - dice_coef: 0.9012 - accuracy: 0.9160 - val_loss: 0.7933 - val_dice_coef: 0.9053 - val_accuracy: 0.9188\n","\n","Epoch 00007: val_loss improved from 0.83022 to 0.79330, saving model to Checkpoint.h5\n","Epoch 8/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8199 - dice_coef: 0.9048 - accuracy: 0.9184 - val_loss: 1.0024 - val_dice_coef: 0.8858 - val_accuracy: 0.8958\n","\n","Epoch 00008: val_loss did not improve from 0.79330\n","Epoch 9/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7997 - dice_coef: 0.9061 - accuracy: 0.9184 - val_loss: 0.7629 - val_dice_coef: 0.9062 - val_accuracy: 0.9215\n","\n","Epoch 00009: val_loss improved from 0.79330 to 0.76291, saving model to Checkpoint.h5\n","Epoch 10/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7817 - dice_coef: 0.9071 - accuracy: 0.9188 - val_loss: 0.7718 - val_dice_coef: 0.9081 - val_accuracy: 0.9189\n","\n","Epoch 00010: val_loss did not improve from 0.76291\n","Epoch 11/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7617 - dice_coef: 0.9081 - accuracy: 0.9193 - val_loss: 0.7072 - val_dice_coef: 0.9143 - val_accuracy: 0.9243\n","\n","Epoch 00011: val_loss improved from 0.76291 to 0.70724, saving model to Checkpoint.h5\n","Epoch 12/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7376 - dice_coef: 0.9119 - accuracy: 0.9221 - val_loss: 0.7335 - val_dice_coef: 0.9013 - val_accuracy: 0.9107\n","\n","Epoch 00012: val_loss did not improve from 0.70724\n","Epoch 13/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7192 - dice_coef: 0.9118 - accuracy: 0.9218 - val_loss: 0.8475 - val_dice_coef: 0.8676 - val_accuracy: 0.8765\n","\n","Epoch 00013: val_loss did not improve from 0.70724\n","Epoch 14/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7081 - dice_coef: 0.9127 - accuracy: 0.9224 - val_loss: 0.7798 - val_dice_coef: 0.9056 - val_accuracy: 0.9143\n","\n","Epoch 00014: val_loss did not improve from 0.70724\n","Epoch 15/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6878 - dice_coef: 0.9148 - accuracy: 0.9240 - val_loss: 0.6974 - val_dice_coef: 0.9156 - val_accuracy: 0.9230\n","\n","Epoch 00015: val_loss improved from 0.70724 to 0.69745, saving model to Checkpoint.h5\n","Epoch 16/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6824 - dice_coef: 0.9158 - accuracy: 0.9249 - val_loss: 0.6686 - val_dice_coef: 0.9167 - val_accuracy: 0.9252\n","\n","Epoch 00016: val_loss improved from 0.69745 to 0.66860, saving model to Checkpoint.h5\n","Epoch 17/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6621 - dice_coef: 0.9171 - accuracy: 0.9260 - val_loss: 0.6404 - val_dice_coef: 0.9137 - val_accuracy: 0.9238\n","\n","Epoch 00017: val_loss improved from 0.66860 to 0.64042, saving model to Checkpoint.h5\n","Epoch 18/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6592 - dice_coef: 0.9171 - accuracy: 0.9257 - val_loss: 0.6355 - val_dice_coef: 0.9130 - val_accuracy: 0.9214\n","\n","Epoch 00018: val_loss improved from 0.64042 to 0.63549, saving model to Checkpoint.h5\n","Epoch 19/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6408 - dice_coef: 0.9193 - accuracy: 0.9277 - val_loss: 0.6027 - val_dice_coef: 0.9196 - val_accuracy: 0.9276\n","\n","Epoch 00019: val_loss improved from 0.63549 to 0.60274, saving model to Checkpoint.h5\n","Epoch 20/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6440 - dice_coef: 0.9187 - accuracy: 0.9270 - val_loss: 0.5682 - val_dice_coef: 0.9271 - val_accuracy: 0.9359\n","\n","Epoch 00020: val_loss improved from 0.60274 to 0.56821, saving model to Checkpoint.h5\n","Epoch 21/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6223 - dice_coef: 0.9221 - accuracy: 0.9299 - val_loss: 0.5699 - val_dice_coef: 0.9270 - val_accuracy: 0.9357\n","\n","Epoch 00021: val_loss did not improve from 0.56821\n","Epoch 22/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6240 - dice_coef: 0.9212 - accuracy: 0.9290 - val_loss: 0.6217 - val_dice_coef: 0.9173 - val_accuracy: 0.9241\n","\n","Epoch 00022: val_loss did not improve from 0.56821\n","Epoch 23/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6133 - dice_coef: 0.9222 - accuracy: 0.9298 - val_loss: 0.6612 - val_dice_coef: 0.9029 - val_accuracy: 0.9118\n","\n","Epoch 00023: val_loss did not improve from 0.56821\n","Epoch 24/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6039 - dice_coef: 0.9228 - accuracy: 0.9305 - val_loss: 0.5539 - val_dice_coef: 0.9281 - val_accuracy: 0.9353\n","\n","Epoch 00024: val_loss improved from 0.56821 to 0.55390, saving model to Checkpoint.h5\n","Epoch 25/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5942 - dice_coef: 0.9237 - accuracy: 0.9312 - val_loss: 0.5537 - val_dice_coef: 0.9264 - val_accuracy: 0.9339\n","\n","Epoch 00025: val_loss improved from 0.55390 to 0.55367, saving model to Checkpoint.h5\n","Epoch 26/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5865 - dice_coef: 0.9253 - accuracy: 0.9326 - val_loss: 0.9124 - val_dice_coef: 0.8921 - val_accuracy: 0.8969\n","\n","Epoch 00026: val_loss did not improve from 0.55367\n","Epoch 27/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5874 - dice_coef: 0.9252 - accuracy: 0.9323 - val_loss: 0.5407 - val_dice_coef: 0.9297 - val_accuracy: 0.9371\n","\n","Epoch 00027: val_loss improved from 0.55367 to 0.54070, saving model to Checkpoint.h5\n","Epoch 28/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5785 - dice_coef: 0.9262 - accuracy: 0.9334 - val_loss: 0.6994 - val_dice_coef: 0.9119 - val_accuracy: 0.9169\n","\n","Epoch 00028: val_loss did not improve from 0.54070\n","Epoch 29/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5763 - dice_coef: 0.9265 - accuracy: 0.9336 - val_loss: 0.5092 - val_dice_coef: 0.9321 - val_accuracy: 0.9402\n","\n","Epoch 00029: val_loss improved from 0.54070 to 0.50921, saving model to Checkpoint.h5\n","Epoch 30/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5755 - dice_coef: 0.9263 - accuracy: 0.9333 - val_loss: 0.5468 - val_dice_coef: 0.9273 - val_accuracy: 0.9361\n","\n","Epoch 00030: val_loss did not improve from 0.50921\n","Epoch 31/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5726 - dice_coef: 0.9274 - accuracy: 0.9343 - val_loss: 0.5582 - val_dice_coef: 0.9237 - val_accuracy: 0.9299\n","\n","Epoch 00031: val_loss did not improve from 0.50921\n","Epoch 32/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5628 - dice_coef: 0.9287 - accuracy: 0.9353 - val_loss: 0.5645 - val_dice_coef: 0.9236 - val_accuracy: 0.9292\n","\n","Epoch 00032: val_loss did not improve from 0.50921\n","Epoch 33/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5661 - dice_coef: 0.9277 - accuracy: 0.9345 - val_loss: 0.5310 - val_dice_coef: 0.9331 - val_accuracy: 0.9387\n","\n","Epoch 00033: val_loss did not improve from 0.50921\n","Epoch 34/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5597 - dice_coef: 0.9289 - accuracy: 0.9356 - val_loss: 0.6070 - val_dice_coef: 0.9210 - val_accuracy: 0.9270\n","\n","Epoch 00034: val_loss did not improve from 0.50921\n","Epoch 35/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5524 - dice_coef: 0.9299 - accuracy: 0.9365 - val_loss: 0.5996 - val_dice_coef: 0.9237 - val_accuracy: 0.9302\n","\n","Epoch 00035: val_loss did not improve from 0.50921\n","Epoch 36/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5455 - dice_coef: 0.9311 - accuracy: 0.9376 - val_loss: 0.5574 - val_dice_coef: 0.9295 - val_accuracy: 0.9355\n","\n","Epoch 00036: val_loss did not improve from 0.50921\n","Epoch 37/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5479 - dice_coef: 0.9308 - accuracy: 0.9372 - val_loss: 0.7257 - val_dice_coef: 0.8856 - val_accuracy: 0.8939\n","\n","Epoch 00037: val_loss did not improve from 0.50921\n","Epoch 38/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5474 - dice_coef: 0.9321 - accuracy: 0.9383 - val_loss: 0.7181 - val_dice_coef: 0.9111 - val_accuracy: 0.9154\n","\n","Epoch 00038: val_loss did not improve from 0.50921\n","Epoch 39/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5291 - dice_coef: 0.9333 - accuracy: 0.9396 - val_loss: 0.5383 - val_dice_coef: 0.9325 - val_accuracy: 0.9387\n","\n","Epoch 00039: val_loss did not improve from 0.50921\n","Epoch 00039: early stopping\n","TRAIN: [0 1 2 3 4 5 6 7] TEST: [8]\n","-----------fold 8--------------\n","Epoch 1/100\n","246/246 [==============================] - 96s 388ms/step - loss: 2.3198 - dice_coef: 0.5495 - accuracy: 0.8432 - val_loss: 2.5560 - val_dice_coef: 0.6256 - val_accuracy: 0.8499\n","\n","Epoch 00001: val_loss improved from inf to 2.55600, saving model to Checkpoint.h5\n","Epoch 2/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.8238 - dice_coef: 0.7063 - accuracy: 0.8637 - val_loss: 1.8110 - val_dice_coef: 0.7553 - val_accuracy: 0.8912\n","\n","Epoch 00002: val_loss improved from 2.55600 to 1.81104, saving model to Checkpoint.h5\n","Epoch 3/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.6119 - dice_coef: 0.7666 - accuracy: 0.8668 - val_loss: 1.5903 - val_dice_coef: 0.8086 - val_accuracy: 0.9012\n","\n","Epoch 00003: val_loss improved from 1.81104 to 1.59025, saving model to Checkpoint.h5\n","Epoch 4/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.4816 - dice_coef: 0.7970 - accuracy: 0.8679 - val_loss: 1.4556 - val_dice_coef: 0.8304 - val_accuracy: 0.8980\n","\n","Epoch 00004: val_loss improved from 1.59025 to 1.45557, saving model to Checkpoint.h5\n","Epoch 5/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.4078 - dice_coef: 0.8137 - accuracy: 0.8688 - val_loss: 1.7085 - val_dice_coef: 0.8285 - val_accuracy: 0.8822\n","\n","Epoch 00005: val_loss did not improve from 1.45557\n","Epoch 6/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.3438 - dice_coef: 0.8293 - accuracy: 0.8749 - val_loss: 1.3543 - val_dice_coef: 0.8567 - val_accuracy: 0.9021\n","\n","Epoch 00006: val_loss improved from 1.45557 to 1.35428, saving model to Checkpoint.h5\n","Epoch 7/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.3043 - dice_coef: 0.8352 - accuracy: 0.8737 - val_loss: 1.4239 - val_dice_coef: 0.8581 - val_accuracy: 0.8973\n","\n","Epoch 00007: val_loss did not improve from 1.35428\n","Epoch 8/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.2544 - dice_coef: 0.8428 - accuracy: 0.8767 - val_loss: 1.2125 - val_dice_coef: 0.8650 - val_accuracy: 0.8992\n","\n","Epoch 00008: val_loss improved from 1.35428 to 1.21254, saving model to Checkpoint.h5\n","Epoch 9/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.2284 - dice_coef: 0.8490 - accuracy: 0.8796 - val_loss: 1.2546 - val_dice_coef: 0.8718 - val_accuracy: 0.9029\n","\n","Epoch 00009: val_loss did not improve from 1.21254\n","Epoch 10/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.2010 - dice_coef: 0.8503 - accuracy: 0.8779 - val_loss: 1.2053 - val_dice_coef: 0.8754 - val_accuracy: 0.9039\n","\n","Epoch 00010: val_loss improved from 1.21254 to 1.20533, saving model to Checkpoint.h5\n","Epoch 11/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.1619 - dice_coef: 0.8546 - accuracy: 0.8799 - val_loss: 1.1707 - val_dice_coef: 0.8757 - val_accuracy: 0.9023\n","\n","Epoch 00011: val_loss improved from 1.20533 to 1.17068, saving model to Checkpoint.h5\n","Epoch 12/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.1461 - dice_coef: 0.8564 - accuracy: 0.8792 - val_loss: 1.2055 - val_dice_coef: 0.8770 - val_accuracy: 0.9020\n","\n","Epoch 00012: val_loss did not improve from 1.17068\n","Epoch 13/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.1132 - dice_coef: 0.8622 - accuracy: 0.8821 - val_loss: 1.0668 - val_dice_coef: 0.8878 - val_accuracy: 0.9068\n","\n","Epoch 00013: val_loss improved from 1.17068 to 1.06681, saving model to Checkpoint.h5\n","Epoch 14/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.0852 - dice_coef: 0.8673 - accuracy: 0.8950 - val_loss: 1.3244 - val_dice_coef: 0.8749 - val_accuracy: 0.9107\n","\n","Epoch 00014: val_loss did not improve from 1.06681\n","Epoch 15/100\n","246/246 [==============================] - 82s 333ms/step - loss: 1.0423 - dice_coef: 0.8744 - accuracy: 0.9193 - val_loss: 1.0581 - val_dice_coef: 0.8909 - val_accuracy: 0.9312\n","\n","Epoch 00015: val_loss improved from 1.06681 to 1.05814, saving model to Checkpoint.h5\n","Epoch 16/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9827 - dice_coef: 0.8821 - accuracy: 0.9233 - val_loss: 1.3277 - val_dice_coef: 0.8670 - val_accuracy: 0.8938\n","\n","Epoch 00016: val_loss did not improve from 1.05814\n","Epoch 17/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9565 - dice_coef: 0.8850 - accuracy: 0.9229 - val_loss: 0.9844 - val_dice_coef: 0.8986 - val_accuracy: 0.9301\n","\n","Epoch 00017: val_loss improved from 1.05814 to 0.98440, saving model to Checkpoint.h5\n","Epoch 18/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9245 - dice_coef: 0.8875 - accuracy: 0.9234 - val_loss: 0.9004 - val_dice_coef: 0.9063 - val_accuracy: 0.9376\n","\n","Epoch 00018: val_loss improved from 0.98440 to 0.90036, saving model to Checkpoint.h5\n","Epoch 19/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.9011 - dice_coef: 0.8916 - accuracy: 0.9252 - val_loss: 0.9833 - val_dice_coef: 0.9001 - val_accuracy: 0.9279\n","\n","Epoch 00019: val_loss did not improve from 0.90036\n","Epoch 20/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8798 - dice_coef: 0.8924 - accuracy: 0.9242 - val_loss: 0.9243 - val_dice_coef: 0.9027 - val_accuracy: 0.9315\n","\n","Epoch 00020: val_loss did not improve from 0.90036\n","Epoch 21/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8664 - dice_coef: 0.8944 - accuracy: 0.9244 - val_loss: 0.8547 - val_dice_coef: 0.9033 - val_accuracy: 0.9306\n","\n","Epoch 00021: val_loss improved from 0.90036 to 0.85466, saving model to Checkpoint.h5\n","Epoch 22/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8344 - dice_coef: 0.8988 - accuracy: 0.9275 - val_loss: 0.9073 - val_dice_coef: 0.8871 - val_accuracy: 0.9136\n","\n","Epoch 00022: val_loss did not improve from 0.85466\n","Epoch 23/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.8327 - dice_coef: 0.9002 - accuracy: 0.9276 - val_loss: 1.0103 - val_dice_coef: 0.8968 - val_accuracy: 0.9218\n","\n","Epoch 00023: val_loss did not improve from 0.85466\n","Epoch 24/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7655 - dice_coef: 0.9083 - accuracy: 0.9285 - val_loss: 0.9124 - val_dice_coef: 0.8675 - val_accuracy: 0.8871\n","\n","Epoch 00024: val_loss did not improve from 0.85466\n","Epoch 25/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.7363 - dice_coef: 0.9119 - accuracy: 0.9279 - val_loss: 0.8846 - val_dice_coef: 0.9111 - val_accuracy: 0.9262\n","\n","Epoch 00025: val_loss did not improve from 0.85466\n","Epoch 26/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.7165 - dice_coef: 0.9160 - accuracy: 0.9304 - val_loss: 0.7320 - val_dice_coef: 0.9242 - val_accuracy: 0.9391\n","\n","Epoch 00026: val_loss improved from 0.85466 to 0.73197, saving model to Checkpoint.h5\n","Epoch 27/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.7084 - dice_coef: 0.9171 - accuracy: 0.9302 - val_loss: 0.7340 - val_dice_coef: 0.9261 - val_accuracy: 0.9392\n","\n","Epoch 00027: val_loss did not improve from 0.73197\n","Epoch 28/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.6905 - dice_coef: 0.9196 - accuracy: 0.9320 - val_loss: 0.6726 - val_dice_coef: 0.9242 - val_accuracy: 0.9354\n","\n","Epoch 00028: val_loss improved from 0.73197 to 0.67260, saving model to Checkpoint.h5\n","Epoch 29/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6774 - dice_coef: 0.9209 - accuracy: 0.9326 - val_loss: 0.6448 - val_dice_coef: 0.9327 - val_accuracy: 0.9437\n","\n","Epoch 00029: val_loss improved from 0.67260 to 0.64477, saving model to Checkpoint.h5\n","Epoch 30/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6574 - dice_coef: 0.9230 - accuracy: 0.9352 - val_loss: 0.6180 - val_dice_coef: 0.9323 - val_accuracy: 0.9427\n","\n","Epoch 00030: val_loss improved from 0.64477 to 0.61802, saving model to Checkpoint.h5\n","Epoch 31/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.6465 - dice_coef: 0.9213 - accuracy: 0.9336 - val_loss: 0.6568 - val_dice_coef: 0.9219 - val_accuracy: 0.9339\n","\n","Epoch 00031: val_loss did not improve from 0.61802\n","Epoch 32/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5968 - dice_coef: 0.9253 - accuracy: 0.9367 - val_loss: 0.6570 - val_dice_coef: 0.9254 - val_accuracy: 0.9342\n","\n","Epoch 00032: val_loss did not improve from 0.61802\n","Epoch 33/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5905 - dice_coef: 0.9254 - accuracy: 0.9360 - val_loss: 0.5941 - val_dice_coef: 0.9371 - val_accuracy: 0.9466\n","\n","Epoch 00033: val_loss improved from 0.61802 to 0.59409, saving model to Checkpoint.h5\n","Epoch 34/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5708 - dice_coef: 0.9278 - accuracy: 0.9377 - val_loss: 0.7166 - val_dice_coef: 0.9252 - val_accuracy: 0.9357\n","\n","Epoch 00034: val_loss did not improve from 0.59409\n","Epoch 35/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5809 - dice_coef: 0.9265 - accuracy: 0.9361 - val_loss: 1.1590 - val_dice_coef: 0.8941 - val_accuracy: 0.9008\n","\n","Epoch 00035: val_loss did not improve from 0.59409\n","Epoch 36/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5682 - dice_coef: 0.9288 - accuracy: 0.9380 - val_loss: 0.7029 - val_dice_coef: 0.9294 - val_accuracy: 0.9375\n","\n","Epoch 00036: val_loss did not improve from 0.59409\n","Epoch 37/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5732 - dice_coef: 0.9284 - accuracy: 0.9374 - val_loss: 0.6204 - val_dice_coef: 0.9350 - val_accuracy: 0.9455\n","\n","Epoch 00037: val_loss did not improve from 0.59409\n","Epoch 38/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5616 - dice_coef: 0.9301 - accuracy: 0.9388 - val_loss: 0.9252 - val_dice_coef: 0.9075 - val_accuracy: 0.9160\n","\n","Epoch 00038: val_loss did not improve from 0.59409\n","Epoch 39/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5713 - dice_coef: 0.9290 - accuracy: 0.9376 - val_loss: 0.5474 - val_dice_coef: 0.9437 - val_accuracy: 0.9517\n","\n","Epoch 00039: val_loss improved from 0.59409 to 0.54742, saving model to Checkpoint.h5\n","Epoch 40/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5490 - dice_coef: 0.9318 - accuracy: 0.9402 - val_loss: 0.6556 - val_dice_coef: 0.9168 - val_accuracy: 0.9259\n","\n","Epoch 00040: val_loss did not improve from 0.54742\n","Epoch 41/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5464 - dice_coef: 0.9310 - accuracy: 0.9392 - val_loss: 0.5832 - val_dice_coef: 0.9392 - val_accuracy: 0.9465\n","\n","Epoch 00041: val_loss did not improve from 0.54742\n","Epoch 42/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5331 - dice_coef: 0.9342 - accuracy: 0.9421 - val_loss: 2.2782 - val_dice_coef: 0.5890 - val_accuracy: 0.5967\n","\n","Epoch 00042: val_loss did not improve from 0.54742\n","Epoch 43/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5542 - dice_coef: 0.9321 - accuracy: 0.9401 - val_loss: 0.8838 - val_dice_coef: 0.9149 - val_accuracy: 0.9217\n","\n","Epoch 00043: val_loss did not improve from 0.54742\n","Epoch 44/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5484 - dice_coef: 0.9329 - accuracy: 0.9407 - val_loss: 0.6259 - val_dice_coef: 0.9344 - val_accuracy: 0.9427\n","\n","Epoch 00044: val_loss did not improve from 0.54742\n","Epoch 45/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5316 - dice_coef: 0.9349 - accuracy: 0.9425 - val_loss: 0.4818 - val_dice_coef: 0.9507 - val_accuracy: 0.9575\n","\n","Epoch 00045: val_loss improved from 0.54742 to 0.48180, saving model to Checkpoint.h5\n","Epoch 46/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5387 - dice_coef: 0.9339 - accuracy: 0.9414 - val_loss: 0.5536 - val_dice_coef: 0.9411 - val_accuracy: 0.9482\n","\n","Epoch 00046: val_loss did not improve from 0.48180\n","Epoch 47/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5299 - dice_coef: 0.9342 - accuracy: 0.9417 - val_loss: 0.5654 - val_dice_coef: 0.9392 - val_accuracy: 0.9469\n","\n","Epoch 00047: val_loss did not improve from 0.48180\n","Epoch 48/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5332 - dice_coef: 0.9361 - accuracy: 0.9434 - val_loss: 0.7127 - val_dice_coef: 0.9307 - val_accuracy: 0.9366\n","\n","Epoch 00048: val_loss did not improve from 0.48180\n","Epoch 49/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5305 - dice_coef: 0.9353 - accuracy: 0.9426 - val_loss: 0.5031 - val_dice_coef: 0.9482 - val_accuracy: 0.9546\n","\n","Epoch 00049: val_loss did not improve from 0.48180\n","Epoch 50/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5308 - dice_coef: 0.9353 - accuracy: 0.9424 - val_loss: 0.4856 - val_dice_coef: 0.9500 - val_accuracy: 0.9564\n","\n","Epoch 00050: val_loss did not improve from 0.48180\n","Epoch 51/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5198 - dice_coef: 0.9377 - accuracy: 0.9448 - val_loss: 0.5048 - val_dice_coef: 0.9495 - val_accuracy: 0.9558\n","\n","Epoch 00051: val_loss did not improve from 0.48180\n","Epoch 52/100\n","246/246 [==============================] - 82s 332ms/step - loss: 0.5304 - dice_coef: 0.9367 - accuracy: 0.9437 - val_loss: 0.8368 - val_dice_coef: 0.9195 - val_accuracy: 0.9253\n","\n","Epoch 00052: val_loss did not improve from 0.48180\n","Epoch 53/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5351 - dice_coef: 0.9355 - accuracy: 0.9424 - val_loss: 0.5610 - val_dice_coef: 0.9385 - val_accuracy: 0.9444\n","\n","Epoch 00053: val_loss did not improve from 0.48180\n","Epoch 54/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5057 - dice_coef: 0.9395 - accuracy: 0.9462 - val_loss: 0.5007 - val_dice_coef: 0.9484 - val_accuracy: 0.9548\n","\n","Epoch 00054: val_loss did not improve from 0.48180\n","Epoch 55/100\n","246/246 [==============================] - 82s 333ms/step - loss: 0.5020 - dice_coef: 0.9397 - accuracy: 0.9464 - val_loss: 0.5739 - val_dice_coef: 0.9423 - val_accuracy: 0.9484\n","\n","Epoch 00055: val_loss did not improve from 0.48180\n","Epoch 00055: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XzwipgD8UuIy","colab_type":"code","colab":{}},"source":["def stitchMaskPatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img\n","\n","\n","def stitchImagePatches(pieces):\n","  k = 0\n","  reconstructed_img = np.ones([1440,1920,3])\n","  for r in range(6):\n","    row = r * 240\n","    for c in range(8):\n","      col = c * 240\n","      reconstructed_img[row:row+240,col:col+240,:] = pieces[k]\n","      k = k + 1\n","  return reconstructed_img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7rOZOq1M7lm","colab_type":"code","colab":{}},"source":["def saveNumpyOutput(mask, Patient_array,Patient_length,title,folder):\n","  idx = 0\n","  for i in range(len(Patient_length)):\n","    temp = []\n","    for j in range(Patient_length[i]):\n","      final_output = mask[idx:idx+48]\n","      idx = idx + 48\n","      final_output = stitchMaskPatches(final_output)\n","      temp.append(final_output)\n","    final_output = np.asarray(temp)\n","    np.save(folder + title + Patient_array[i], final_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_seHRjOYNLO","colab_type":"code","outputId":"b7447198-0c92-4fd9-d422-6fef0c75ac75","executionInfo":{"status":"ok","timestamp":1591535420448,"user_tz":-330,"elapsed":5251,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["MODELS_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Models/4 Class/Ki67/KFold/\"\n","model_names = os.listdir(MODELS_PATH)\n","print(model_names)\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["['LadderNet_Ki67_0.h5', 'LadderNet_Ki67_1.h5', 'LadderNet_Ki67_2.h5', 'LadderNet_Ki67_3.h5', 'LadderNet_Ki67_4.h5', 'LadderNet_Ki67_5.h5', 'LadderNet_Ki67_6.h5', 'LadderNet_Ki67_7.h5', 'LadderNet_Ki67_8.h5']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x-ad_aPT0HPU","colab_type":"code","colab":{}},"source":["SAVE_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/Ki67/KFold LadderNet/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrOgLuXs0fzn","colab_type":"code","outputId":"ba775c16-975c-462e-da08-45b424f8816d","executionInfo":{"status":"ok","timestamp":1591535420452,"user_tz":-330,"elapsed":5242,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# Axis 0 = Folds\n","# Axis 1 = Class (Backround, Immunopositive,Immunongative)\n","# Axis 2 = Evaluation Technique (Precision, Recall, Dice coefficient)\n","pixEvaluationTrain = np.empty((0,3,3))\n","pixEvaluationTest = np.empty((0,3,3))\n","score = np.zeros((1,3,3))\n","print(pixEvaluationTrain.shape)\n","print(pixEvaluationTest.shape)\n","print(score.shape)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["(0, 3, 3)\n","(0, 3, 3)\n","(1, 3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qIijdgE31k8S","colab_type":"code","outputId":"442c4f35-90e1-4101-f365-a619f526ebea","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591538978092,"user_tz":-330,"elapsed":3562873,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}}},"source":["oneOut = LeaveOneOut()\n","fold = 0\n","\n","for train_index, test_index in oneOut.split(X):\n","  print(\"FOLD:\",fold,\"\\tTRAIN:\", train_index, \"TEST:\", test_index)\n","  # Splitting Train and Test data\n","  TrainX =  np.concatenate(np.array([X[i] for i in train_index]))\n","  TrainY =  np.concatenate(np.array([Y[i] for i in train_index]))\n","  TestX  =  np.concatenate(np.array([X[i] for i in test_index]))\n","  TestY  =  np.concatenate(np.array([Y[i] for i in test_index]))\n","\n","  train_no = [patient_no[i] for i in train_index]\n","  train_size = [size[i] for i in train_index]\n","  print(train_no)\n","\n","  test_no = [patient_no[i] for i in test_index]\n","  test_size = [size[i] for i in test_index]\n","  print(test_no)\n","\n","  TrainX = TrainX.astype('float32')/255\n","  TestX = TestX.astype('float32')/255\n","\n","  convertToLabels(TrainY)\n","  convertToLabels(TestY)\n","\n","  TrainY = keras.utils.to_categorical(TrainY,num_classes=3, dtype='int16')\n","  TestY  = keras.utils.to_categorical(TestY, num_classes=3, dtype='int16')\n","  \n","  # Loading corrosponding fold of model\n","  model = keras.models.load_model(MODELS_PATH + model_names[fold],custom_objects={ 'combined_loss': combined_loss, 'dice_coef': dice_coef })\n","\n","  # Predicting results using model\n","  trainResult = model.predict(TrainX, batch_size=8)\n","  testResult = model.predict(TestX,batch_size=8)\n","\n","  trainResult = np.argmax(trainResult,axis=-1)\n","  testResult = np.argmax(testResult,axis=-1)\n","\n","  trainOneHot = keras.utils.to_categorical(trainResult,num_classes=3, dtype='int16')\n","  testOneHot = keras.utils.to_categorical(testResult,  num_classes=3, dtype='int16')\n","\n","  # Obtaining pixel-wise results: Precision recall and dice coefficient\n","  # For TRAIN\n","  y_true = np.reshape(TrainY,(-1, TrainY.shape[3]))\n","  y_pred = np.reshape(trainOneHot,(-1, trainOneHot.shape[3]))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  \n","  #Precision Recall Dice for each class  #0 : Background, 1 : Immunonegative, 2:Immunopositive \n","  for i in range(3):\n","    score[0][i][0] = prec[i]\n","    score[0][i][1] = recall[i]\n","    score[0][i][2] = dice[i]\n","\n","  pixEvaluationTrain = np.append(pixEvaluationTrain,score,axis=0)\n","  print(pixEvaluationTrain)\n"," \n","  # For TEST\n","  y_true = np.reshape(TestY,(-1, TestY.shape[3]))\n","  y_pred = np.reshape(testOneHot,(-1, testOneHot.shape[3]))\n","\n","  prec   = metrics.precision_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  recall = metrics.recall_score(y_true,y_pred,labels=[0,1,2],average=None,zero_division=1)\n","  dice = 2*prec*recall/(prec+recall)\n","\n","  # Precision Recall Dice for each class\n","  for i in range(3):\n","    score[0][i][0] = prec[i]\n","    score[0][i][1] = recall[i]\n","    score[0][i][2] = dice[i]\n","\n","  pixEvaluationTest = np.append(pixEvaluationTest,score,axis=0)\n","  print(pixEvaluationTest)\n","\n","  # Converting predicted labels to required output format\n","  convertFromLabels(trainResult)\n","  convertFromLabels(testResult)\n","\n","  # Saving numpy arrays\n","  path = os.path.join(SAVE_PATH,\"Fold \" + str(fold))\n","  os.mkdir(path)\n","  os.mkdir(path + '/Train')\n","  os.mkdir(path + '/Test')\n","\n","  saveNumpyOutput(trainResult, train_no, train_size,\"/Train/\",path)\n","  saveNumpyOutput(testResult, test_no, test_size,\"/Test/\",path)\n","\n","  fold +=1"],"execution_count":20,"outputs":[{"output_type":"stream","text":["FOLD: 0 \tTRAIN: [1 2 3 4 5 6 7 8] TEST: [0]\n","['242', '263', '232', '221', '229', '246', '252', '239']\n","['230']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]]\n","FOLD: 1 \tTRAIN: [0 2 3 4 5 6 7 8] TEST: [1]\n","['230', '263', '232', '221', '229', '246', '252', '239']\n","['242']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]]\n","FOLD: 2 \tTRAIN: [0 1 3 4 5 6 7 8] TEST: [2]\n","['230', '242', '232', '221', '229', '246', '252', '239']\n","['263']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]\n","\n"," [[0.94400455 0.96472859 0.95425407]\n","  [0.8866178  0.75681591 0.81659084]\n","  [0.86517646 0.90780576 0.88597863]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]\n","\n"," [[0.95566557 0.96310863 0.95937267]\n","  [0.81829307 0.78599135 0.80181701]\n","  [0.86299069 0.85645591 0.85971088]]]\n","FOLD: 3 \tTRAIN: [0 1 2 4 5 6 7 8] TEST: [3]\n","['230', '242', '263', '221', '229', '246', '252', '239']\n","['232']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]\n","\n"," [[0.94400455 0.96472859 0.95425407]\n","  [0.8866178  0.75681591 0.81659084]\n","  [0.86517646 0.90780576 0.88597863]]\n","\n"," [[0.9481396  0.94098668 0.9445496 ]\n","  [0.83919622 0.75667129 0.79580001]\n","  [0.7553705  0.92902931 0.83324794]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]\n","\n"," [[0.95566557 0.96310863 0.95937267]\n","  [0.81829307 0.78599135 0.80181701]\n","  [0.86299069 0.85645591 0.85971088]]\n","\n"," [[0.89234983 0.9644642  0.92700664]\n","  [0.90511257 0.41019509 0.56454127]\n","  [0.78347899 0.92183733 0.84704541]]]\n","FOLD: 4 \tTRAIN: [0 1 2 3 5 6 7 8] TEST: [4]\n","['230', '242', '263', '232', '229', '246', '252', '239']\n","['221']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]\n","\n"," [[0.94400455 0.96472859 0.95425407]\n","  [0.8866178  0.75681591 0.81659084]\n","  [0.86517646 0.90780576 0.88597863]]\n","\n"," [[0.9481396  0.94098668 0.9445496 ]\n","  [0.83919622 0.75667129 0.79580001]\n","  [0.7553705  0.92902931 0.83324794]]\n","\n"," [[0.96989342 0.96691974 0.96840429]\n","  [0.87187895 0.88138167 0.87660455]\n","  [0.90163497 0.90961127 0.90560556]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]\n","\n"," [[0.95566557 0.96310863 0.95937267]\n","  [0.81829307 0.78599135 0.80181701]\n","  [0.86299069 0.85645591 0.85971088]]\n","\n"," [[0.89234983 0.9644642  0.92700664]\n","  [0.90511257 0.41019509 0.56454127]\n","  [0.78347899 0.92183733 0.84704541]]\n","\n"," [[0.92651631 0.93540618 0.93094002]\n","  [0.80535751 0.78969963 0.79745172]\n","  [0.7674757  0.73735295 0.75211283]]]\n","FOLD: 5 \tTRAIN: [0 1 2 3 4 6 7 8] TEST: [5]\n","['230', '242', '263', '232', '221', '246', '252', '239']\n","['229']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]\n","\n"," [[0.94400455 0.96472859 0.95425407]\n","  [0.8866178  0.75681591 0.81659084]\n","  [0.86517646 0.90780576 0.88597863]]\n","\n"," [[0.9481396  0.94098668 0.9445496 ]\n","  [0.83919622 0.75667129 0.79580001]\n","  [0.7553705  0.92902931 0.83324794]]\n","\n"," [[0.96989342 0.96691974 0.96840429]\n","  [0.87187895 0.88138167 0.87660455]\n","  [0.90163497 0.90961127 0.90560556]]\n","\n"," [[0.94108635 0.9695701  0.95511591]\n","  [0.88993479 0.76346627 0.82186375]\n","  [0.87624614 0.86532512 0.87075138]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]\n","\n"," [[0.95566557 0.96310863 0.95937267]\n","  [0.81829307 0.78599135 0.80181701]\n","  [0.86299069 0.85645591 0.85971088]]\n","\n"," [[0.89234983 0.9644642  0.92700664]\n","  [0.90511257 0.41019509 0.56454127]\n","  [0.78347899 0.92183733 0.84704541]]\n","\n"," [[0.92651631 0.93540618 0.93094002]\n","  [0.80535751 0.78969963 0.79745172]\n","  [0.7674757  0.73735295 0.75211283]]\n","\n"," [[0.88871334 0.99314849 0.93803307]\n","  [0.97512292 0.29792735 0.45640898]\n","  [0.93844285 0.75842201 0.8388832 ]]]\n","FOLD: 6 \tTRAIN: [0 1 2 3 4 5 7 8] TEST: [6]\n","['230', '242', '263', '232', '221', '229', '252', '239']\n","['246']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]\n","\n"," [[0.94400455 0.96472859 0.95425407]\n","  [0.8866178  0.75681591 0.81659084]\n","  [0.86517646 0.90780576 0.88597863]]\n","\n"," [[0.9481396  0.94098668 0.9445496 ]\n","  [0.83919622 0.75667129 0.79580001]\n","  [0.7553705  0.92902931 0.83324794]]\n","\n"," [[0.96989342 0.96691974 0.96840429]\n","  [0.87187895 0.88138167 0.87660455]\n","  [0.90163497 0.90961127 0.90560556]]\n","\n"," [[0.94108635 0.9695701  0.95511591]\n","  [0.88993479 0.76346627 0.82186375]\n","  [0.87624614 0.86532512 0.87075138]]\n","\n"," [[0.97016611 0.92555951 0.94733801]\n","  [0.74590236 0.9056271  0.81804098]\n","  [0.87782035 0.8954319  0.88653867]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]\n","\n"," [[0.95566557 0.96310863 0.95937267]\n","  [0.81829307 0.78599135 0.80181701]\n","  [0.86299069 0.85645591 0.85971088]]\n","\n"," [[0.89234983 0.9644642  0.92700664]\n","  [0.90511257 0.41019509 0.56454127]\n","  [0.78347899 0.92183733 0.84704541]]\n","\n"," [[0.92651631 0.93540618 0.93094002]\n","  [0.80535751 0.78969963 0.79745172]\n","  [0.7674757  0.73735295 0.75211283]]\n","\n"," [[0.88871334 0.99314849 0.93803307]\n","  [0.97512292 0.29792735 0.45640898]\n","  [0.93844285 0.75842201 0.8388832 ]]\n","\n"," [[0.97766069 0.86546395 0.91814744]\n","  [0.46573872 0.87770437 0.60855709]\n","  [0.83753362 0.89606152 0.86580959]]]\n","FOLD: 7 \tTRAIN: [0 1 2 3 4 5 6 8] TEST: [7]\n","['230', '242', '263', '232', '221', '229', '246', '239']\n","['252']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]\n","\n"," [[0.94400455 0.96472859 0.95425407]\n","  [0.8866178  0.75681591 0.81659084]\n","  [0.86517646 0.90780576 0.88597863]]\n","\n"," [[0.9481396  0.94098668 0.9445496 ]\n","  [0.83919622 0.75667129 0.79580001]\n","  [0.7553705  0.92902931 0.83324794]]\n","\n"," [[0.96989342 0.96691974 0.96840429]\n","  [0.87187895 0.88138167 0.87660455]\n","  [0.90163497 0.90961127 0.90560556]]\n","\n"," [[0.94108635 0.9695701  0.95511591]\n","  [0.88993479 0.76346627 0.82186375]\n","  [0.87624614 0.86532512 0.87075138]]\n","\n"," [[0.97016611 0.92555951 0.94733801]\n","  [0.74590236 0.9056271  0.81804098]\n","  [0.87782035 0.8954319  0.88653867]]\n","\n"," [[0.9638087  0.95623308 0.96000594]\n","  [0.86268469 0.84671967 0.85462763]\n","  [0.83850103 0.91581957 0.87545646]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]\n","\n"," [[0.95566557 0.96310863 0.95937267]\n","  [0.81829307 0.78599135 0.80181701]\n","  [0.86299069 0.85645591 0.85971088]]\n","\n"," [[0.89234983 0.9644642  0.92700664]\n","  [0.90511257 0.41019509 0.56454127]\n","  [0.78347899 0.92183733 0.84704541]]\n","\n"," [[0.92651631 0.93540618 0.93094002]\n","  [0.80535751 0.78969963 0.79745172]\n","  [0.7674757  0.73735295 0.75211283]]\n","\n"," [[0.88871334 0.99314849 0.93803307]\n","  [0.97512292 0.29792735 0.45640898]\n","  [0.93844285 0.75842201 0.8388832 ]]\n","\n"," [[0.97766069 0.86546395 0.91814744]\n","  [0.46573872 0.87770437 0.60855709]\n","  [0.83753362 0.89606152 0.86580959]]\n","\n"," [[0.93793798 0.98592155 0.96133138]\n","  [0.8883793  0.57418109 0.69753098]\n","  [0.88423411 0.88618743 0.88520969]]]\n","FOLD: 8 \tTRAIN: [0 1 2 3 4 5 6 7] TEST: [8]\n","['230', '242', '263', '232', '221', '229', '246', '252']\n","['239']\n","[[[0.97376292 0.95996381 0.96681413]\n","  [0.85986493 0.90590767 0.88228601]\n","  [0.88895767 0.92151741 0.90494476]]\n","\n"," [[0.9300178  0.97895904 0.95386106]\n","  [0.89067318 0.74117018 0.80907324]\n","  [0.93464429 0.77076582 0.84483125]]\n","\n"," [[0.94400455 0.96472859 0.95425407]\n","  [0.8866178  0.75681591 0.81659084]\n","  [0.86517646 0.90780576 0.88597863]]\n","\n"," [[0.9481396  0.94098668 0.9445496 ]\n","  [0.83919622 0.75667129 0.79580001]\n","  [0.7553705  0.92902931 0.83324794]]\n","\n"," [[0.96989342 0.96691974 0.96840429]\n","  [0.87187895 0.88138167 0.87660455]\n","  [0.90163497 0.90961127 0.90560556]]\n","\n"," [[0.94108635 0.9695701  0.95511591]\n","  [0.88993479 0.76346627 0.82186375]\n","  [0.87624614 0.86532512 0.87075138]]\n","\n"," [[0.97016611 0.92555951 0.94733801]\n","  [0.74590236 0.9056271  0.81804098]\n","  [0.87782035 0.8954319  0.88653867]]\n","\n"," [[0.9638087  0.95623308 0.96000594]\n","  [0.86268469 0.84671967 0.85462763]\n","  [0.83850103 0.91581957 0.87545646]]\n","\n"," [[0.96174263 0.95846747 0.96010226]\n","  [0.84911916 0.82144062 0.8350506 ]\n","  [0.85480877 0.9214061  0.88685893]]]\n","[[[0.93626459 0.87158995 0.90277042]\n","  [0.67623864 0.84833817 0.75257481]\n","  [0.75364224 0.62540261 0.68355982]]\n","\n"," [[0.926629   0.93965091 0.93309453]\n","  [0.74610135 0.55018636 0.63333901]\n","  [0.80828047 0.83018321 0.81908545]]\n","\n"," [[0.95566557 0.96310863 0.95937267]\n","  [0.81829307 0.78599135 0.80181701]\n","  [0.86299069 0.85645591 0.85971088]]\n","\n"," [[0.89234983 0.9644642  0.92700664]\n","  [0.90511257 0.41019509 0.56454127]\n","  [0.78347899 0.92183733 0.84704541]]\n","\n"," [[0.92651631 0.93540618 0.93094002]\n","  [0.80535751 0.78969963 0.79745172]\n","  [0.7674757  0.73735295 0.75211283]]\n","\n"," [[0.88871334 0.99314849 0.93803307]\n","  [0.97512292 0.29792735 0.45640898]\n","  [0.93844285 0.75842201 0.8388832 ]]\n","\n"," [[0.97766069 0.86546395 0.91814744]\n","  [0.46573872 0.87770437 0.60855709]\n","  [0.83753362 0.89606152 0.86580959]]\n","\n"," [[0.93793798 0.98592155 0.96133138]\n","  [0.8883793  0.57418109 0.69753098]\n","  [0.88423411 0.88618743 0.88520969]]\n","\n"," [[0.93668141 0.93594732 0.93631422]\n","  [0.84348032 0.82294598 0.83308663]\n","  [0.83565273 0.89851418 0.86594413]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t-oUz3CNd30L","colab_type":"code","outputId":"8556921d-9da1-4861-e577-dcb51969df27","executionInfo":{"status":"ok","timestamp":1591538978096,"user_tz":-330,"elapsed":3562870,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(pixEvaluationTrain.shape)\n","print(pixEvaluationTest.shape)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["(9, 3, 3)\n","(9, 3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BWlJ0gSReCpZ","colab_type":"code","colab":{}},"source":["np.save(SAVE_PATH + \"Pixel-wise Metrics Train.npy\", pixEvaluationTrain)\n","np.save(SAVE_PATH + \"Pixel-wise Metrics Test.npy\", pixEvaluationTest)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-K-j8Hn0wu2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"9ffbd52f-9036-4e85-d0e8-9bedd4f1128d","executionInfo":{"status":"ok","timestamp":1591551056588,"user_tz":-330,"elapsed":5093,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}}},"source":["LOAD_PATH = \"/content/drive/My Drive/Breast Cancer Treatment/Numpy Arrays/Predicted Output/Ki67/KFold LadderNet/\"\n","trainMetrics = np.load(LOAD_PATH + \"Pixel-wise Metrics Train.npy\")\n","testMetrics  = np.load(LOAD_PATH + \"Pixel-wise Metrics Test.npy\")\n","print(trainMetrics.shape)\n","print(testMetrics.shape)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(9, 3, 3)\n","(9, 3, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6T6WjW7H1RMk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"ca44992e-abaa-4b24-8010-ffa793e7c65c","executionInfo":{"status":"ok","timestamp":1591551064967,"user_tz":-330,"elapsed":1804,"user":{"displayName":"Ramya B","photoUrl":"","userId":"10194325446164447523"}}},"source":["\n","#For pixel-wise background is included and for object-wise background is not included\n","numClasses = 3\n","avgTrainMetrics  = np.zeros([numClasses, 3])\n","avgTestMetrics   = np.zeros([numClasses, 3])\n","\n","def calculateMetrics(AvgMetrics, ValidationMetrics):\n","  for patientNum in range(ValidationMetrics.shape[0]):\n","    for row in range(numClasses):\n","      for col in range(3):\n","        AvgMetrics[row][col] += ValidationMetrics[patientNum][row][col]\n","  AvgMetrics = np.divide(AvgMetrics,ValidationMetrics.shape[0] )\n","  return AvgMetrics\n","\n","\n","avgTrainMetrics = calculateMetrics(avgTrainMetrics, trainMetrics)\n","print('TRAIN :')\n","print(avgTrainMetrics)\n","\n","avgTestMetrics = calculateMetrics(avgTestMetrics, testMetrics)\n","print('TEST :')\n","print(avgTestMetrics)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["TRAIN :\n","[[0.9558469  0.957932   0.95671614]\n"," [0.8550969  0.81991115 0.83443751]\n"," [0.86590669 0.89296803 0.87713484]]\n","TEST :\n","[[0.93093541 0.93941124 0.93411226]\n"," [0.79153604 0.66190771 0.68281195]\n"," [0.83019238 0.82337968 0.82415122]]\n"],"name":"stdout"}]}]}